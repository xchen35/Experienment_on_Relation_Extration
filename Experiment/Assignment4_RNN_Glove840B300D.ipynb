{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment4.ipynb","version":"0.3.2","provenance":[{"file_id":"1BLxBltRR1dsBrhPWTO8KGysK3X3p1zxT","timestamp":1554158151758}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-rpFuvhvjGL0","colab_type":"code","outputId":"e9f09e2e-0dc2-40db-82f3-cd650aae1dd6","executionInfo":{"status":"ok","timestamp":1554407220311,"user_tz":240,"elapsed":2057,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["import keras\n","import itertools\n","import os\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import json\n","import time\n","import datetime\n","import subprocess\n","\n","from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n","from sklearn.metrics import confusion_matrix\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.preprocessing import text, sequence\n","\n","from __future__ import absolute_import, division, print_function\n","keras.__version__"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"5IIGLg48nJvf","colab_type":"code","outputId":"e9e9900f-635d-4579-f7e2-42d728893a1f","executionInfo":{"status":"ok","timestamp":1554407221685,"user_tz":240,"elapsed":3408,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import nltk\n","import re\n","nltk.download('punkt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"EihwcokIm75h","colab_type":"code","outputId":"e861d640-c7af-40b7-d326-8269f3526539","executionInfo":{"status":"ok","timestamp":1554407239367,"user_tz":240,"elapsed":21068,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"H-ckbIMfnDuj","colab_type":"code","outputId":"17fff702-61f9-490f-a587-6e024372abcf","executionInfo":{"status":"ok","timestamp":1554407241003,"user_tz":240,"elapsed":22689,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"PxdTqlYGoQ03","colab_type":"code","colab":{}},"cell_type":"code","source":["def clean_str(text):\n","    text = text.lower()\n","    # Clean the text\n","    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n","    text = re.sub(r\"what's\", \"what is \", text)\n","    text = re.sub(r\"that's\", \"that is \", text)\n","    text = re.sub(r\"there's\", \"there is \", text)\n","    text = re.sub(r\"it's\", \"it is \", text)\n","    text = re.sub(r\"\\'s\", \" \", text)\n","    text = re.sub(r\"\\'ve\", \" have \", text)\n","    text = re.sub(r\"can't\", \"can not \", text)\n","    text = re.sub(r\"n't\", \" not \", text)\n","    text = re.sub(r\"i'm\", \"i am \", text)\n","    text = re.sub(r\"\\'re\", \" are \", text)\n","    text = re.sub(r\"\\'d\", \" would \", text)\n","    text = re.sub(r\"\\'ll\", \" will \", text)\n","    text = re.sub(r\",\", \" \", text)\n","    text = re.sub(r\"\\.\", \" \", text)\n","    text = re.sub(r\"!\", \" ! \", text)\n","    text = re.sub(r\"\\/\", \" \", text)\n","    text = re.sub(r\"\\^\", \" ^ \", text)\n","    text = re.sub(r\"\\+\", \" + \", text)\n","    text = re.sub(r\"\\-\", \" - \", text)\n","    text = re.sub(r\"\\=\", \" = \", text)\n","    text = re.sub(r\"'\", \" \", text)\n","    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n","    text = re.sub(r\":\", \" : \", text)\n","    text = re.sub(r\" e g \", \" eg \", text)\n","    text = re.sub(r\" b g \", \" bg \", text)\n","    text = re.sub(r\" u s \", \" american \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    text = re.sub(r\" 9 11 \", \"911\", text)\n","    text = re.sub(r\"e - mail\", \"email\", text)\n","    text = re.sub(r\"j k\", \"jk\", text)\n","    text = re.sub(r\"\\s{2,}\", \" \", text)\n","\n","    return text.strip()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0YmTo-cborq8","colab_type":"code","colab":{}},"cell_type":"code","source":["class2label = {'Other': 0,\n","               'Message-Topic(e1,e2)': 1, 'Message-Topic(e2,e1)': 2,\n","               'Product-Producer(e1,e2)': 3, 'Product-Producer(e2,e1)': 4,\n","               'Instrument-Agency(e1,e2)': 5, 'Instrument-Agency(e2,e1)': 6,\n","               'Entity-Destination(e1,e2)': 7, 'Entity-Destination(e2,e1)': 8,\n","               'Cause-Effect(e1,e2)': 9, 'Cause-Effect(e2,e1)': 10,\n","               'Component-Whole(e1,e2)': 11, 'Component-Whole(e2,e1)': 12,\n","               'Entity-Origin(e1,e2)': 13, 'Entity-Origin(e2,e1)': 14,\n","               'Member-Collection(e1,e2)': 15, 'Member-Collection(e2,e1)': 16,\n","               'Content-Container(e1,e2)': 17, 'Content-Container(e2,e1)': 18}\n","\n","label2class = {0: 'Other',\n","               1: 'Message-Topic(e1,e2)', 2: 'Message-Topic(e2,e1)',\n","               3: 'Product-Producer(e1,e2)', 4: 'Product-Producer(e2,e1)',\n","               5: 'Instrument-Agency(e1,e2)', 6: 'Instrument-Agency(e2,e1)',\n","               7: 'Entity-Destination(e1,e2)', 8: 'Entity-Destination(e2,e1)',\n","               9: 'Cause-Effect(e1,e2)', 10: 'Cause-Effect(e2,e1)',\n","               11: 'Component-Whole(e1,e2)', 12: 'Component-Whole(e2,e1)',\n","               13: 'Entity-Origin(e1,e2)', 14: 'Entity-Origin(e2,e1)',\n","               15: 'Member-Collection(e1,e2)', 16: 'Member-Collection(e2,e1)',\n","               17: 'Content-Container(e1,e2)', 18: 'Content-Container(e2,e1)'}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N1iUFZB6as4B","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_word2vec(word2vec_path, embedding_dim, vocab):\n","    # initial matrix with random uniform\n","    initW = np.random.randn(len(vocab.vocabulary_), embedding_dim).astype(np.float32) * np.sqrt(2.0 / len(vocab.vocabulary_))\n","    # load any vectors from the word2vec\n","    print(\"Load word2vec file {0}\".format(word2vec_path))\n","    with open(word2vec_path, \"rb\") as f:\n","        header = f.readline()\n","        vocab_size, layer1_size = map(int, header.split())\n","        binary_len = np.dtype('float32').itemsize * layer1_size\n","        for line in range(vocab_size):\n","            word = []\n","            while True:\n","                ch = f.read(1).decode('latin-1')\n","                if ch == ' ':\n","                    word = ''.join(word)\n","                    break\n","                if ch != '\\n':\n","                    word.append(ch)\n","            idx = vocab.vocabulary_.get(word)\n","            if idx != 0:\n","                initW[idx] = np.fromstring(f.read(binary_len), dtype='float32')\n","            else:\n","                f.read(binary_len)\n","    return initW\n","\n","\n","def load_glove(word2vec_path, embedding_dim, vocab):\n","    # initial matrix with random uniform\n","    initW = np.random.randn(len(vocab.vocabulary_), embedding_dim).astype(np.float32) * np.sqrt(2.0 / len(vocab.vocabulary_))\n","    # load any vectors from the word2vec\n","    print(\"Load glove file {0}\".format(word2vec_path))\n","    f = open(word2vec_path, 'r', encoding='utf8')\n","    for line in f:\n","        splitLine = line.split(' ')\n","        word = splitLine[0]\n","        embedding = np.asarray(splitLine[1:], dtype='float32')\n","        idx = vocab.vocabulary_.get(word)\n","        if idx != 0:\n","            initW[idx] = embedding\n","    return initW"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vl0qkdaUouPU","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_data_and_labels(path):\n","    data = []\n","    lines = [line.strip() for line in open(path)]\n","    max_sentence_length = 0\n","    for idx in range(0, len(lines), 4):\n","        id = lines[idx].split(\"\\t\")[0]\n","        relation = lines[idx + 1]\n","\n","        sentence = lines[idx].split(\"\\t\")[1][1:-1]\n","        sentence = sentence.replace('<e1>', ' _e11_ ')\n","        sentence = sentence.replace('</e1>', ' _e12_ ')\n","        sentence = sentence.replace('<e2>', ' _e21_ ')\n","        sentence = sentence.replace('</e2>', ' _e22_ ')\n","\n","        sentence = clean_str(sentence)\n","        tokens = nltk.word_tokenize(sentence)\n","        if max_sentence_length < len(tokens):\n","            max_sentence_length = len(tokens)\n","        e1 = tokens.index(\"e12\") - 1\n","        e2 = tokens.index(\"e22\") - 1\n","        sentence = \" \".join(tokens)\n","\n","        data.append([id, sentence, e1, e2, relation])\n","\n","    print(path)\n","    print(\"max sentence length = {}\\n\".format(max_sentence_length))\n","\n","    df = pd.DataFrame(data=data, columns=[\"id\", \"sentence\", \"e1\", \"e2\", \"relation\"])\n","\n","    pos1, pos2 = get_relative_position(df, 90)\n","\n","    df['label'] = [class2label[r] for r in df['relation']]\n","\n","    # Text Data\n","    x_text = df['sentence'].tolist()\n","    e1 = df['e1'].tolist()\n","    e2 = df['e2'].tolist()\n","\n","    # Label Data\n","    y = df['label']\n","    labels_flat = y.values.ravel()\n","    labels_count = np.unique(labels_flat).shape[0]\n","\n","    # convert class labels from scalars to one-hot vectors\n","    # 0  => [1 0 0 0 0 ... 0 0 0 0 0]\n","    # 1  => [0 1 0 0 0 ... 0 0 0 0 0]\n","    # ...\n","    # 18 => [0 0 0 0 0 ... 0 0 0 0 1]\n","    def dense_to_one_hot(labels_dense, num_classes):\n","        num_labels = labels_dense.shape[0]\n","        index_offset = np.arange(num_labels) * num_classes\n","        labels_one_hot = np.zeros((num_labels, num_classes))\n","        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n","        return labels_one_hot\n","\n","    labels = dense_to_one_hot(labels_flat, labels_count)\n","    labels = labels.astype(np.uint8)\n","\n","    return x_text, labels, e1, e2, pos1, pos2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vDLNSbr1tOCv","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_relative_position(df, max_sentence_length):\n","    # Position data\n","    pos1 = []\n","    pos2 = []\n","    for df_idx in range(len(df)):\n","        sentence = df.iloc[df_idx]['sentence']\n","        tokens = nltk.word_tokenize(sentence)\n","        e1 = df.iloc[df_idx]['e1']\n","        e2 = df.iloc[df_idx]['e2']\n","\n","        p1 = \"\"\n","        p2 = \"\"\n","        for word_idx in range(len(tokens)):\n","            p1 += str((max_sentence_length - 1) + word_idx - e1) + \" \"\n","            p2 += str((max_sentence_length - 1) + word_idx - e2) + \" \"\n","        pos1.append(p1)\n","        pos2.append(p2)\n","\n","    return pos1, pos2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KDGyY3z-Zmvv","colab_type":"code","colab":{}},"cell_type":"code","source":["def batch_iter(data, batch_size, num_epochs, shuffle=True):\n","    \"\"\"\n","    Generates a batch iterator for a dataset.\n","    \"\"\"\n","    data = np.array(data)\n","    data_size = len(data)\n","    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n","    for epoch in range(num_epochs):\n","        # Shuffle the data at each epoch\n","        if shuffle:\n","            shuffle_indices = np.random.permutation(np.arange(data_size))\n","            shuffled_data = data[shuffle_indices]\n","        else:\n","            shuffled_data = data\n","        for batch_num in range(num_batches_per_epoch):\n","            start_index = batch_num * batch_size\n","            end_index = min((batch_num + 1) * batch_size, data_size)\n","            yield shuffled_data[start_index:end_index]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RgtcoR4XoyxR","colab_type":"code","outputId":"2485d625-fb55-4f05-aad2-f77326d69b60","executionInfo":{"status":"ok","timestamp":1554407251265,"user_tz":240,"elapsed":32911,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["text_train, y_train, train_e1, train_e2, train_pos1, train_pos2 = load_data_and_labels(\"drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT\n","max sentence length = 89\n","\n"],"name":"stdout"}]},{"metadata":{"id":"cZFx8-ejpKsA","colab_type":"code","outputId":"a34c4ac7-fce9-4ecc-ed0c-92a956aace44","executionInfo":{"status":"ok","timestamp":1554407254849,"user_tz":240,"elapsed":36475,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["text_test, y_test, test_e1, test_e2, test_pos1, test_pos2 = load_data_and_labels(\"drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\n","max sentence length = 68\n","\n"],"name":"stdout"}]},{"metadata":{"id":"yGrIs5LFsJX4","colab_type":"code","colab":{}},"cell_type":"code","source":["import argparse\n","import sys\n","\n","def parse_args():\n","    \"\"\"\n","    Parse input arguments\n","    \"\"\"\n","    parser = argparse.ArgumentParser()\n","\n","    # Data loading params\n","    parser.add_argument(\"--train_path\", default=\"drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT\",\n","                        type=str, help=\"Path of train data\")\n","    parser.add_argument(\"--test_path\", default=\"drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\",\n","                        type=str, help=\"Path of test data\")\n","    parser.add_argument(\"--max_sentence_length\", default=90,\n","                        type=int, help=\"Max sentence length in data\")\n","\n","    # Model Hyper-parameters\n","    # Embeddings\n","    parser.add_argument(\"--embeddings\", default=None,\n","                        type=str, help=\"Embeddings {'word2vec', 'glove100', 'glove300', 'elmo'}\")\n","    parser.add_argument(\"--embedding_size\", default=300,\n","                        type=int, help=\"Dimensionality of word embedding (default: 300)\")\n","    parser.add_argument(\"--pos_embedding_size\", default=50,\n","                        type=int, help=\"Dimensionality of relative position embedding (default: 50)\")\n","    parser.add_argument(\"--emb_dropout_keep_prob\", default=0.7,\n","                        type=float, help=\"Dropout keep probability of embedding layer (default: 0.7)\")\n","    # RNN\n","    parser.add_argument(\"--hidden_size\", default=300,\n","                        type=int, help=\"Dimensionality of RNN hidden (default: 300)\")\n","    parser.add_argument(\"--rnn_dropout_keep_prob\", default=0.7,\n","                        type=float, help=\"Dropout keep probability of RNN (default: 0.7)\")\n","    # Attention\n","    parser.add_argument(\"--num_heads\", default=4,\n","                        type=int, help=\"Number of heads in multi-head attention (default: 4)\")\n","    parser.add_argument(\"--attention_size\", default=50,\n","                        type=int, help=\"Dimensionality of attention (default: 50)\")\n","    # Misc\n","    parser.add_argument(\"--desc\", default=\"\",\n","                        type=str, help=\"Description for model\")\n","    parser.add_argument(\"--dropout_keep_prob\", default=0.5,\n","                        type=float, help=\"Dropout keep probability of output layer (default: 0.5)\")\n","    parser.add_argument(\"--l2_reg_lambda\", default=1e-5,\n","                        type=float, help=\"L2 regularization lambda (default: 1e-5)\")\n","\n","    # Training parameters\n","    parser.add_argument(\"--batch_size\", default=20,\n","                        type=int, help=\"Batch Size (default: 20)\")\n","    parser.add_argument(\"--num_epochs\", default=100,\n","                        type=int, help=\"Number of training epochs (Default: 100)\")\n","    parser.add_argument(\"--display_every\", default=10,\n","                        type=int, help=\"Number of iterations to display training information\")\n","    parser.add_argument(\"--evaluate_every\", default=100,\n","                        type=int, help=\"Evaluate model on dev set after this many steps (default: 100)\")\n","    parser.add_argument(\"--num_checkpoints\", default=5,\n","                        type=int, help=\"Number of checkpoints to store (default: 5)\")\n","    parser.add_argument(\"--learning_rate\", default=1.0,\n","                        type=float, help=\"Which learning rate to start with (Default: 1.0)\")\n","    parser.add_argument(\"--decay_rate\", default=0.9,\n","                        type=float, help=\"Decay rate for learning rate (Default: 0.9)\")\n","\n","    # Misc Parameters\n","    parser.add_argument(\"--allow_soft_placement\", default=True,\n","                        type=bool, help=\"Allow device soft device placement\")\n","    parser.add_argument(\"--log_device_placement\", default=False,\n","                        type=bool, help=\"Log placement of ops on devices\")\n","    parser.add_argument(\"--gpu_allow_growth\", default=True,\n","                        type=bool, help=\"Allow gpu memory growth\")\n","\n","    # Visualization Parameters\n","    parser.add_argument(\"--checkpoint_dir\", default=None,\n","                        type=str, help=\"Visualize this checkpoint\")\n","\n","    if len(sys.argv) == 0:\n","        parser.print_help()\n","        sys.exit(1)\n","\n","    print(\"\")\n","    args = parser.parse_known_args()[0]\n","    for arg in vars(args):\n","        print(\"{}={}\".format(arg.upper(), getattr(args, arg)))\n","    print(\"\")\n","\n","    return args"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JyQ-Wuvfw9Hz","colab_type":"code","outputId":"a8c58325-6935-45a2-d3b8-d28cbbf762e2","executionInfo":{"status":"ok","timestamp":1554407254852,"user_tz":240,"elapsed":36460,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":508}},"cell_type":"code","source":["FLAGS = parse_args()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","TRAIN_PATH=drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT\n","TEST_PATH=drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\n","MAX_SENTENCE_LENGTH=90\n","EMBEDDINGS=None\n","EMBEDDING_SIZE=300\n","POS_EMBEDDING_SIZE=50\n","EMB_DROPOUT_KEEP_PROB=0.7\n","HIDDEN_SIZE=300\n","RNN_DROPOUT_KEEP_PROB=0.7\n","NUM_HEADS=4\n","ATTENTION_SIZE=50\n","DESC=\n","DROPOUT_KEEP_PROB=0.5\n","L2_REG_LAMBDA=1e-05\n","BATCH_SIZE=20\n","NUM_EPOCHS=100\n","DISPLAY_EVERY=10\n","EVALUATE_EVERY=100\n","NUM_CHECKPOINTS=5\n","LEARNING_RATE=1.0\n","DECAY_RATE=0.9\n","ALLOW_SOFT_PLACEMENT=True\n","LOG_DEVICE_PLACEMENT=False\n","GPU_ALLOW_GROWTH=True\n","CHECKPOINT_DIR=None\n","\n"],"name":"stdout"}]},{"metadata":{"id":"sVADfqlQqgPq","colab_type":"code","colab":{}},"cell_type":"code","source":["FLAGS.embeddings = \"glove300\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"gtWZHnf5w8F3","colab_type":"code","outputId":"f6e9d890-6dc0-47cf-fc3f-02d7369f77f2","executionInfo":{"status":"ok","timestamp":1554407258067,"user_tz":240,"elapsed":39650,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"cell_type":"code","source":["vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(90)\n","vocab_processor.fit(text_train + text_test)\n","x_train = np.array(list(vocab_processor.transform(text_train)))\n","x_test = np.array(list(vocab_processor.transform(text_test)))\n","text_train = np.array(text_train)\n","text_test = np.array(text_test)\n","print(\"\\nText Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n","print(\"x_train = {0}\".format(x_train.shape))\n","print(\"y_train = {0}\".format(y_train.shape))\n","print(\"x_test = {0}\".format(x_test.shape))\n","print(\"y_test = {0}\".format(y_test.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-17-eb4cf98214cd>:1: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","\n","Text Vocabulary Size: 22384\n","x_train = (8000, 90)\n","y_train = (8000, 19)\n","x_test = (2717, 90)\n","y_test = (2717, 19)\n"],"name":"stdout"}]},{"metadata":{"id":"mMs23rCEyH8x","colab_type":"code","outputId":"055fd106-2641-415b-9713-09686f79c368","executionInfo":{"status":"ok","timestamp":1554407259051,"user_tz":240,"elapsed":40620,"user":{"displayName":"Yuchen He","photoUrl":"","userId":"17836836288676257850"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"cell_type":"code","source":["pos_vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(FLAGS.max_sentence_length)\n","pos_vocab_processor.fit(train_pos1 + train_pos2 + test_pos1 + test_pos2)\n","train_p1 = np.array(list(pos_vocab_processor.transform(train_pos1)))\n","train_p2 = np.array(list(pos_vocab_processor.transform(train_pos2)))\n","test_p1 = np.array(list(pos_vocab_processor.transform(test_pos1)))\n","test_p2 = np.array(list(pos_vocab_processor.transform(test_pos2)))\n","print(\"\\nPosition Vocabulary Size: {:d}\".format(len(pos_vocab_processor.vocabulary_)))\n","print(\"train_p1 = {0}\".format(train_p1.shape))\n","print(\"test_p1 = {0}\".format(test_p1.shape))\n","print(\"\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Position Vocabulary Size: 162\n","train_p1 = (8000, 90)\n","test_p1 = (2717, 90)\n","\n"],"name":"stdout"}]},{"metadata":{"id":"oinb5Ifu2lAN","colab_type":"code","colab":{}},"cell_type":"code","source":["def initializer():\n","    return tf.keras.initializers.glorot_normal()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u2x6tEqa2lDW","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_word2vec(word2vec_path, embedding_dim, vocab):\n","    # initial matrix with random uniform\n","    initW = np.random.randn(len(vocab.vocabulary_), embedding_dim).astype(np.float32) * np.sqrt(2.0 / len(vocab.vocabulary_))\n","    # load any vectors from the word2vec\n","    print(\"Load word2vec file {0}\".format(word2vec_path))\n","    with open(word2vec_path, \"rb\") as f:\n","        header = f.readline()\n","        vocab_size, layer1_size = map(int, header.split())\n","        binary_len = np.dtype('float32').itemsize * layer1_size\n","        for line in range(vocab_size):\n","            word = []\n","            while True:\n","                ch = f.read(1).decode('latin-1')\n","                if ch == ' ':\n","                    word = ''.join(word)\n","                    break\n","                if ch != '\\n':\n","                    word.append(ch)\n","            idx = vocab.vocabulary_.get(word)\n","            if idx != 0:\n","                initW[idx] = np.fromstring(f.read(binary_len), dtype='float32')\n","            else:\n","                f.read(binary_len)\n","    return initW"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PRRVp2-d2lGa","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_glove(word2vec_path, embedding_dim, vocab):\n","    # initial matrix with random uniform\n","    initW = np.random.randn(len(vocab.vocabulary_), embedding_dim).astype(np.float32) * np.sqrt(2.0 / len(vocab.vocabulary_))\n","    # load any vectors from the word2vec\n","    print(\"Load glove file {0}\".format(word2vec_path))\n","    f = open(word2vec_path, 'r', encoding='utf8')\n","    for line in f:\n","        splitLine = line.split(' ')\n","        word = splitLine[0]\n","        embedding = np.asarray(splitLine[1:], dtype='float32')\n","        idx = vocab.vocabulary_.get(word)\n","        if idx != 0:\n","            initW[idx] = embedding\n","    return initW"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fAGRdcaH2lJk","colab_type":"code","colab":{}},"cell_type":"code","source":["def attention(inputs, e1, e2, p1, p2, attention_size):\n","    # inputs = (batch, seq_len, hidden)\n","    # e1, e2 = (batch, seq_len)\n","    # p1, p2 = (batch, seq_len, dist_emb_size)\n","    # attention_size = scalar(int)\n","    def extract_entity(x, e):\n","        e_idx = tf.concat([tf.expand_dims(tf.range(tf.shape(e)[0]), axis=-1), tf.expand_dims(e, axis=-1)], axis=-1)\n","        return tf.gather_nd(x, e_idx)  # (batch, hidden)\n","    seq_len = tf.shape(inputs)[1]  # fixed at run-time\n","    hidden_size = inputs.shape[2].value  # fixed at compile-time\n","    latent_size = hidden_size\n","\n","    # Latent Relation Variable based on Entities\n","    e1_h = extract_entity(inputs, e1)  # (batch, hidden)\n","    e2_h = extract_entity(inputs, e2)  # (batch, hidden)\n","    e1_type, e2_type, e1_alphas, e2_alphas = latent_type_attention(e1_h, e2_h,\n","                                                                   num_type=3,\n","                                                                   latent_size=latent_size)  # (batch, hidden)\n","    e1_h = tf.concat([e1_h, e1_type], axis=-1)  # (batch, hidden+latent)\n","    e2_h = tf.concat([e2_h, e2_type], axis=-1)  # (batch, hidden+latent)\n","\n","    # v*tanh(W*[h;p1;p2]+W*[e1;e2]) 85.18%? 84.83% 84.55%\n","    e_h = tf.layers.dense(tf.concat([e1_h, e2_h], -1), attention_size, use_bias=False, kernel_initializer=initializer())\n","    e_h = tf.reshape(tf.tile(e_h, [1, seq_len]), [-1, seq_len, attention_size])\n","    v = tf.layers.dense(tf.concat([inputs, p1, p2], axis=-1), attention_size, use_bias=False, kernel_initializer=initializer())\n","    v = tf.tanh(tf.add(v, e_h))\n","\n","    u_omega = tf.get_variable(\"u_omega\", [attention_size], initializer=initializer())\n","    vu = tf.tensordot(v, u_omega, axes=1, name='vu')  # (batch, seq_len)\n","    alphas = tf.nn.softmax(vu, name='alphas')  # (batch, seq_len)\n","\n","    # v*tanh(W*[h;p1;p2;e1;e2]) 85.18% 84.41%\n","    # e1_h = tf.reshape(tf.tile(e1_h, [1, seq_len]), [-1, seq_len, hidden_size+latent_size])\n","    # e2_h = tf.reshape(tf.tile(e2_h, [1, seq_len]), [-1, seq_len, hidden_size+latent_size])\n","    # v = tf.concat([inputs, p1, p2, e1_h, e2_h], axis=-1)\n","    # v = tf.layers.dense(v, attention_size, activation=tf.tanh, kernel_initializer=initializer())\n","    #\n","    # u_omega = tf.get_variable(\"u_omega\", [attention_size], initializer=initializer())\n","    # vu = tf.tensordot(v, u_omega, axes=1, name='vu')  # (batch, seq_len)\n","    # alphas = tf.nn.softmax(vu, name='alphas')  # (batch, seq_len)\n","\n","    # output\n","    output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)  # (batch, hidden)\n","\n","    return output, alphas, e1_alphas, e2_alphas"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rZ_kkfDKXGP2","colab_type":"code","colab":{}},"cell_type":"code","source":["def latent_type_attention(e1, e2, num_type, latent_size):\n","    # Latent Entity Type Vectors\n","    latent_type = tf.get_variable(\"latent_type\", shape=[num_type, latent_size], initializer=initializer())\n","\n","    # e1_h = tf.layers.dense(e1, latent_size, kernel_initializer=initializer())\n","    # e2_h = tf.layers.dense(e2, latent_size, kernel_initializer=initializer())\n","\n","    e1_sim = tf.matmul(e1, tf.transpose(latent_type))  # (batch, num_type)\n","    e1_alphas = tf.nn.softmax(e1_sim, name='e1_alphas')  # (batch, num_type)\n","    e1_type = tf.matmul(e1_alphas, latent_type, name='e1_type')  # (batch, hidden)\n","\n","    e2_sim = tf.matmul(e2, tf.transpose(latent_type))  # (batch, num_type)\n","    e2_alphas = tf.nn.softmax(e2_sim, name='e2_alphas')  # (batch, num_type)\n","    e2_type = tf.matmul(e2_alphas, latent_type, name='e2_type')  # (batch, hidden)\n","\n","    return e1_type, e2_type, e1_alphas, e2_alphas"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MXvp-3Eo2lMb","colab_type":"code","colab":{}},"cell_type":"code","source":["def multihead_attention(queries, keys, num_units, num_heads,\n","                        dropout_rate=0, scope=\"multihead_attention\", reuse=None):\n","    with tf.variable_scope(scope, reuse=reuse):\n","        # Linear projections\n","        Q = tf.layers.dense(queries, num_units, kernel_initializer=initializer())  # (N, T_q, C)\n","        K = tf.layers.dense(keys, num_units, kernel_initializer=initializer())  # (N, T_k, C)\n","        V = tf.layers.dense(keys, num_units, kernel_initializer=initializer())  # (N, T_k, C)\n","\n","        # Split and concat\n","        Q_ = tf.concat(tf.split(Q, num_heads, axis=2), axis=0)  # (h*N, T_q, C/h)\n","        K_ = tf.concat(tf.split(K, num_heads, axis=2), axis=0)  # (h*N, T_k, C/h)\n","        V_ = tf.concat(tf.split(V, num_heads, axis=2), axis=0)  # (h*N, T_k, C/h)\n","\n","        # Multiplication\n","        outputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1]))  # (h*N, T_q, T_k)\n","\n","        # Scale\n","        outputs /= K_.get_shape().as_list()[-1] ** 0.5\n","\n","        # Key Masking\n","        key_masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1)))  # (N, T_k)\n","        key_masks = tf.tile(key_masks, [num_heads, 1])  # (h*N, T_k)\n","        key_masks = tf.tile(tf.expand_dims(key_masks, 1), [1, tf.shape(queries)[1], 1])  # (h*N, T_q, T_k)\n","\n","        paddings = tf.ones_like(outputs) * (-2 ** 32 + 1)\n","        outputs = tf.where(tf.equal(key_masks, 0), paddings, outputs)  # (h*N, T_q, T_k)\n","\n","        # Activation\n","        alphas = tf.nn.softmax(outputs)  # (h*N, T_q, T_k)\n","\n","        # Query Masking\n","        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1)))  # (N, T_q)\n","        query_masks = tf.tile(query_masks, [num_heads, 1])  # (h*N, T_q)\n","        query_masks = tf.tile(tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]])  # (h*N, T_q, T_k)\n","        alphas *= query_masks  # broadcasting. (N, T_q, C)\n","\n","        # Dropouts\n","        alphas = tf.layers.dropout(alphas, rate=dropout_rate, training=tf.convert_to_tensor(True))\n","\n","        # Weighted sum\n","        outputs = tf.matmul(alphas, V_)  # ( h*N, T_q, C/h)\n","        # Restore shape\n","        outputs = tf.concat(tf.split(outputs, num_heads, axis=0), axis=2)  # (N, T_q, C)\n","\n","        # Linear\n","        outputs = tf.layers.dense(outputs, num_units, activation=tf.nn.relu, kernel_initializer=initializer())\n","\n","        # Residual connection\n","        outputs += queries\n","        # Normalize\n","        outputs = layer_norm(outputs)  # (N, T_q, C)\n","\n","    return outputs, alphas"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f9PKygyn_CRN","colab_type":"code","colab":{}},"cell_type":"code","source":["def layer_norm(inputs, epsilon=1e-8, scope=\"layer_norm\", reuse=None):\n","    with tf.variable_scope(scope, reuse=reuse):\n","        inputs_shape = inputs.get_shape()\n","        params_shape = inputs_shape[-1:]\n","\n","        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n","        beta = tf.Variable(tf.zeros(params_shape))\n","        gamma = tf.Variable(tf.ones(params_shape))\n","        normalized = (inputs - mean) / ((variance + epsilon) ** (.5))\n","        outputs = gamma * normalized + beta\n","    return outputs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vt4U-Ckd3gWX","colab_type":"code","colab":{}},"cell_type":"code","source":["class Logger:\n","    def __init__(self, out_dir):\n","        self.log_dir = os.path.abspath(os.path.join(out_dir, \"logs\"))\n","        os.makedirs(self.log_dir)\n","        self.log_path = os.path.abspath(os.path.join(self.log_dir, \"logs.txt\"))\n","        self.log_file = open(self.log_path, \"w\")\n","\n","        self.print_hyperparameters()\n","\n","        self.best_f1 = 0.0\n","\n","    def print_hyperparameters(self):\n","        self.log_file.write(\"\\n================ Hyper-parameters ================\\n\\n\")\n","        for arg in vars(FLAGS):\n","            self.log_file.write(\"{}={}\\n\".format(arg.upper(), getattr(FLAGS, arg)))\n","        self.log_file.write(\"\\n==================================================\\n\\n\")\n","\n","    def logging_train(self, step, loss, accuracy):\n","        time_str = datetime.datetime.now().isoformat()\n","        log = \"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy)\n","        self.log_file.write(log+\"\\n\")\n","        print(log)\n","\n","    def logging_eval(self, step, loss, accuracy, predictions):\n","        self.log_file.write(\"\\nEvaluation:\\n\")\n","        # loss & acc\n","        time_str = datetime.datetime.now().isoformat()\n","        log = \"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy)\n","        self.log_file.write(log + \"\\n\")\n","        print(log)\n","#         print(\"=========Prediction_Path============\")\n","#         print(self.log_dir)\n","        # f1-score\n","        prediction_path = os.path.abspath(os.path.join(self.log_dir, \"predictions.txt\"))[9:]\n","#         print(prediction_path)\n","        prediction_file = open(prediction_path, 'w')\n","        for i in range(len(predictions)):\n","            prediction_file.write(\"{}\\t{}\\n\".format(i, label2class[predictions[i]]))\n","        prediction_file.close()\n","        perl_path = \"drive/My Drive/INFO7374/Assignment4/SemEval2010_task8_all_data/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl\"\n","#         os.path.join(os.path.curdir,\n","#                                  \"SemEval2010_task8_all_data\",\n","#                                  \"SemEval2010_task8_scorer-v1.2\",\n","#                                  \"semeval2010_task8_scorer-v1.2.pl\")\n","        target_path = \"drive/My Drive/INFO7374/Assignment4/resource/target.txt\"\n","        process = subprocess.Popen([\"perl\", perl_path, prediction_path, target_path], stdout=subprocess.PIPE)\n","#         print(\"===========logger===========\")\n","#         print(perl_path)\n","#         print(prediction_path)\n","#         print(target_path)\n","#         print(process)\n","        str_parse = str(process.communicate()[0]).split(\"\\\\n\")[-2]\n","        idx = str_parse.find('%')\n","        f1_score = float(str_parse[idx-5:idx])\n","\n","        self.best_f1 = max(self.best_f1, f1_score)\n","        f1_log = \"<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\\n\" \\\n","                 \"macro-averaged F1-score = {:g}%, Best = {:g}%\\n\".format(f1_score, self.best_f1)\n","        self.log_file.write(f1_log + \"\\n\")\n","        print(f1_log)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YpoaA2H-2lPB","colab_type":"code","colab":{}},"cell_type":"code","source":["class EntityAttentionLSTM:\n","    def __init__(self, sequence_length, num_classes,\n","                 vocab_size, embedding_size, pos_vocab_size, pos_embedding_size,\n","                 hidden_size, num_heads, attention_size,\n","                 use_elmo=False, l2_reg_lambda=0.0):\n","        # Placeholders for input, output and dropout\n","        self.input_x = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_x')\n","        self.input_y = tf.placeholder(tf.float32, shape=[None, num_classes], name='input_y')\n","        self.input_text = tf.placeholder(tf.string, shape=[None, ], name='input_text')\n","        self.input_e1 = tf.placeholder(tf.int32, shape=[None, ], name='input_e1')\n","        self.input_e2 = tf.placeholder(tf.int32, shape=[None, ], name='input_e2')\n","        self.input_p1 = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_p1')\n","        self.input_p2 = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_p2')\n","        self.emb_dropout_keep_prob = tf.placeholder(tf.float32, name='emb_dropout_keep_prob')\n","        self.rnn_dropout_keep_prob = tf.placeholder(tf.float32, name='rnn_dropout_keep_prob')\n","        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n","\n","        if use_elmo:\n","            # Contextual Embedding Layer\n","            with tf.variable_scope(\"elmo-embeddings\"):\n","                elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","                self.embedded_chars = elmo_model(self.input_text, signature=\"default\", as_dict=True)[\"elmo\"]\n","        else:\n","            # Word Embedding Layer\n","            with tf.device('/cpu:0'), tf.variable_scope(\"word-embeddings\"):\n","                self.W_text = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -0.25, 0.25), name=\"W_text\")\n","                self.embedded_chars = tf.nn.embedding_lookup(self.W_text, self.input_x)\n","\n","        # Position Embedding Layer\n","        with tf.device('/cpu:0'), tf.variable_scope(\"position-embeddings\"):\n","            self.W_pos = tf.get_variable(\"W_pos\", [pos_vocab_size, pos_embedding_size], initializer=initializer())\n","            self.p1 = tf.nn.embedding_lookup(self.W_pos, self.input_p1)[:, :tf.shape(self.embedded_chars)[1]]\n","            self.p2 = tf.nn.embedding_lookup(self.W_pos, self.input_p2)[:, :tf.shape(self.embedded_chars)[1]]\n","\n","        # Dropout for Word Embedding\n","        with tf.variable_scope('dropout-embeddings'):\n","            self.embedded_chars = tf.nn.dropout(self.embedded_chars,  self.emb_dropout_keep_prob)\n","\n","        # Self Attention\n","        with tf.variable_scope(\"self-attention\"):\n","            self.self_attn, self.self_alphas = multihead_attention(self.embedded_chars, self.embedded_chars,\n","                                                                   num_units=embedding_size, num_heads=num_heads)\n","\n","        # Bidirectional LSTM\n","        with tf.variable_scope(\"bi-lstm\"):\n","            _fw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size, initializer=initializer())\n","            fw_cell = tf.nn.rnn_cell.DropoutWrapper(_fw_cell, self.rnn_dropout_keep_prob)\n","            _bw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size, initializer=initializer())\n","            bw_cell = tf.nn.rnn_cell.DropoutWrapper(_bw_cell, self.rnn_dropout_keep_prob)\n","            self.rnn_outputs, _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_cell,\n","                                                                  cell_bw=bw_cell,\n","                                                                  inputs=self.self_attn,\n","                                                                  sequence_length=self._length(self.input_x),\n","                                                                  dtype=tf.float32)\n","            self.rnn_outputs = tf.concat(self.rnn_outputs, axis=-1)\n","\n","        # Attention\n","        with tf.variable_scope('attention'):\n","            self.attn, self.alphas, self.e1_alphas, self.e2_alphas = attention(self.rnn_outputs,\n","                                                                               self.input_e1, self.input_e2,\n","                                                                               self.p1, self.p2,\n","                                                                               attention_size=attention_size)\n","\n","        # Dropout\n","        with tf.variable_scope('dropout'):\n","            self.h_drop = tf.nn.dropout(self.attn, self.dropout_keep_prob)\n","\n","        # Fully connected layer\n","        with tf.variable_scope('output'):\n","            self.logits = tf.layers.dense(self.h_drop, num_classes, kernel_initializer=initializer())\n","            self.predictions = tf.argmax(self.logits, 1, name=\"predictions\")\n","\n","        # Calculate mean cross-entropy loss\n","        with tf.variable_scope(\"loss\"):\n","            losses = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.input_y)\n","            self.l2 = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n","            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * self.l2\n","\n","        # Accuracy\n","        with tf.variable_scope(\"accuracy\"):\n","            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n","            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name=\"accuracy\")\n","\n","    # Length of the sequence data\n","    @staticmethod\n","    def _length(seq):\n","        relevant = tf.sign(tf.abs(seq))\n","        length = tf.reduce_sum(relevant, reduction_indices=1)\n","        length = tf.cast(length, tf.int32)\n","        return length"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vib4Jq5buyhz","colab_type":"code","outputId":"7046895e-8de6-4540-f40e-5ed375bd1695","colab":{"base_uri":"https://localhost:8080/","height":93074}},"cell_type":"code","source":["with tf.Graph().as_default():\n","  session_conf = tf.ConfigProto(\n","      allow_soft_placement=FLAGS.allow_soft_placement,\n","      log_device_placement=FLAGS.log_device_placement)\n","  session_conf.gpu_options.allow_growth = FLAGS.gpu_allow_growth\n","  sess = tf.Session(config=session_conf)\n","  with sess.as_default():\n","    model = EntityAttentionLSTM(\n","        sequence_length=x_train.shape[1],\n","        num_classes=y_train.shape[1],\n","        vocab_size=len(vocab_processor.vocabulary_),\n","        embedding_size=FLAGS.embedding_size,\n","        pos_vocab_size=len(pos_vocab_processor.vocabulary_),\n","        pos_embedding_size=FLAGS.pos_embedding_size,\n","        hidden_size=FLAGS.hidden_size,\n","        num_heads=FLAGS.num_heads,\n","        attention_size=FLAGS.attention_size,\n","        use_elmo=(FLAGS.embeddings == 'elmo'),\n","        l2_reg_lambda=FLAGS.l2_reg_lambda)\n","\n","    # Define Training procedure\n","    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n","    optimizer = tf.train.AdadeltaOptimizer(FLAGS.learning_rate, FLAGS.decay_rate, 1e-6)\n","    gvs = optimizer.compute_gradients(model.loss)\n","    capped_gvs = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in gvs]\n","    train_op = optimizer.apply_gradients(capped_gvs, global_step=global_step)\n","\n","    # Output directory for models and summaries\n","    timestamp = str(int(time.time()))\n","    out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n","    print(\"\\nWriting to {}\\n\".format(out_dir))\n","\n","    # Logger\n","    logger = Logger(out_dir)\n","\n","    # Summaries for loss and accuracy\n","    loss_summary = tf.summary.scalar(\"loss\", model.loss)\n","    acc_summary = tf.summary.scalar(\"accuracy\", model.accuracy)\n","\n","    # Train Summaries\n","    train_summary_op = tf.summary.merge([loss_summary, acc_summary])\n","    train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n","    train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n","\n","    # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n","    checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))[9:]\n","    print(checkpoint_dir)\n","    checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","    saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n","\n","    # Write vocabulary\n","    vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n","    pos_vocab_processor.save(os.path.join(out_dir, \"pos_vocab\"))\n","\n","    # Initialize all variables\n","    sess.run(tf.global_variables_initializer())\n","\n","    if FLAGS.embeddings == \"word2vec\":\n","        pretrain_W = load_word2vec('drive/My Drive/INFO7374/Assignment4/resource/GoogleNews-vectors-negative300.bin', FLAGS.embedding_size, vocab_processor)\n","        sess.run(model.W_text.assign(pretrain_W))\n","        print(\"Success to load pre-trained word2vec model!\\n\")\n","    elif FLAGS.embeddings == \"glove100\":\n","        pretrain_W = load_glove('drive/My Drive/INFO7374/Assignment4/resource/glove.6B.100d.txt', FLAGS.embedding_size, vocab_processor)\n","        sess.run(model.W_text.assign(pretrain_W))\n","        print(\"Success to load pre-trained glove100 model!\\n\")\n","    elif FLAGS.embeddings == \"glove300\":\n","        pretrain_W = load_glove('drive/My Drive/INFO7374/Assignment4/resource/glove.840B.300d.txt', FLAGS.embedding_size, vocab_processor)\n","        sess.run(model.W_text.assign(pretrain_W))\n","        print(\"Success to load pre-trained glove300 model!\\n\")\n","    \n","    sess.run(model.W_text.assign(pretrain_W))    \n","    \n","    # Generate batches\n","    train_batches = batch_iter(list(zip(x_train, y_train, text_train,\n","                                                     train_e1, train_e2, train_p1, train_p2)),\n","                                            FLAGS.batch_size, FLAGS.num_epochs)\n","    # Training loop. For each batch...\n","    best_f1 = 0.0  # For save checkpoint(model)\n","    for train_batch in train_batches:\n","        train_bx, train_by, train_btxt, train_be1, train_be2, train_bp1, train_bp2 = zip(*train_batch)\n","        feed_dict = {\n","            model.input_x: train_bx,\n","            model.input_y: train_by,\n","            model.input_text: train_btxt,\n","            model.input_e1: train_be1,\n","            model.input_e2: train_be2,\n","            model.input_p1: train_bp1,\n","            model.input_p2: train_bp2,\n","            model.emb_dropout_keep_prob: FLAGS.emb_dropout_keep_prob,\n","            model.rnn_dropout_keep_prob: FLAGS.rnn_dropout_keep_prob,\n","            model.dropout_keep_prob: FLAGS.dropout_keep_prob\n","        }\n","        _, step, summaries, loss, accuracy = sess.run(\n","            [train_op, global_step, train_summary_op, model.loss, model.accuracy], feed_dict)\n","        train_summary_writer.add_summary(summaries, step)\n","\n","        # Training log display\n","        if step % FLAGS.display_every == 0:\n","            logger.logging_train(step, loss, accuracy)\n","\n","        # Evaluation\n","        if step % FLAGS.evaluate_every == 0:\n","            print(\"\\nEvaluation:\")\n","            # Generate batches\n","            test_batches = batch_iter(list(zip(x_test, y_test, text_test,\n","                                                            test_e1, test_e2, test_p1, test_p2)),\n","                                                   FLAGS.batch_size, 1, shuffle=False)\n","            # Training loop. For each batch...\n","            losses = 0.0\n","            accuracy = 0.0\n","            predictions = []\n","            iter_cnt = 0\n","            for test_batch in test_batches:\n","                test_bx, test_by, test_btxt, test_be1, test_be2, test_bp1, test_bp2 = zip(*test_batch)\n","                feed_dict = {\n","                    model.input_x: test_bx,\n","                    model.input_y: test_by,\n","                    model.input_text: test_btxt,\n","                    model.input_e1: test_be1,\n","                    model.input_e2: test_be2,\n","                    model.input_p1: test_bp1,\n","                    model.input_p2: test_bp2,\n","                    model.emb_dropout_keep_prob: 1.0,\n","                    model.rnn_dropout_keep_prob: 1.0,\n","                    model.dropout_keep_prob: 1.0\n","                }\n","                loss, acc, pred = sess.run(\n","                    [model.loss, model.accuracy, model.predictions], feed_dict)\n","                losses += loss\n","                accuracy += acc\n","                predictions += pred.tolist()\n","                iter_cnt += 1\n","            losses /= iter_cnt\n","            accuracy /= iter_cnt\n","            predictions = np.array(predictions, dtype='int')\n","\n","            logger.logging_eval(step, loss, accuracy, predictions)\n","\n","            # Model checkpoint\n","            if best_f1 < logger.best_f1:\n","                best_f1 = logger.best_f1\n","                path = saver.save(sess, checkpoint_prefix+\"-{:.3g}\".format(best_f1), global_step=step)\n","                print(\"Saved model checkpoint to {}\\n\".format(path))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-27-405d1c558ebf>:37: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-24-5ce9c3177aae>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:From <ipython-input-24-5ce9c3177aae>:38: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From <ipython-input-27-405d1c558ebf>:46: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-27-405d1c558ebf>:54: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","\n","Writing to /content/runs/1554407263\n","\n","runs/1554407263/checkpoints\n","Load glove file drive/My Drive/INFO7374/Assignment4/resource/glove.840B.300d.txt\n","Success to load pre-trained glove300 model!\n","\n","2019-04-04T19:51:21.600890: step 10, loss 7.70561, acc 0.25\n","2019-04-04T19:51:24.082883: step 20, loss 7.49838, acc 0.3\n","2019-04-04T19:51:26.328845: step 30, loss 7.6413, acc 0.2\n","2019-04-04T19:51:28.669275: step 40, loss 7.17912, acc 0.35\n","2019-04-04T19:51:31.111250: step 50, loss 7.50701, acc 0.25\n","2019-04-04T19:51:33.613092: step 60, loss 6.55504, acc 0.55\n","2019-04-04T19:51:36.118575: step 70, loss 6.94825, acc 0.4\n","2019-04-04T19:51:38.809489: step 80, loss 6.48497, acc 0.45\n","2019-04-04T19:51:41.295755: step 90, loss 6.46988, acc 0.5\n","2019-04-04T19:51:43.799313: step 100, loss 6.42015, acc 0.45\n","\n","Evaluation:\n","2019-04-04T19:51:54.478677: step 100, loss 6.74913, acc 0.58949\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 63.28%, Best = 63.28%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-63.3-100\n","\n","2019-04-04T19:51:58.485674: step 110, loss 6.20422, acc 0.6\n","2019-04-04T19:52:00.994449: step 120, loss 6.58101, acc 0.55\n","2019-04-04T19:52:03.479752: step 130, loss 6.00134, acc 0.65\n","2019-04-04T19:52:05.726895: step 140, loss 6.79001, acc 0.45\n","2019-04-04T19:52:08.041049: step 150, loss 6.683, acc 0.4\n","2019-04-04T19:52:10.434828: step 160, loss 6.17269, acc 0.6\n","2019-04-04T19:52:12.719279: step 170, loss 5.98626, acc 0.65\n","2019-04-04T19:52:15.251894: step 180, loss 5.6697, acc 0.8\n","2019-04-04T19:52:17.559441: step 190, loss 5.87199, acc 0.75\n","2019-04-04T19:52:19.992513: step 200, loss 6.58095, acc 0.55\n","\n","Evaluation:\n","2019-04-04T19:52:30.364555: step 200, loss 6.37909, acc 0.649243\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 69.39%, Best = 69.39%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-69.4-200\n","\n","2019-04-04T19:52:33.892142: step 210, loss 6.43404, acc 0.55\n","2019-04-04T19:52:36.218894: step 220, loss 6.75614, acc 0.35\n","2019-04-04T19:52:38.757442: step 230, loss 6.28919, acc 0.5\n","2019-04-04T19:52:41.330297: step 240, loss 6.66252, acc 0.4\n","2019-04-04T19:52:43.679334: step 250, loss 7.11776, acc 0.45\n","2019-04-04T19:52:46.014620: step 260, loss 6.20534, acc 0.55\n","2019-04-04T19:52:48.170958: step 270, loss 6.32071, acc 0.55\n","2019-04-04T19:52:50.757468: step 280, loss 6.42769, acc 0.55\n","2019-04-04T19:52:53.127700: step 290, loss 6.28159, acc 0.55\n","2019-04-04T19:52:55.356210: step 300, loss 6.53557, acc 0.5\n","\n","Evaluation:\n","2019-04-04T19:53:05.627084: step 300, loss 6.4007, acc 0.664987\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 71.99%, Best = 71.99%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-72-300\n","\n","2019-04-04T19:53:09.076063: step 310, loss 5.94371, acc 0.65\n","2019-04-04T19:53:11.433503: step 320, loss 6.06082, acc 0.6\n","2019-04-04T19:53:13.889168: step 330, loss 5.85538, acc 0.65\n","2019-04-04T19:53:16.307140: step 340, loss 6.13739, acc 0.6\n","2019-04-04T19:53:18.588942: step 350, loss 5.74251, acc 0.7\n","2019-04-04T19:53:20.989913: step 360, loss 6.13672, acc 0.6\n","2019-04-04T19:53:23.238413: step 370, loss 5.93787, acc 0.65\n","2019-04-04T19:53:25.619170: step 380, loss 5.75355, acc 0.65\n","2019-04-04T19:53:27.994513: step 390, loss 5.79472, acc 0.8\n","2019-04-04T19:53:30.523434: step 400, loss 6.02908, acc 0.75\n","\n","Evaluation:\n","2019-04-04T19:53:40.797449: step 400, loss 6.2171, acc 0.717625\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 76.22%, Best = 76.22%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-76.2-400\n","\n","2019-04-04T19:53:44.087202: step 410, loss 5.75513, acc 0.65\n","2019-04-04T19:53:46.423599: step 420, loss 6.06426, acc 0.65\n","2019-04-04T19:53:48.823102: step 430, loss 6.65146, acc 0.5\n","2019-04-04T19:53:51.431232: step 440, loss 5.67892, acc 0.75\n","2019-04-04T19:53:53.943535: step 450, loss 5.75496, acc 0.65\n","2019-04-04T19:53:56.411580: step 460, loss 5.67538, acc 0.7\n","2019-04-04T19:53:58.771145: step 470, loss 6.13822, acc 0.6\n","2019-04-04T19:54:01.145963: step 480, loss 5.99433, acc 0.65\n","2019-04-04T19:54:03.504698: step 490, loss 5.45564, acc 0.85\n","2019-04-04T19:54:05.880681: step 500, loss 6.07516, acc 0.6\n","\n","Evaluation:\n","2019-04-04T19:54:16.144877: step 500, loss 6.17389, acc 0.708802\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 76.66%, Best = 76.66%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-76.7-500\n","\n","2019-04-04T19:54:19.414613: step 510, loss 5.69635, acc 0.65\n","2019-04-04T19:54:21.695275: step 520, loss 5.7179, acc 0.8\n","2019-04-04T19:54:23.941356: step 530, loss 5.76807, acc 0.7\n","2019-04-04T19:54:26.387616: step 540, loss 5.66001, acc 0.75\n","2019-04-04T19:54:28.780194: step 550, loss 5.7079, acc 0.75\n","2019-04-04T19:54:31.187484: step 560, loss 5.77278, acc 0.7\n","2019-04-04T19:54:33.574686: step 570, loss 5.41662, acc 0.85\n","2019-04-04T19:54:35.976171: step 580, loss 5.91502, acc 0.7\n","2019-04-04T19:54:38.550372: step 590, loss 6.17533, acc 0.55\n","2019-04-04T19:54:41.176409: step 600, loss 5.71434, acc 0.75\n","\n","Evaluation:\n","2019-04-04T19:54:51.455684: step 600, loss 6.50128, acc 0.72939\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 77.8%, Best = 77.8%\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","Saved model checkpoint to runs/1554407263/checkpoints/model-77.8-600\n","\n","2019-04-04T19:54:54.651461: step 610, loss 6.10549, acc 0.7\n","2019-04-04T19:54:57.275749: step 620, loss 5.53997, acc 0.8\n","2019-04-04T19:54:59.786513: step 630, loss 5.53118, acc 0.75\n","2019-04-04T19:55:02.437622: step 640, loss 5.83335, acc 0.75\n","2019-04-04T19:55:04.742453: step 650, loss 5.98573, acc 0.6\n","2019-04-04T19:55:06.946718: step 660, loss 5.67964, acc 0.8\n","2019-04-04T19:55:09.154137: step 670, loss 5.91448, acc 0.7\n","2019-04-04T19:55:11.535751: step 680, loss 5.89821, acc 0.65\n","2019-04-04T19:55:13.917011: step 690, loss 5.8037, acc 0.8\n","2019-04-04T19:55:16.189442: step 700, loss 5.84547, acc 0.75\n","\n","Evaluation:\n","2019-04-04T19:55:26.506411: step 700, loss 6.18622, acc 0.758499\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 80.06%, Best = 80.06%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-80.1-700\n","\n","2019-04-04T19:55:29.785054: step 710, loss 5.62759, acc 0.75\n","2019-04-04T19:55:32.295839: step 720, loss 6.02327, acc 0.6\n","2019-04-04T19:55:34.630511: step 730, loss 5.90535, acc 0.7\n","2019-04-04T19:55:37.011140: step 740, loss 6.02384, acc 0.65\n","2019-04-04T19:55:39.532741: step 750, loss 5.87853, acc 0.7\n","2019-04-04T19:55:41.889476: step 760, loss 5.37667, acc 0.9\n","2019-04-04T19:55:44.166311: step 770, loss 5.99398, acc 0.75\n","2019-04-04T19:55:46.640088: step 780, loss 5.51678, acc 0.8\n","2019-04-04T19:55:49.247372: step 790, loss 5.89812, acc 0.65\n","2019-04-04T19:55:51.636222: step 800, loss 5.44426, acc 0.85\n","\n","Evaluation:\n","2019-04-04T19:56:01.957872: step 800, loss 6.15573, acc 0.750779\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 79.63%, Best = 80.06%\n","\n","2019-04-04T19:56:04.375857: step 810, loss 5.74198, acc 0.6\n","2019-04-04T19:56:07.011733: step 820, loss 5.39487, acc 0.85\n","2019-04-04T19:56:09.685651: step 830, loss 5.92625, acc 0.7\n","2019-04-04T19:56:12.019732: step 840, loss 6.36876, acc 0.55\n","2019-04-04T19:56:14.386208: step 850, loss 5.65662, acc 0.8\n","2019-04-04T19:56:16.828176: step 860, loss 5.77026, acc 0.75\n","2019-04-04T19:56:19.182054: step 870, loss 5.78457, acc 0.7\n","2019-04-04T19:56:21.476082: step 880, loss 5.60086, acc 0.8\n","2019-04-04T19:56:23.930295: step 890, loss 5.60929, acc 0.7\n","2019-04-04T19:56:26.495137: step 900, loss 5.62829, acc 0.7\n","\n","Evaluation:\n","2019-04-04T19:56:36.823643: step 900, loss 5.98048, acc 0.762976\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 80.92%, Best = 80.92%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-80.9-900\n","\n","2019-04-04T19:56:39.877917: step 910, loss 5.35991, acc 0.85\n","2019-04-04T19:56:42.380008: step 920, loss 5.82595, acc 0.7\n","2019-04-04T19:56:44.850840: step 930, loss 5.56199, acc 0.8\n","2019-04-04T19:56:47.439672: step 940, loss 5.3082, acc 0.85\n","2019-04-04T19:56:49.764536: step 950, loss 5.77734, acc 0.6\n","2019-04-04T19:56:51.950966: step 960, loss 5.37255, acc 0.85\n","2019-04-04T19:56:54.468541: step 970, loss 5.35935, acc 0.85\n","2019-04-04T19:56:56.809173: step 980, loss 5.64686, acc 0.7\n","2019-04-04T19:56:59.058642: step 990, loss 5.91783, acc 0.8\n","2019-04-04T19:57:01.509624: step 1000, loss 5.19984, acc 0.9\n","\n","Evaluation:\n","2019-04-04T19:57:11.797859: step 1000, loss 6.21612, acc 0.762543\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 80.66%, Best = 80.92%\n","\n","2019-04-04T19:57:14.133724: step 1010, loss 5.97141, acc 0.45\n","2019-04-04T19:57:16.524526: step 1020, loss 5.69689, acc 0.7\n","2019-04-04T19:57:18.885469: step 1030, loss 5.78614, acc 0.65\n","2019-04-04T19:57:21.506548: step 1040, loss 5.51024, acc 0.85\n","2019-04-04T19:57:23.913509: step 1050, loss 5.899, acc 0.5\n","2019-04-04T19:57:26.346235: step 1060, loss 5.53948, acc 0.75\n","2019-04-04T19:57:28.827131: step 1070, loss 5.60426, acc 0.65\n","2019-04-04T19:57:31.037774: step 1080, loss 5.60956, acc 0.85\n","2019-04-04T19:57:33.423939: step 1090, loss 5.76844, acc 0.7\n","2019-04-04T19:57:35.732665: step 1100, loss 5.43851, acc 0.85\n","\n","Evaluation:\n","2019-04-04T19:57:46.018446: step 1100, loss 6.02989, acc 0.766285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 81.1%, Best = 81.1%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-81.1-1100\n","\n","2019-04-04T19:57:49.221051: step 1110, loss 5.63595, acc 0.8\n","2019-04-04T19:57:51.762054: step 1120, loss 5.61817, acc 0.75\n","2019-04-04T19:57:53.916185: step 1130, loss 5.79474, acc 0.75\n","2019-04-04T19:57:56.160909: step 1140, loss 5.84751, acc 0.65\n","2019-04-04T19:57:58.457837: step 1150, loss 6.24703, acc 0.55\n","2019-04-04T19:58:00.846691: step 1160, loss 5.86149, acc 0.7\n","2019-04-04T19:58:03.370605: step 1170, loss 5.41347, acc 0.8\n","2019-04-04T19:58:05.797517: step 1180, loss 5.69512, acc 0.75\n","2019-04-04T19:58:08.236390: step 1190, loss 5.42551, acc 0.85\n","2019-04-04T19:58:10.768439: step 1200, loss 5.76288, acc 0.7\n","\n","Evaluation:\n","2019-04-04T19:58:21.097503: step 1200, loss 6.04341, acc 0.768858\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 81.17%, Best = 81.17%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-81.2-1200\n","\n","2019-04-04T19:58:24.393697: step 1210, loss 5.47429, acc 0.85\n","2019-04-04T19:58:26.671730: step 1220, loss 5.10611, acc 0.95\n","2019-04-04T19:58:28.988772: step 1230, loss 5.55433, acc 0.75\n","2019-04-04T19:58:31.441134: step 1240, loss 5.34288, acc 0.85\n","2019-04-04T19:58:33.674297: step 1250, loss 5.65287, acc 0.75\n","2019-04-04T19:58:36.122209: step 1260, loss 5.35611, acc 0.75\n","2019-04-04T19:58:38.614600: step 1270, loss 5.26986, acc 0.8\n","2019-04-04T19:58:40.896835: step 1280, loss 5.36596, acc 0.9\n","2019-04-04T19:58:43.280898: step 1290, loss 5.34208, acc 0.85\n","2019-04-04T19:58:45.764021: step 1300, loss 5.33973, acc 0.85\n","\n","Evaluation:\n","2019-04-04T19:58:56.106675: step 1300, loss 5.95003, acc 0.777249\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 81.81%, Best = 81.81%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-81.8-1300\n","\n","2019-04-04T19:58:59.406190: step 1310, loss 5.26328, acc 0.85\n","2019-04-04T19:59:01.931250: step 1320, loss 5.8172, acc 0.6\n","2019-04-04T19:59:04.264569: step 1330, loss 5.38905, acc 0.8\n","2019-04-04T19:59:06.552218: step 1340, loss 5.74954, acc 0.65\n","2019-04-04T19:59:09.100783: step 1350, loss 5.37503, acc 0.8\n","2019-04-04T19:59:11.538768: step 1360, loss 5.37039, acc 0.8\n","2019-04-04T19:59:13.922792: step 1370, loss 5.35368, acc 0.8\n","2019-04-04T19:59:16.363980: step 1380, loss 5.25642, acc 0.8\n","2019-04-04T19:59:18.867439: step 1390, loss 5.25116, acc 0.9\n","2019-04-04T19:59:21.154900: step 1400, loss 5.47611, acc 0.8\n","\n","Evaluation:\n","2019-04-04T19:59:31.432285: step 1400, loss 6.03517, acc 0.77394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 81.61%, Best = 81.81%\n","\n","2019-04-04T19:59:33.860587: step 1410, loss 5.12573, acc 0.85\n","2019-04-04T19:59:36.259429: step 1420, loss 5.0082, acc 0.95\n","2019-04-04T19:59:38.700850: step 1430, loss 5.33185, acc 0.85\n","2019-04-04T19:59:41.123628: step 1440, loss 5.73216, acc 0.7\n","2019-04-04T19:59:43.473632: step 1450, loss 5.77973, acc 0.6\n","2019-04-04T19:59:46.096215: step 1460, loss 5.91792, acc 0.65\n","2019-04-04T19:59:48.605705: step 1470, loss 5.31383, acc 0.8\n","2019-04-04T19:59:51.148675: step 1480, loss 5.45852, acc 0.75\n","2019-04-04T19:59:53.764235: step 1490, loss 5.61122, acc 0.75\n","2019-04-04T19:59:56.247446: step 1500, loss 5.43636, acc 0.8\n","\n","Evaluation:\n","2019-04-04T20:00:06.513563: step 1500, loss 6.00981, acc 0.769529\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 81.13%, Best = 81.81%\n","\n","2019-04-04T20:00:08.608935: step 1510, loss 5.08893, acc 0.95\n","2019-04-04T20:00:10.879730: step 1520, loss 5.34861, acc 0.8\n","2019-04-04T20:00:13.583200: step 1530, loss 5.23558, acc 0.95\n","2019-04-04T20:00:15.822949: step 1540, loss 5.26356, acc 0.85\n","2019-04-04T20:00:18.180833: step 1550, loss 5.42625, acc 0.8\n","2019-04-04T20:00:20.335507: step 1560, loss 5.59825, acc 0.7\n","2019-04-04T20:00:22.650814: step 1570, loss 5.33393, acc 0.85\n","2019-04-04T20:00:24.967699: step 1580, loss 5.36312, acc 0.75\n","2019-04-04T20:00:27.207661: step 1590, loss 5.4491, acc 0.85\n","2019-04-04T20:00:29.590319: step 1600, loss 5.21404, acc 0.8\n","\n","Evaluation:\n","2019-04-04T20:00:39.818056: step 1600, loss 5.87597, acc 0.78099\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.33%, Best = 82.33%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-82.3-1600\n","\n","2019-04-04T20:00:43.286011: step 1610, loss 5.15691, acc 0.95\n","2019-04-04T20:00:45.943693: step 1620, loss 5.1776, acc 0.95\n","2019-04-04T20:00:48.388328: step 1630, loss 5.23718, acc 0.85\n","2019-04-04T20:00:50.693279: step 1640, loss 5.37378, acc 0.8\n","2019-04-04T20:00:52.949645: step 1650, loss 5.04465, acc 0.95\n","2019-04-04T20:00:55.275173: step 1660, loss 5.86593, acc 0.7\n","2019-04-04T20:00:57.542525: step 1670, loss 5.21642, acc 0.85\n","2019-04-04T20:00:59.883788: step 1680, loss 5.43103, acc 0.75\n","2019-04-04T20:01:02.146396: step 1690, loss 5.11512, acc 0.9\n","2019-04-04T20:01:04.574350: step 1700, loss 5.43162, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:01:14.824370: step 1700, loss 5.89074, acc 0.776146\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.18%, Best = 82.33%\n","\n","2019-04-04T20:01:17.176668: step 1710, loss 5.34395, acc 0.8\n","2019-04-04T20:01:19.565306: step 1720, loss 4.95259, acc 0.95\n","2019-04-04T20:01:21.906985: step 1730, loss 5.27195, acc 0.85\n","2019-04-04T20:01:24.264212: step 1740, loss 5.38103, acc 0.85\n","2019-04-04T20:01:26.785402: step 1750, loss 5.15249, acc 0.8\n","2019-04-04T20:01:29.123628: step 1760, loss 5.03096, acc 0.95\n","2019-04-04T20:01:31.537685: step 1770, loss 5.05012, acc 0.9\n","2019-04-04T20:01:33.810640: step 1780, loss 5.61449, acc 0.7\n","2019-04-04T20:01:36.158360: step 1790, loss 5.42826, acc 0.9\n","2019-04-04T20:01:38.822536: step 1800, loss 5.64428, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:01:49.106889: step 1800, loss 5.84438, acc 0.784667\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 82.81%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-82.8-1800\n","\n","2019-04-04T20:01:52.551688: step 1810, loss 4.98262, acc 0.95\n","2019-04-04T20:01:54.918391: step 1820, loss 5.34171, acc 0.75\n","2019-04-04T20:01:57.549392: step 1830, loss 5.83558, acc 0.65\n","2019-04-04T20:01:59.871483: step 1840, loss 4.99549, acc 0.95\n","2019-04-04T20:02:02.323825: step 1850, loss 5.16222, acc 0.9\n","2019-04-04T20:02:04.688628: step 1860, loss 5.06709, acc 0.95\n","2019-04-04T20:02:06.967431: step 1870, loss 5.13419, acc 0.85\n","2019-04-04T20:02:09.432481: step 1880, loss 5.43141, acc 0.7\n","2019-04-04T20:02:11.883619: step 1890, loss 5.45401, acc 0.7\n","2019-04-04T20:02:14.223854: step 1900, loss 5.33435, acc 0.8\n","\n","Evaluation:\n","2019-04-04T20:02:24.473102: step 1900, loss 5.8913, acc 0.79827\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.48%, Best = 83.48%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-83.5-1900\n","\n","2019-04-04T20:02:27.621335: step 1910, loss 4.9533, acc 0.95\n","2019-04-04T20:02:29.944341: step 1920, loss 5.50875, acc 0.85\n","2019-04-04T20:02:32.495452: step 1930, loss 5.48331, acc 0.8\n","2019-04-04T20:02:34.830390: step 1940, loss 5.38349, acc 0.75\n","2019-04-04T20:02:37.219558: step 1950, loss 5.1741, acc 0.85\n","2019-04-04T20:02:39.542992: step 1960, loss 5.69227, acc 0.8\n","2019-04-04T20:02:41.840638: step 1970, loss 4.98352, acc 1\n","2019-04-04T20:02:44.221542: step 1980, loss 4.99911, acc 0.95\n","2019-04-04T20:02:46.876908: step 1990, loss 5.49225, acc 0.75\n","2019-04-04T20:02:49.224943: step 2000, loss 5.36926, acc 0.75\n","\n","Evaluation:\n","2019-04-04T20:02:59.573889: step 2000, loss 6.07975, acc 0.785402\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.49%, Best = 83.48%\n","\n","2019-04-04T20:03:02.001055: step 2010, loss 5.14127, acc 0.9\n","2019-04-04T20:03:04.387776: step 2020, loss 4.99927, acc 0.95\n","2019-04-04T20:03:06.678190: step 2030, loss 5.19647, acc 0.8\n","2019-04-04T20:03:09.040230: step 2040, loss 5.25792, acc 0.85\n","2019-04-04T20:03:11.344395: step 2050, loss 5.43881, acc 0.7\n","2019-04-04T20:03:13.681443: step 2060, loss 4.98435, acc 0.9\n","2019-04-04T20:03:16.042367: step 2070, loss 5.38832, acc 0.8\n","2019-04-04T20:03:18.441647: step 2080, loss 5.2814, acc 0.75\n","2019-04-04T20:03:20.953292: step 2090, loss 5.27594, acc 0.9\n","2019-04-04T20:03:23.473919: step 2100, loss 5.1048, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:03:33.729831: step 2100, loss 6.00087, acc 0.77952\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.17%, Best = 83.48%\n","\n","2019-04-04T20:03:36.087615: step 2110, loss 5.78273, acc 0.8\n","2019-04-04T20:03:38.517442: step 2120, loss 5.33966, acc 0.9\n","2019-04-04T20:03:40.815669: step 2130, loss 5.28841, acc 0.85\n","2019-04-04T20:03:43.166846: step 2140, loss 5.44956, acc 0.7\n","2019-04-04T20:03:45.515497: step 2150, loss 5.00794, acc 0.9\n","2019-04-04T20:03:47.911705: step 2160, loss 5.44722, acc 0.7\n","2019-04-04T20:03:50.384125: step 2170, loss 5.11875, acc 0.85\n","2019-04-04T20:03:52.818661: step 2180, loss 4.97474, acc 0.95\n","2019-04-04T20:03:55.271446: step 2190, loss 5.14381, acc 0.9\n","2019-04-04T20:03:57.666200: step 2200, loss 5.04041, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:04:07.914101: step 2200, loss 5.91833, acc 0.789814\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.48%\n","\n","2019-04-04T20:04:10.388716: step 2210, loss 5.32256, acc 0.75\n","2019-04-04T20:04:12.655804: step 2220, loss 5.65058, acc 0.75\n","2019-04-04T20:04:15.076898: step 2230, loss 5.2375, acc 0.85\n","2019-04-04T20:04:17.484750: step 2240, loss 5.45201, acc 0.65\n","2019-04-04T20:04:19.834648: step 2250, loss 5.08503, acc 0.9\n","2019-04-04T20:04:22.391499: step 2260, loss 4.92936, acc 0.95\n","2019-04-04T20:04:24.723866: step 2270, loss 4.94002, acc 1\n","2019-04-04T20:04:27.031254: step 2280, loss 5.72043, acc 0.7\n","2019-04-04T20:04:29.484213: step 2290, loss 5.63518, acc 0.65\n","2019-04-04T20:04:31.968685: step 2300, loss 5.2833, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:04:42.184407: step 2300, loss 5.98941, acc 0.790484\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.26%, Best = 83.48%\n","\n","2019-04-04T20:04:44.642605: step 2310, loss 5.35994, acc 0.75\n","2019-04-04T20:04:46.937729: step 2320, loss 5.15764, acc 0.85\n","2019-04-04T20:04:49.308934: step 2330, loss 4.98191, acc 0.8\n","2019-04-04T20:04:51.824785: step 2340, loss 5.6888, acc 0.75\n","2019-04-04T20:04:54.155418: step 2350, loss 5.07207, acc 0.8\n","2019-04-04T20:04:56.585543: step 2360, loss 5.23919, acc 0.8\n","2019-04-04T20:04:58.800056: step 2370, loss 5.2301, acc 0.85\n","2019-04-04T20:05:01.362691: step 2380, loss 5.4497, acc 0.7\n","2019-04-04T20:05:03.837411: step 2390, loss 5.20301, acc 0.75\n","2019-04-04T20:05:06.124662: step 2400, loss 5.18292, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:05:16.378079: step 2400, loss 5.9907, acc 0.796432\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.64%, Best = 83.64%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-83.6-2400\n","\n","2019-04-04T20:05:19.562960: step 2410, loss 5.04704, acc 0.9\n","2019-04-04T20:05:21.930714: step 2420, loss 5.22316, acc 0.8\n","2019-04-04T20:05:24.323310: step 2430, loss 4.97468, acc 0.9\n","2019-04-04T20:05:26.805705: step 2440, loss 5.21017, acc 0.9\n","2019-04-04T20:05:29.297719: step 2450, loss 5.04011, acc 0.85\n","2019-04-04T20:05:31.558083: step 2460, loss 5.2396, acc 0.8\n","2019-04-04T20:05:33.927440: step 2470, loss 5.29203, acc 0.9\n","2019-04-04T20:05:36.180892: step 2480, loss 4.97944, acc 0.95\n","2019-04-04T20:05:38.459665: step 2490, loss 5.00616, acc 0.9\n","2019-04-04T20:05:40.849104: step 2500, loss 4.99477, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:05:51.115126: step 2500, loss 6.18537, acc 0.796129\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.62%, Best = 83.64%\n","\n","2019-04-04T20:05:53.630496: step 2510, loss 5.18419, acc 0.8\n","2019-04-04T20:05:55.934514: step 2520, loss 4.97756, acc 0.95\n","2019-04-04T20:05:58.457344: step 2530, loss 5.03737, acc 0.9\n","2019-04-04T20:06:00.654462: step 2540, loss 5.16616, acc 0.95\n","2019-04-04T20:06:03.068100: step 2550, loss 5.20278, acc 0.85\n","2019-04-04T20:06:05.282887: step 2560, loss 4.86873, acc 1\n","2019-04-04T20:06:07.691516: step 2570, loss 4.9926, acc 0.85\n","2019-04-04T20:06:09.924649: step 2580, loss 4.8706, acc 0.95\n","2019-04-04T20:06:12.395398: step 2590, loss 5.46778, acc 0.7\n","2019-04-04T20:06:14.715855: step 2600, loss 5.25222, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:06:24.606991: step 2600, loss 6.24971, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.44%, Best = 83.64%\n","\n","2019-04-04T20:06:27.124497: step 2610, loss 5.23383, acc 0.75\n","2019-04-04T20:06:29.552402: step 2620, loss 5.2759, acc 0.8\n","2019-04-04T20:06:31.901736: step 2630, loss 5.11181, acc 0.9\n","2019-04-04T20:06:34.399288: step 2640, loss 5.07038, acc 0.9\n","2019-04-04T20:06:36.852281: step 2650, loss 5.29576, acc 0.8\n","2019-04-04T20:06:39.156631: step 2660, loss 5.08935, acc 0.85\n","2019-04-04T20:06:41.480739: step 2670, loss 4.88803, acc 0.95\n","2019-04-04T20:06:43.949052: step 2680, loss 4.84529, acc 0.95\n","2019-04-04T20:06:46.362073: step 2690, loss 4.87761, acc 0.9\n","2019-04-04T20:06:48.742498: step 2700, loss 4.94874, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:06:58.849701: step 2700, loss 6.40165, acc 0.792323\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.64%\n","\n","2019-04-04T20:07:01.273452: step 2710, loss 5.12197, acc 0.9\n","2019-04-04T20:07:03.484822: step 2720, loss 5.28211, acc 0.8\n","2019-04-04T20:07:05.719169: step 2730, loss 5.13845, acc 0.8\n","2019-04-04T20:07:08.450088: step 2740, loss 5.25731, acc 0.85\n","2019-04-04T20:07:10.764243: step 2750, loss 5.08986, acc 0.85\n","2019-04-04T20:07:13.242582: step 2760, loss 5.01761, acc 0.9\n","2019-04-04T20:07:15.426867: step 2770, loss 5.52361, acc 0.75\n","2019-04-04T20:07:17.761303: step 2780, loss 5.12633, acc 0.9\n","2019-04-04T20:07:20.204101: step 2790, loss 5.02858, acc 0.9\n","2019-04-04T20:07:22.469596: step 2800, loss 5.21204, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:07:32.685357: step 2800, loss 5.96114, acc 0.795329\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.22%, Best = 83.64%\n","\n","2019-04-04T20:07:35.068825: step 2810, loss 5.06983, acc 0.9\n","2019-04-04T20:07:37.331310: step 2820, loss 4.8503, acc 0.95\n","2019-04-04T20:07:39.814606: step 2830, loss 4.88917, acc 0.95\n","2019-04-04T20:07:42.224079: step 2840, loss 5.42473, acc 0.75\n","2019-04-04T20:07:44.501237: step 2850, loss 5.43951, acc 0.8\n","2019-04-04T20:07:46.848423: step 2860, loss 5.40206, acc 0.85\n","2019-04-04T20:07:49.210568: step 2870, loss 5.13336, acc 0.85\n","2019-04-04T20:07:51.785424: step 2880, loss 5.09181, acc 0.9\n","2019-04-04T20:07:54.080444: step 2890, loss 4.99119, acc 0.9\n","2019-04-04T20:07:56.499416: step 2900, loss 5.20989, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:08:06.500005: step 2900, loss 6.04381, acc 0.79122\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.64%\n","\n","2019-04-04T20:08:08.958450: step 2910, loss 5.37348, acc 0.75\n","2019-04-04T20:08:11.195683: step 2920, loss 4.92092, acc 0.9\n","2019-04-04T20:08:13.580732: step 2930, loss 4.92354, acc 0.9\n","2019-04-04T20:08:15.833108: step 2940, loss 4.8504, acc 0.9\n","2019-04-04T20:08:18.245255: step 2950, loss 5.32522, acc 0.85\n","2019-04-04T20:08:20.575243: step 2960, loss 4.91976, acc 0.9\n","2019-04-04T20:08:22.926866: step 2970, loss 5.15732, acc 0.75\n","2019-04-04T20:08:25.131053: step 2980, loss 4.89372, acc 0.9\n","2019-04-04T20:08:27.636674: step 2990, loss 5.03976, acc 0.8\n","2019-04-04T20:08:30.184341: step 3000, loss 4.92201, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:08:40.375089: step 3000, loss 6.2974, acc 0.795631\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.39%, Best = 83.64%\n","\n","2019-04-04T20:08:42.809889: step 3010, loss 4.90921, acc 0.9\n","2019-04-04T20:08:45.085677: step 3020, loss 4.82961, acc 1\n","2019-04-04T20:08:47.340285: step 3030, loss 5.24985, acc 0.75\n","2019-04-04T20:08:49.511839: step 3040, loss 5.22288, acc 0.9\n","2019-04-04T20:08:51.953815: step 3050, loss 5.03453, acc 0.9\n","2019-04-04T20:08:54.578650: step 3060, loss 4.86667, acc 0.95\n","2019-04-04T20:08:56.871215: step 3070, loss 4.97847, acc 0.85\n","2019-04-04T20:08:59.361434: step 3080, loss 4.83908, acc 0.95\n","2019-04-04T20:09:01.646595: step 3090, loss 5.04728, acc 0.8\n","2019-04-04T20:09:04.021315: step 3100, loss 5.15513, acc 0.8\n","\n","Evaluation:\n","2019-04-04T20:09:13.962799: step 3100, loss 6.10303, acc 0.787976\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.66%, Best = 83.64%\n","\n","2019-04-04T20:09:16.280543: step 3110, loss 4.89004, acc 0.9\n","2019-04-04T20:09:18.696075: step 3120, loss 5.04233, acc 0.95\n","2019-04-04T20:09:20.970992: step 3130, loss 5.2206, acc 0.85\n","2019-04-04T20:09:23.263780: step 3140, loss 5.08391, acc 0.8\n","2019-04-04T20:09:25.940861: step 3150, loss 5.26072, acc 0.8\n","2019-04-04T20:09:28.426103: step 3160, loss 4.89215, acc 0.9\n","2019-04-04T20:09:30.853328: step 3170, loss 5.15471, acc 0.8\n","2019-04-04T20:09:33.131406: step 3180, loss 5.02778, acc 0.85\n","2019-04-04T20:09:35.535946: step 3190, loss 4.95466, acc 0.95\n","2019-04-04T20:09:38.146499: step 3200, loss 5.23611, acc 0.8\n","\n","Evaluation:\n","2019-04-04T20:09:48.076972: step 3200, loss 5.97479, acc 0.797902\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.38%, Best = 83.64%\n","\n","2019-04-04T20:09:50.540115: step 3210, loss 5.09859, acc 0.9\n","2019-04-04T20:09:52.915337: step 3220, loss 4.72271, acc 1\n","2019-04-04T20:09:55.335468: step 3230, loss 5.09066, acc 0.85\n","2019-04-04T20:09:57.574504: step 3240, loss 5.14815, acc 0.75\n","2019-04-04T20:10:00.081038: step 3250, loss 5.16859, acc 0.85\n","2019-04-04T20:10:02.566964: step 3260, loss 4.85651, acc 0.95\n","2019-04-04T20:10:05.014634: step 3270, loss 4.77182, acc 0.95\n","2019-04-04T20:10:07.421812: step 3280, loss 4.83232, acc 0.9\n","2019-04-04T20:10:09.670472: step 3290, loss 4.79783, acc 0.95\n","2019-04-04T20:10:12.130993: step 3300, loss 4.81602, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:10:22.054349: step 3300, loss 5.97968, acc 0.787608\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.57%, Best = 83.64%\n","\n","2019-04-04T20:10:24.349933: step 3310, loss 5.0981, acc 0.8\n","2019-04-04T20:10:26.755409: step 3320, loss 5.18226, acc 0.8\n","2019-04-04T20:10:29.121918: step 3330, loss 4.8452, acc 0.95\n","2019-04-04T20:10:31.414233: step 3340, loss 4.89285, acc 0.9\n","2019-04-04T20:10:33.888465: step 3350, loss 4.84881, acc 0.9\n","2019-04-04T20:10:36.191224: step 3360, loss 4.84149, acc 0.95\n","2019-04-04T20:10:38.643329: step 3370, loss 5.03654, acc 0.85\n","2019-04-04T20:10:41.034537: step 3380, loss 4.95689, acc 0.85\n","2019-04-04T20:10:43.441416: step 3390, loss 4.82135, acc 0.95\n","2019-04-04T20:10:45.815418: step 3400, loss 5.06312, acc 0.75\n","\n","Evaluation:\n","2019-04-04T20:10:55.757099: step 3400, loss 6.02302, acc 0.788343\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.9%, Best = 83.64%\n","\n","2019-04-04T20:10:58.190729: step 3410, loss 4.9801, acc 0.8\n","2019-04-04T20:11:00.747031: step 3420, loss 4.88387, acc 0.85\n","2019-04-04T20:11:03.103045: step 3430, loss 4.85926, acc 0.9\n","2019-04-04T20:11:05.386239: step 3440, loss 4.72547, acc 1\n","2019-04-04T20:11:07.779493: step 3450, loss 5.04248, acc 0.85\n","2019-04-04T20:11:10.015681: step 3460, loss 5.29784, acc 0.75\n","2019-04-04T20:11:12.345695: step 3470, loss 4.9708, acc 0.85\n","2019-04-04T20:11:14.560357: step 3480, loss 4.76084, acc 1\n","2019-04-04T20:11:16.847582: step 3490, loss 5.0836, acc 0.8\n","2019-04-04T20:11:19.165982: step 3500, loss 4.71227, acc 1\n","\n","Evaluation:\n","2019-04-04T20:11:29.136897: step 3500, loss 6.21479, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.64%\n","\n","2019-04-04T20:11:31.568494: step 3510, loss 5.04332, acc 0.95\n","2019-04-04T20:11:33.923964: step 3520, loss 4.89251, acc 0.95\n","2019-04-04T20:11:36.553868: step 3530, loss 4.76106, acc 0.95\n","2019-04-04T20:11:39.065865: step 3540, loss 5.14496, acc 0.75\n","2019-04-04T20:11:41.377402: step 3550, loss 5.161, acc 0.8\n","2019-04-04T20:11:43.664106: step 3560, loss 4.94876, acc 0.85\n","2019-04-04T20:11:46.201926: step 3570, loss 4.857, acc 0.9\n","2019-04-04T20:11:48.750697: step 3580, loss 4.8375, acc 0.95\n","2019-04-04T20:11:50.858388: step 3590, loss 4.90096, acc 0.9\n","2019-04-04T20:11:53.272565: step 3600, loss 5.06772, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:12:03.250124: step 3600, loss 6.10183, acc 0.795999\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.33%, Best = 83.64%\n","\n","2019-04-04T20:12:05.484295: step 3610, loss 5.0119, acc 0.85\n","2019-04-04T20:12:07.913943: step 3620, loss 4.97425, acc 0.95\n","2019-04-04T20:12:10.314076: step 3630, loss 5.03052, acc 0.85\n","2019-04-04T20:12:12.673856: step 3640, loss 4.9923, acc 0.85\n","2019-04-04T20:12:15.133124: step 3650, loss 4.68062, acc 1\n","2019-04-04T20:12:17.716238: step 3660, loss 5.05065, acc 0.9\n","2019-04-04T20:12:20.240866: step 3670, loss 5.13232, acc 0.8\n","2019-04-04T20:12:22.642077: step 3680, loss 4.71701, acc 0.95\n","2019-04-04T20:12:24.951530: step 3690, loss 4.88164, acc 0.9\n","2019-04-04T20:12:27.243000: step 3700, loss 4.7922, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:12:37.209461: step 3700, loss 6.09452, acc 0.796432\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.34%, Best = 83.64%\n","\n","2019-04-04T20:12:39.707649: step 3710, loss 4.92909, acc 0.85\n","2019-04-04T20:12:42.003352: step 3720, loss 5.11275, acc 0.8\n","2019-04-04T20:12:44.274450: step 3730, loss 4.87613, acc 0.9\n","2019-04-04T20:12:46.689736: step 3740, loss 4.94876, acc 0.9\n","2019-04-04T20:12:48.980988: step 3750, loss 5.06233, acc 0.85\n","2019-04-04T20:12:51.298565: step 3760, loss 4.85957, acc 0.9\n","2019-04-04T20:12:53.733419: step 3770, loss 4.90598, acc 0.9\n","2019-04-04T20:12:56.133052: step 3780, loss 4.80341, acc 1\n","2019-04-04T20:12:58.433131: step 3790, loss 4.83382, acc 0.95\n","2019-04-04T20:13:00.876850: step 3800, loss 4.7611, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:13:10.803049: step 3800, loss 5.99119, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.78%, Best = 83.64%\n","\n","2019-04-04T20:13:13.337549: step 3810, loss 4.84945, acc 0.95\n","2019-04-04T20:13:15.594587: step 3820, loss 4.76799, acc 0.95\n","2019-04-04T20:13:17.917225: step 3830, loss 4.7546, acc 0.95\n","2019-04-04T20:13:20.302009: step 3840, loss 4.72407, acc 1\n","2019-04-04T20:13:22.559318: step 3850, loss 4.72313, acc 0.95\n","2019-04-04T20:13:25.094056: step 3860, loss 5.11298, acc 0.8\n","2019-04-04T20:13:27.609595: step 3870, loss 4.87722, acc 0.95\n","2019-04-04T20:13:29.961500: step 3880, loss 5.00035, acc 0.85\n","2019-04-04T20:13:32.356375: step 3890, loss 4.93029, acc 0.9\n","2019-04-04T20:13:34.641275: step 3900, loss 4.88128, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:13:44.571824: step 3900, loss 6.12713, acc 0.78497\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.37%, Best = 83.64%\n","\n","2019-04-04T20:13:46.950237: step 3910, loss 4.99167, acc 0.85\n","2019-04-04T20:13:49.275647: step 3920, loss 5.18296, acc 0.75\n","2019-04-04T20:13:51.627040: step 3930, loss 4.77898, acc 0.95\n","2019-04-04T20:13:53.877189: step 3940, loss 4.8857, acc 0.9\n","2019-04-04T20:13:56.269745: step 3950, loss 4.74485, acc 1\n","2019-04-04T20:13:58.933233: step 3960, loss 4.80367, acc 0.95\n","2019-04-04T20:14:01.156321: step 3970, loss 4.70615, acc 1\n","2019-04-04T20:14:03.394740: step 3980, loss 4.72062, acc 0.95\n","2019-04-04T20:14:05.745454: step 3990, loss 4.82768, acc 0.9\n","2019-04-04T20:14:08.249089: step 4000, loss 4.89605, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:14:18.173730: step 4000, loss 6.01374, acc 0.78657\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.43%, Best = 83.64%\n","\n","2019-04-04T20:14:20.693685: step 4010, loss 4.89395, acc 0.9\n","2019-04-04T20:14:23.108979: step 4020, loss 4.70815, acc 0.95\n","2019-04-04T20:14:25.441587: step 4030, loss 4.72994, acc 0.95\n","2019-04-04T20:14:27.668063: step 4040, loss 4.91283, acc 0.9\n","2019-04-04T20:14:30.020504: step 4050, loss 4.76213, acc 0.95\n","2019-04-04T20:14:32.374924: step 4060, loss 4.97746, acc 0.95\n","2019-04-04T20:14:34.688121: step 4070, loss 4.75785, acc 0.95\n","2019-04-04T20:14:37.007425: step 4080, loss 4.82965, acc 0.9\n","2019-04-04T20:14:39.488461: step 4090, loss 4.7397, acc 0.95\n","2019-04-04T20:14:41.803373: step 4100, loss 4.64999, acc 1\n","\n","Evaluation:\n","2019-04-04T20:14:51.775286: step 4100, loss 6.02313, acc 0.789144\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.87%, Best = 83.64%\n","\n","2019-04-04T20:14:54.229594: step 4110, loss 4.8736, acc 0.85\n","2019-04-04T20:14:56.539665: step 4120, loss 4.67742, acc 1\n","2019-04-04T20:14:58.981290: step 4130, loss 4.89205, acc 0.95\n","2019-04-04T20:15:01.324308: step 4140, loss 4.93889, acc 0.85\n","2019-04-04T20:15:03.727750: step 4150, loss 4.66858, acc 0.95\n","2019-04-04T20:15:05.954294: step 4160, loss 4.76727, acc 1\n","2019-04-04T20:15:08.422624: step 4170, loss 4.81173, acc 0.85\n","2019-04-04T20:15:10.645359: step 4180, loss 4.62893, acc 1\n","2019-04-04T20:15:12.858800: step 4190, loss 4.67905, acc 1\n","2019-04-04T20:15:15.149572: step 4200, loss 4.73162, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:15:25.054660: step 4200, loss 6.22582, acc 0.793058\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.13%, Best = 83.64%\n","\n","2019-04-04T20:15:27.437820: step 4210, loss 4.78879, acc 0.9\n","2019-04-04T20:15:30.041942: step 4220, loss 4.76691, acc 0.95\n","2019-04-04T20:15:32.679864: step 4230, loss 4.7037, acc 0.9\n","2019-04-04T20:15:35.164688: step 4240, loss 4.69066, acc 0.95\n","2019-04-04T20:15:37.602223: step 4250, loss 4.72311, acc 0.95\n","2019-04-04T20:15:39.958611: step 4260, loss 4.7595, acc 0.95\n","2019-04-04T20:15:42.287121: step 4270, loss 4.67523, acc 1\n","2019-04-04T20:15:44.640571: step 4280, loss 4.64853, acc 0.95\n","2019-04-04T20:15:46.958097: step 4290, loss 4.74433, acc 0.95\n","2019-04-04T20:15:49.182139: step 4300, loss 5.09197, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:15:59.152360: step 4300, loss 6.2182, acc 0.791587\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.94%, Best = 83.64%\n","\n","2019-04-04T20:16:01.620513: step 4310, loss 4.89833, acc 0.8\n","2019-04-04T20:16:04.081193: step 4320, loss 4.84071, acc 0.9\n","2019-04-04T20:16:06.305619: step 4330, loss 4.79765, acc 0.95\n","2019-04-04T20:16:08.642769: step 4340, loss 4.79917, acc 0.9\n","2019-04-04T20:16:10.912764: step 4350, loss 4.78368, acc 0.9\n","2019-04-04T20:16:13.347851: step 4360, loss 4.90915, acc 0.9\n","2019-04-04T20:16:15.767095: step 4370, loss 4.74778, acc 0.9\n","2019-04-04T20:16:18.191797: step 4380, loss 4.95991, acc 0.8\n","2019-04-04T20:16:20.550591: step 4390, loss 4.72761, acc 0.9\n","2019-04-04T20:16:23.142138: step 4400, loss 4.61156, acc 1\n","\n","Evaluation:\n","2019-04-04T20:16:33.148634: step 4400, loss 6.09729, acc 0.783629\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.29%, Best = 83.64%\n","\n","2019-04-04T20:16:35.503357: step 4410, loss 4.75402, acc 0.95\n","2019-04-04T20:16:37.878051: step 4420, loss 4.61515, acc 1\n","2019-04-04T20:16:40.366072: step 4430, loss 4.80198, acc 0.9\n","2019-04-04T20:16:42.637312: step 4440, loss 4.66291, acc 0.95\n","2019-04-04T20:16:44.898526: step 4450, loss 4.86964, acc 0.95\n","2019-04-04T20:16:47.233988: step 4460, loss 4.62353, acc 1\n","2019-04-04T20:16:49.876060: step 4470, loss 4.57592, acc 1\n","2019-04-04T20:16:52.279008: step 4480, loss 4.61358, acc 1\n","2019-04-04T20:16:54.468638: step 4490, loss 4.60384, acc 1\n","2019-04-04T20:16:56.737355: step 4500, loss 4.83936, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:17:06.735920: step 4500, loss 6.0869, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.42%, Best = 83.64%\n","\n","2019-04-04T20:17:09.126887: step 4510, loss 5.1511, acc 0.75\n","2019-04-04T20:17:11.409367: step 4520, loss 5.03621, acc 0.85\n","2019-04-04T20:17:13.754516: step 4530, loss 4.75901, acc 0.9\n","2019-04-04T20:17:16.159834: step 4540, loss 4.73794, acc 0.95\n","2019-04-04T20:17:18.483744: step 4550, loss 4.63561, acc 0.95\n","2019-04-04T20:17:20.897503: step 4560, loss 4.59516, acc 1\n","2019-04-04T20:17:23.302739: step 4570, loss 4.7664, acc 0.9\n","2019-04-04T20:17:25.651884: step 4580, loss 4.73877, acc 0.95\n","2019-04-04T20:17:28.015899: step 4590, loss 4.79825, acc 0.9\n","2019-04-04T20:17:30.542616: step 4600, loss 4.61223, acc 1\n","\n","Evaluation:\n","2019-04-04T20:17:40.538367: step 4600, loss 6.09337, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.64%\n","\n","2019-04-04T20:17:43.021372: step 4610, loss 4.67428, acc 0.95\n","2019-04-04T20:17:45.613285: step 4620, loss 4.58748, acc 1\n","2019-04-04T20:17:47.887891: step 4630, loss 4.75563, acc 0.95\n","2019-04-04T20:17:50.303076: step 4640, loss 4.82534, acc 0.9\n","2019-04-04T20:17:52.690513: step 4650, loss 4.71435, acc 0.9\n","2019-04-04T20:17:54.946727: step 4660, loss 4.6979, acc 0.95\n","2019-04-04T20:17:57.298904: step 4670, loss 4.82103, acc 0.9\n","2019-04-04T20:17:59.631386: step 4680, loss 4.84205, acc 0.85\n","2019-04-04T20:18:02.087700: step 4690, loss 4.6068, acc 0.95\n","2019-04-04T20:18:04.421882: step 4700, loss 4.7194, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:18:14.395278: step 4700, loss 6.12016, acc 0.788711\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.74%, Best = 83.64%\n","\n","2019-04-04T20:18:16.784688: step 4710, loss 4.66861, acc 0.95\n","2019-04-04T20:18:18.957824: step 4720, loss 4.81984, acc 0.9\n","2019-04-04T20:18:21.219913: step 4730, loss 4.78171, acc 0.85\n","2019-04-04T20:18:23.494876: step 4740, loss 4.69121, acc 0.9\n","2019-04-04T20:18:26.092431: step 4750, loss 4.64198, acc 0.95\n","2019-04-04T20:18:28.490999: step 4760, loss 4.71791, acc 0.95\n","2019-04-04T20:18:30.810077: step 4770, loss 4.71602, acc 0.9\n","2019-04-04T20:18:33.321137: step 4780, loss 4.88039, acc 0.9\n","2019-04-04T20:18:35.821390: step 4790, loss 4.79349, acc 0.9\n","2019-04-04T20:18:38.230294: step 4800, loss 4.68093, acc 1\n","\n","Evaluation:\n","2019-04-04T20:18:48.282874: step 4800, loss 5.92615, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.64%\n","\n","2019-04-04T20:18:50.795143: step 4810, loss 4.71959, acc 0.95\n","2019-04-04T20:18:53.195707: step 4820, loss 4.63869, acc 0.95\n","2019-04-04T20:18:55.558867: step 4830, loss 4.65357, acc 0.95\n","2019-04-04T20:18:58.144413: step 4840, loss 4.66369, acc 0.95\n","2019-04-04T20:19:00.347414: step 4850, loss 4.67438, acc 0.9\n","2019-04-04T20:19:02.784420: step 4860, loss 4.59133, acc 1\n","2019-04-04T20:19:05.232579: step 4870, loss 4.69134, acc 0.9\n","2019-04-04T20:19:07.429319: step 4880, loss 4.6133, acc 0.95\n","2019-04-04T20:19:09.729638: step 4890, loss 4.59044, acc 1\n","2019-04-04T20:19:12.037338: step 4900, loss 4.69132, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:19:22.029240: step 4900, loss 5.9845, acc 0.786938\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.68%, Best = 83.64%\n","\n","2019-04-04T20:19:24.666030: step 4910, loss 4.71504, acc 0.95\n","2019-04-04T20:19:27.156933: step 4920, loss 4.59675, acc 0.95\n","2019-04-04T20:19:29.727673: step 4930, loss 4.80132, acc 0.9\n","2019-04-04T20:19:31.866806: step 4940, loss 4.62241, acc 0.95\n","2019-04-04T20:19:34.221540: step 4950, loss 4.59458, acc 0.95\n","2019-04-04T20:19:36.486848: step 4960, loss 4.75254, acc 0.95\n","2019-04-04T20:19:38.829686: step 4970, loss 4.86898, acc 0.95\n","2019-04-04T20:19:41.361611: step 4980, loss 4.61772, acc 0.95\n","2019-04-04T20:19:43.790135: step 4990, loss 4.59046, acc 1\n","2019-04-04T20:19:46.221954: step 5000, loss 4.63133, acc 1\n","\n","Evaluation:\n","2019-04-04T20:19:56.304207: step 5000, loss 5.97223, acc 0.795761\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.42%, Best = 83.64%\n","\n","2019-04-04T20:19:58.805972: step 5010, loss 4.6497, acc 0.95\n","2019-04-04T20:20:01.010907: step 5020, loss 4.76105, acc 0.95\n","2019-04-04T20:20:03.399187: step 5030, loss 4.87281, acc 0.85\n","2019-04-04T20:20:05.747269: step 5040, loss 4.71017, acc 0.9\n","2019-04-04T20:20:08.034083: step 5050, loss 4.62947, acc 1\n","2019-04-04T20:20:10.502811: step 5060, loss 4.71407, acc 0.9\n","2019-04-04T20:20:12.734266: step 5070, loss 4.60443, acc 0.95\n","2019-04-04T20:20:15.166398: step 5080, loss 4.61091, acc 0.95\n","2019-04-04T20:20:17.608022: step 5090, loss 4.53377, acc 1\n","2019-04-04T20:20:19.946912: step 5100, loss 4.7859, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:20:29.956770: step 5100, loss 5.90545, acc 0.796497\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.39%, Best = 83.64%\n","\n","2019-04-04T20:20:32.264173: step 5110, loss 4.54494, acc 1\n","2019-04-04T20:20:34.636192: step 5120, loss 4.7531, acc 0.9\n","2019-04-04T20:20:37.002057: step 5130, loss 5.0543, acc 0.8\n","2019-04-04T20:20:39.237974: step 5140, loss 4.67478, acc 0.95\n","2019-04-04T20:20:41.712567: step 5150, loss 4.55408, acc 1\n","2019-04-04T20:20:44.065198: step 5160, loss 4.72954, acc 0.95\n","2019-04-04T20:20:46.316510: step 5170, loss 4.60906, acc 1\n","2019-04-04T20:20:48.496088: step 5180, loss 4.59378, acc 0.95\n","2019-04-04T20:20:50.963080: step 5190, loss 4.52097, acc 1\n","2019-04-04T20:20:53.263661: step 5200, loss 4.5893, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:21:03.266042: step 5200, loss 6.04027, acc 0.793058\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.09%, Best = 83.64%\n","\n","2019-04-04T20:21:05.690366: step 5210, loss 4.60849, acc 0.95\n","2019-04-04T20:21:07.978745: step 5220, loss 4.54875, acc 1\n","2019-04-04T20:21:10.487321: step 5230, loss 4.57735, acc 1\n","2019-04-04T20:21:12.793012: step 5240, loss 4.77424, acc 0.85\n","2019-04-04T20:21:15.111993: step 5250, loss 4.62979, acc 0.95\n","2019-04-04T20:21:17.436824: step 5260, loss 4.55403, acc 1\n","2019-04-04T20:21:19.892423: step 5270, loss 4.58637, acc 1\n","2019-04-04T20:21:22.337805: step 5280, loss 4.6738, acc 0.95\n","2019-04-04T20:21:24.719663: step 5290, loss 4.78683, acc 0.9\n","2019-04-04T20:21:27.395173: step 5300, loss 4.82341, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:21:37.361476: step 5300, loss 5.98941, acc 0.800541\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.79%, Best = 83.79%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-83.8-5300\n","\n","2019-04-04T20:21:40.377729: step 5310, loss 4.59298, acc 0.95\n","2019-04-04T20:21:42.752740: step 5320, loss 4.70351, acc 0.95\n","2019-04-04T20:21:45.035532: step 5330, loss 4.52412, acc 1\n","2019-04-04T20:21:47.449411: step 5340, loss 4.65429, acc 1\n","2019-04-04T20:21:50.109016: step 5350, loss 4.5288, acc 1\n","2019-04-04T20:21:52.485776: step 5360, loss 4.83275, acc 0.9\n","2019-04-04T20:21:54.801821: step 5370, loss 4.52585, acc 1\n","2019-04-04T20:21:57.418678: step 5380, loss 4.85073, acc 0.85\n","2019-04-04T20:21:59.721165: step 5390, loss 4.61419, acc 0.95\n","2019-04-04T20:22:02.164408: step 5400, loss 4.85577, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:22:12.138372: step 5400, loss 6.08114, acc 0.793923\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.21%, Best = 83.79%\n","\n","2019-04-04T20:22:14.565347: step 5410, loss 5.37407, acc 0.8\n","2019-04-04T20:22:17.098938: step 5420, loss 4.53355, acc 1\n","2019-04-04T20:22:19.452101: step 5430, loss 4.71749, acc 0.9\n","2019-04-04T20:22:21.720846: step 5440, loss 4.54422, acc 1\n","2019-04-04T20:22:24.007675: step 5450, loss 4.56079, acc 1\n","2019-04-04T20:22:26.343024: step 5460, loss 4.68382, acc 0.9\n","2019-04-04T20:22:28.671372: step 5470, loss 4.76853, acc 0.9\n","2019-04-04T20:22:31.049404: step 5480, loss 4.67341, acc 0.9\n","2019-04-04T20:22:33.540483: step 5490, loss 5.07233, acc 0.85\n","2019-04-04T20:22:35.808535: step 5500, loss 4.62575, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:22:45.871614: step 5500, loss 5.96697, acc 0.794593\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.45%, Best = 83.79%\n","\n","2019-04-04T20:22:48.002361: step 5510, loss 4.56678, acc 0.95\n","2019-04-04T20:22:50.295046: step 5520, loss 4.51044, acc 1\n","2019-04-04T20:22:52.629894: step 5530, loss 4.62574, acc 0.95\n","2019-04-04T20:22:54.880477: step 5540, loss 4.54159, acc 1\n","2019-04-04T20:22:57.253282: step 5550, loss 4.88895, acc 0.9\n","2019-04-04T20:22:59.680013: step 5560, loss 4.50408, acc 1\n","2019-04-04T20:23:02.115622: step 5570, loss 4.71988, acc 0.95\n","2019-04-04T20:23:04.414263: step 5580, loss 4.48525, acc 1\n","2019-04-04T20:23:06.732987: step 5590, loss 4.55667, acc 0.95\n","2019-04-04T20:23:09.082687: step 5600, loss 4.49209, acc 1\n","\n","Evaluation:\n","2019-04-04T20:23:19.029644: step 5600, loss 6.03325, acc 0.796799\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.79%\n","\n","2019-04-04T20:23:21.303390: step 5610, loss 4.59819, acc 0.9\n","2019-04-04T20:23:23.651393: step 5620, loss 4.55777, acc 0.95\n","2019-04-04T20:23:26.080881: step 5630, loss 4.55191, acc 1\n","2019-04-04T20:23:28.538315: step 5640, loss 4.55964, acc 1\n","2019-04-04T20:23:30.909199: step 5650, loss 4.54493, acc 1\n","2019-04-04T20:23:33.111432: step 5660, loss 4.51795, acc 1\n","2019-04-04T20:23:35.334385: step 5670, loss 4.49217, acc 1\n","2019-04-04T20:23:37.743106: step 5680, loss 4.56913, acc 0.95\n","2019-04-04T20:23:40.400674: step 5690, loss 4.65175, acc 0.9\n","2019-04-04T20:23:42.621073: step 5700, loss 4.54119, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:23:52.621970: step 5700, loss 6.04662, acc 0.797535\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.49%, Best = 83.79%\n","\n","2019-04-04T20:23:55.145218: step 5710, loss 4.70439, acc 0.95\n","2019-04-04T20:23:57.423877: step 5720, loss 4.57848, acc 0.95\n","2019-04-04T20:23:59.723394: step 5730, loss 4.67395, acc 0.95\n","2019-04-04T20:24:02.049834: step 5740, loss 4.49597, acc 1\n","2019-04-04T20:24:04.481207: step 5750, loss 4.50875, acc 1\n","2019-04-04T20:24:06.879222: step 5760, loss 4.87895, acc 0.9\n","2019-04-04T20:24:09.240090: step 5770, loss 4.6548, acc 0.95\n","2019-04-04T20:24:11.590855: step 5780, loss 4.51962, acc 0.95\n","2019-04-04T20:24:13.903183: step 5790, loss 4.65123, acc 0.95\n","2019-04-04T20:24:16.232750: step 5800, loss 4.46308, acc 1\n","\n","Evaluation:\n","2019-04-04T20:24:26.223776: step 5800, loss 6.05116, acc 0.793555\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.11%, Best = 83.79%\n","\n","2019-04-04T20:24:28.537669: step 5810, loss 4.73158, acc 0.9\n","2019-04-04T20:24:30.832588: step 5820, loss 4.52224, acc 1\n","2019-04-04T20:24:33.201966: step 5830, loss 4.86847, acc 0.9\n","2019-04-04T20:24:35.843216: step 5840, loss 4.4809, acc 1\n","2019-04-04T20:24:38.081885: step 5850, loss 4.50595, acc 1\n","2019-04-04T20:24:40.382815: step 5860, loss 4.78449, acc 0.85\n","2019-04-04T20:24:42.977559: step 5870, loss 4.54249, acc 0.95\n","2019-04-04T20:24:45.256888: step 5880, loss 4.75317, acc 0.95\n","2019-04-04T20:24:47.668259: step 5890, loss 4.46709, acc 1\n","2019-04-04T20:24:50.039089: step 5900, loss 4.53367, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:25:00.075674: step 5900, loss 6.23077, acc 0.799005\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.59%, Best = 83.79%\n","\n","2019-04-04T20:25:02.663109: step 5910, loss 4.46275, acc 1\n","2019-04-04T20:25:04.957817: step 5920, loss 4.51482, acc 0.95\n","2019-04-04T20:25:07.359764: step 5930, loss 4.53619, acc 1\n","2019-04-04T20:25:09.722987: step 5940, loss 4.77894, acc 0.9\n","2019-04-04T20:25:12.100697: step 5950, loss 4.48657, acc 1\n","2019-04-04T20:25:14.448049: step 5960, loss 4.65666, acc 0.95\n","2019-04-04T20:25:16.977940: step 5970, loss 4.65414, acc 0.9\n","2019-04-04T20:25:19.247468: step 5980, loss 4.45313, acc 1\n","2019-04-04T20:25:21.788167: step 5990, loss 4.51441, acc 1\n","2019-04-04T20:25:24.084327: step 6000, loss 4.50405, acc 1\n","\n","Evaluation:\n","2019-04-04T20:25:34.071582: step 6000, loss 6.25503, acc 0.794593\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.21%, Best = 83.79%\n","\n","2019-04-04T20:25:36.544106: step 6010, loss 4.51853, acc 0.95\n","2019-04-04T20:25:39.128550: step 6020, loss 4.4598, acc 1\n","2019-04-04T20:25:41.385853: step 6030, loss 4.5244, acc 1\n","2019-04-04T20:25:44.036197: step 6040, loss 4.46888, acc 1\n","2019-04-04T20:25:46.508475: step 6050, loss 4.45265, acc 1\n","2019-04-04T20:25:48.803557: step 6060, loss 4.65819, acc 0.9\n","2019-04-04T20:25:51.152094: step 6070, loss 4.45497, acc 1\n","2019-04-04T20:25:53.477302: step 6080, loss 4.55389, acc 0.9\n","2019-04-04T20:25:55.682480: step 6090, loss 4.46175, acc 1\n","2019-04-04T20:25:58.023760: step 6100, loss 4.78409, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:26:07.999933: step 6100, loss 6.19482, acc 0.792755\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.23%, Best = 83.79%\n","\n","2019-04-04T20:26:10.362682: step 6110, loss 4.55031, acc 0.95\n","2019-04-04T20:26:12.821531: step 6120, loss 4.56246, acc 0.95\n","2019-04-04T20:26:15.025381: step 6130, loss 4.44305, acc 1\n","2019-04-04T20:26:17.474652: step 6140, loss 4.49896, acc 1\n","2019-04-04T20:26:19.978360: step 6150, loss 4.48743, acc 0.95\n","2019-04-04T20:26:22.236219: step 6160, loss 4.53, acc 0.95\n","2019-04-04T20:26:24.711084: step 6170, loss 4.59024, acc 0.95\n","2019-04-04T20:26:26.998921: step 6180, loss 4.47489, acc 1\n","2019-04-04T20:26:29.262145: step 6190, loss 4.43321, acc 1\n","2019-04-04T20:26:31.657239: step 6200, loss 4.44394, acc 1\n","\n","Evaluation:\n","2019-04-04T20:26:41.643139: step 6200, loss 6.02559, acc 0.795026\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.79%\n","\n","2019-04-04T20:26:44.209775: step 6210, loss 4.42827, acc 1\n","2019-04-04T20:26:46.477655: step 6220, loss 4.49913, acc 0.95\n","2019-04-04T20:26:48.880563: step 6230, loss 4.52873, acc 0.95\n","2019-04-04T20:26:51.191566: step 6240, loss 4.50089, acc 0.95\n","2019-04-04T20:26:53.375902: step 6250, loss 4.69729, acc 0.95\n","2019-04-04T20:26:55.896538: step 6260, loss 4.76699, acc 0.85\n","2019-04-04T20:26:58.228681: step 6270, loss 4.44968, acc 1\n","2019-04-04T20:27:00.506811: step 6280, loss 4.7534, acc 0.85\n","2019-04-04T20:27:02.967940: step 6290, loss 4.4431, acc 1\n","2019-04-04T20:27:05.289467: step 6300, loss 4.43862, acc 1\n","\n","Evaluation:\n","2019-04-04T20:27:15.303214: step 6300, loss 6.1175, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.7%, Best = 83.79%\n","\n","2019-04-04T20:27:17.989707: step 6310, loss 4.72047, acc 0.9\n","2019-04-04T20:27:20.414539: step 6320, loss 4.42914, acc 1\n","2019-04-04T20:27:22.716740: step 6330, loss 4.71633, acc 0.95\n","2019-04-04T20:27:25.014286: step 6340, loss 5.41506, acc 0.85\n","2019-04-04T20:27:27.380864: step 6350, loss 4.68404, acc 0.9\n","2019-04-04T20:27:29.737524: step 6360, loss 4.50673, acc 0.95\n","2019-04-04T20:27:32.176792: step 6370, loss 4.58037, acc 0.95\n","2019-04-04T20:27:34.539594: step 6380, loss 4.45817, acc 1\n","2019-04-04T20:27:36.827639: step 6390, loss 4.42744, acc 1\n","2019-04-04T20:27:39.125970: step 6400, loss 4.40323, acc 1\n","\n","Evaluation:\n","2019-04-04T20:27:49.126858: step 6400, loss 6.17065, acc 0.795394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.33%, Best = 83.79%\n","\n","2019-04-04T20:27:51.599306: step 6410, loss 4.42446, acc 1\n","2019-04-04T20:27:54.056840: step 6420, loss 4.47443, acc 1\n","2019-04-04T20:27:56.574527: step 6430, loss 4.45314, acc 0.95\n","2019-04-04T20:27:58.833315: step 6440, loss 4.59611, acc 0.9\n","2019-04-04T20:28:01.201751: step 6450, loss 4.50035, acc 0.95\n","2019-04-04T20:28:03.490997: step 6460, loss 4.44893, acc 1\n","2019-04-04T20:28:05.734166: step 6470, loss 4.51685, acc 0.9\n","2019-04-04T20:28:08.079848: step 6480, loss 4.39973, acc 1\n","2019-04-04T20:28:10.501272: step 6490, loss 4.5274, acc 0.95\n","2019-04-04T20:28:12.736055: step 6500, loss 4.48618, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:28:22.745417: step 6500, loss 6.1874, acc 0.803114\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.96%, Best = 83.96%\n","\n","Saved model checkpoint to runs/1554407263/checkpoints/model-84-6500\n","\n","2019-04-04T20:28:25.770255: step 6510, loss 4.42791, acc 1\n","2019-04-04T20:28:28.495113: step 6520, loss 4.57377, acc 0.9\n","2019-04-04T20:28:30.942113: step 6530, loss 4.49573, acc 0.95\n","2019-04-04T20:28:33.307927: step 6540, loss 4.40889, acc 1\n","2019-04-04T20:28:35.834767: step 6550, loss 4.55131, acc 0.9\n","2019-04-04T20:28:38.305277: step 6560, loss 4.4437, acc 0.95\n","2019-04-04T20:28:40.579995: step 6570, loss 4.49631, acc 0.95\n","2019-04-04T20:28:42.988724: step 6580, loss 4.46326, acc 1\n","2019-04-04T20:28:45.380529: step 6590, loss 4.46443, acc 0.95\n","2019-04-04T20:28:47.819541: step 6600, loss 4.42678, acc 1\n","\n","Evaluation:\n","2019-04-04T20:28:57.825931: step 6600, loss 6.17132, acc 0.795394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.39%, Best = 83.96%\n","\n","2019-04-04T20:29:00.082888: step 6610, loss 4.48585, acc 0.95\n","2019-04-04T20:29:02.512703: step 6620, loss 4.38972, acc 1\n","2019-04-04T20:29:04.888230: step 6630, loss 4.50475, acc 0.95\n","2019-04-04T20:29:07.295338: step 6640, loss 4.41496, acc 1\n","2019-04-04T20:29:09.635706: step 6650, loss 4.55418, acc 0.95\n","2019-04-04T20:29:11.941323: step 6660, loss 4.44193, acc 1\n","2019-04-04T20:29:14.181968: step 6670, loss 4.39216, acc 1\n","2019-04-04T20:29:16.524140: step 6680, loss 4.53496, acc 0.95\n","2019-04-04T20:29:18.674609: step 6690, loss 4.50329, acc 0.95\n","2019-04-04T20:29:20.836439: step 6700, loss 4.5735, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:29:30.806565: step 6700, loss 6.14525, acc 0.795026\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.94%, Best = 83.96%\n","\n","2019-04-04T20:29:33.214932: step 6710, loss 4.46626, acc 1\n","2019-04-04T20:29:35.533828: step 6720, loss 4.44297, acc 1\n","2019-04-04T20:29:37.985759: step 6730, loss 4.52667, acc 0.95\n","2019-04-04T20:29:40.192606: step 6740, loss 4.41201, acc 1\n","2019-04-04T20:29:42.655804: step 6750, loss 4.4399, acc 1\n","2019-04-04T20:29:44.970845: step 6760, loss 4.48269, acc 0.95\n","2019-04-04T20:29:47.344488: step 6770, loss 4.46084, acc 1\n","2019-04-04T20:29:49.726182: step 6780, loss 4.44522, acc 0.95\n","2019-04-04T20:29:52.216144: step 6790, loss 4.58863, acc 0.8\n","2019-04-04T20:29:54.533447: step 6800, loss 4.44099, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:30:04.463539: step 6800, loss 6.00645, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.17%, Best = 83.96%\n","\n","2019-04-04T20:30:06.933264: step 6810, loss 4.77588, acc 0.8\n","2019-04-04T20:30:09.533231: step 6820, loss 4.84837, acc 0.9\n","2019-04-04T20:30:12.122189: step 6830, loss 4.38208, acc 1\n","2019-04-04T20:30:14.524542: step 6840, loss 4.4267, acc 0.95\n","2019-04-04T20:30:16.744550: step 6850, loss 4.37147, acc 1\n","2019-04-04T20:30:19.184869: step 6860, loss 4.50908, acc 0.95\n","2019-04-04T20:30:21.403299: step 6870, loss 4.39674, acc 1\n","2019-04-04T20:30:23.610212: step 6880, loss 4.44284, acc 0.95\n","2019-04-04T20:30:26.005436: step 6890, loss 4.41905, acc 0.95\n","2019-04-04T20:30:28.443428: step 6900, loss 4.5055, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:30:38.388914: step 6900, loss 6.05455, acc 0.800908\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.7%, Best = 83.96%\n","\n","2019-04-04T20:30:40.831262: step 6910, loss 4.55515, acc 0.95\n","2019-04-04T20:30:43.206573: step 6920, loss 4.45849, acc 0.95\n","2019-04-04T20:30:45.780107: step 6930, loss 4.37067, acc 1\n","2019-04-04T20:30:48.196386: step 6940, loss 4.38715, acc 1\n","2019-04-04T20:30:50.422573: step 6950, loss 4.39016, acc 1\n","2019-04-04T20:30:52.744225: step 6960, loss 4.36641, acc 1\n","2019-04-04T20:30:55.137773: step 6970, loss 4.45956, acc 1\n","2019-04-04T20:30:57.356691: step 6980, loss 4.45929, acc 0.95\n","2019-04-04T20:30:59.746722: step 6990, loss 4.39225, acc 1\n","2019-04-04T20:31:02.063074: step 7000, loss 4.42396, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:31:12.023960: step 7000, loss 6.153, acc 0.800908\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.58%, Best = 83.96%\n","\n","2019-04-04T20:31:14.410845: step 7010, loss 4.39886, acc 1\n","2019-04-04T20:31:16.742050: step 7020, loss 4.39426, acc 1\n","2019-04-04T20:31:18.971820: step 7030, loss 4.53597, acc 0.95\n","2019-04-04T20:31:21.442696: step 7040, loss 4.5733, acc 0.9\n","2019-04-04T20:31:23.621812: step 7050, loss 4.39515, acc 1\n","2019-04-04T20:31:25.804288: step 7060, loss 4.65006, acc 0.85\n","2019-04-04T20:31:28.099402: step 7070, loss 4.45069, acc 0.95\n","2019-04-04T20:31:30.291373: step 7080, loss 4.57685, acc 0.9\n","2019-04-04T20:31:32.482080: step 7090, loss 4.36928, acc 1\n","2019-04-04T20:31:34.958179: step 7100, loss 4.41379, acc 1\n","\n","Evaluation:\n","2019-04-04T20:31:44.944273: step 7100, loss 6.05057, acc 0.792085\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.83%, Best = 83.96%\n","\n","2019-04-04T20:31:47.316341: step 7110, loss 4.39397, acc 0.95\n","2019-04-04T20:31:49.894741: step 7120, loss 4.48942, acc 0.95\n","2019-04-04T20:31:52.179193: step 7130, loss 4.43089, acc 1\n","2019-04-04T20:31:54.561119: step 7140, loss 4.37537, acc 1\n","2019-04-04T20:31:56.932666: step 7150, loss 4.36782, acc 1\n","2019-04-04T20:31:59.351615: step 7160, loss 4.386, acc 1\n","2019-04-04T20:32:01.680417: step 7170, loss 4.39967, acc 0.95\n","2019-04-04T20:32:04.170377: step 7180, loss 4.43763, acc 0.95\n","2019-04-04T20:32:06.509991: step 7190, loss 4.44083, acc 0.95\n","2019-04-04T20:32:08.985606: step 7200, loss 4.40832, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:32:19.198822: step 7200, loss 6.31409, acc 0.794961\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.99%, Best = 83.96%\n","\n","2019-04-04T20:32:21.534334: step 7210, loss 4.35216, acc 1\n","2019-04-04T20:32:23.931517: step 7220, loss 4.39154, acc 0.95\n","2019-04-04T20:32:26.270808: step 7230, loss 4.55289, acc 0.95\n","2019-04-04T20:32:28.610331: step 7240, loss 4.40378, acc 1\n","2019-04-04T20:32:30.999935: step 7250, loss 4.39484, acc 0.95\n","2019-04-04T20:32:33.446850: step 7260, loss 4.35726, acc 1\n","2019-04-04T20:32:35.836246: step 7270, loss 4.4042, acc 0.95\n","2019-04-04T20:32:38.447260: step 7280, loss 4.33003, acc 1\n","2019-04-04T20:32:40.682448: step 7290, loss 4.54961, acc 0.95\n","2019-04-04T20:32:42.971654: step 7300, loss 4.532, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:32:53.029907: step 7300, loss 6.3212, acc 0.789079\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.79%, Best = 83.96%\n","\n","2019-04-04T20:32:55.349354: step 7310, loss 4.44075, acc 0.95\n","2019-04-04T20:32:57.592026: step 7320, loss 4.35171, acc 1\n","2019-04-04T20:33:00.098424: step 7330, loss 4.39347, acc 0.95\n","2019-04-04T20:33:02.437512: step 7340, loss 4.38261, acc 0.95\n","2019-04-04T20:33:04.921940: step 7350, loss 4.33863, acc 1\n","2019-04-04T20:33:07.301554: step 7360, loss 4.33962, acc 1\n","2019-04-04T20:33:09.592768: step 7370, loss 4.41069, acc 0.95\n","2019-04-04T20:33:11.844608: step 7380, loss 4.52709, acc 0.9\n","2019-04-04T20:33:14.099460: step 7390, loss 4.35332, acc 1\n","2019-04-04T20:33:16.305403: step 7400, loss 4.54742, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:33:26.341307: step 7400, loss 6.31436, acc 0.793793\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.96%\n","\n","2019-04-04T20:33:28.716983: step 7410, loss 4.34142, acc 1\n","2019-04-04T20:33:31.341225: step 7420, loss 4.42353, acc 1\n","2019-04-04T20:33:33.525878: step 7430, loss 4.33266, acc 1\n","2019-04-04T20:33:35.920589: step 7440, loss 4.53377, acc 0.95\n","2019-04-04T20:33:38.379326: step 7450, loss 4.34709, acc 1\n","2019-04-04T20:33:40.729738: step 7460, loss 4.32092, acc 1\n","2019-04-04T20:33:43.013642: step 7470, loss 4.34177, acc 1\n","2019-04-04T20:33:45.476266: step 7480, loss 4.57309, acc 0.95\n","2019-04-04T20:33:47.820326: step 7490, loss 4.4022, acc 1\n","2019-04-04T20:33:50.449725: step 7500, loss 4.41217, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:34:00.465208: step 7500, loss 6.22138, acc 0.797167\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.47%, Best = 83.96%\n","\n","2019-04-04T20:34:03.196950: step 7510, loss 4.50727, acc 0.95\n","2019-04-04T20:34:05.407108: step 7520, loss 4.44536, acc 0.95\n","2019-04-04T20:34:07.878187: step 7530, loss 4.65268, acc 0.9\n","2019-04-04T20:34:10.159991: step 7540, loss 4.35124, acc 1\n","2019-04-04T20:34:12.389013: step 7550, loss 4.48924, acc 0.95\n","2019-04-04T20:34:14.698470: step 7560, loss 4.61108, acc 0.9\n","2019-04-04T20:34:17.054214: step 7570, loss 4.83014, acc 0.85\n","2019-04-04T20:34:19.656424: step 7580, loss 4.6216, acc 0.9\n","2019-04-04T20:34:21.946473: step 7590, loss 4.38518, acc 0.95\n","2019-04-04T20:34:24.384023: step 7600, loss 4.64941, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:34:34.371142: step 7600, loss 6.20171, acc 0.790614\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.96%\n","\n","2019-04-04T20:34:36.883531: step 7610, loss 4.59036, acc 0.95\n","2019-04-04T20:34:39.224268: step 7620, loss 4.51102, acc 0.9\n","2019-04-04T20:34:41.606553: step 7630, loss 4.53678, acc 0.95\n","2019-04-04T20:34:44.148190: step 7640, loss 4.32431, acc 1\n","2019-04-04T20:34:46.431606: step 7650, loss 4.33365, acc 1\n","2019-04-04T20:34:48.753226: step 7660, loss 4.33011, acc 1\n","2019-04-04T20:34:51.104682: step 7670, loss 4.31124, acc 1\n","2019-04-04T20:34:53.545115: step 7680, loss 4.44765, acc 0.95\n","2019-04-04T20:34:56.056591: step 7690, loss 4.50868, acc 0.85\n","2019-04-04T20:34:58.495132: step 7700, loss 4.38103, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:35:08.459785: step 7700, loss 6.22134, acc 0.788776\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.65%, Best = 83.96%\n","\n","2019-04-04T20:35:10.848737: step 7710, loss 4.55313, acc 0.85\n","2019-04-04T20:35:13.187540: step 7720, loss 4.37372, acc 0.9\n","2019-04-04T20:35:15.653888: step 7730, loss 4.34133, acc 1\n","2019-04-04T20:35:18.226922: step 7740, loss 4.29569, acc 1\n","2019-04-04T20:35:20.604518: step 7750, loss 4.31996, acc 1\n","2019-04-04T20:35:22.845882: step 7760, loss 4.35052, acc 0.95\n","2019-04-04T20:35:24.969904: step 7770, loss 4.30581, acc 1\n","2019-04-04T20:35:27.231632: step 7780, loss 4.40621, acc 0.9\n","2019-04-04T20:35:29.738296: step 7790, loss 4.30987, acc 1\n","2019-04-04T20:35:31.958649: step 7800, loss 4.29861, acc 1\n","\n","Evaluation:\n","2019-04-04T20:35:41.974047: step 7800, loss 6.27345, acc 0.793188\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.98%, Best = 83.96%\n","\n","2019-04-04T20:35:44.328863: step 7810, loss 4.34823, acc 0.95\n","2019-04-04T20:35:46.849855: step 7820, loss 4.36116, acc 0.95\n","2019-04-04T20:35:49.149391: step 7830, loss 4.32008, acc 1\n","2019-04-04T20:35:51.542496: step 7840, loss 4.3385, acc 1\n","2019-04-04T20:35:53.902200: step 7850, loss 4.32564, acc 1\n","2019-04-04T20:35:56.245945: step 7860, loss 4.30237, acc 1\n","2019-04-04T20:35:58.803764: step 7870, loss 4.5546, acc 0.85\n","2019-04-04T20:36:01.227606: step 7880, loss 4.4403, acc 0.9\n","2019-04-04T20:36:03.398095: step 7890, loss 4.6388, acc 0.95\n","2019-04-04T20:36:05.717409: step 7900, loss 4.31379, acc 1\n","\n","Evaluation:\n","2019-04-04T20:36:15.667284: step 7900, loss 6.33798, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T20:36:18.164138: step 7910, loss 4.50571, acc 0.9\n","2019-04-04T20:36:20.349571: step 7920, loss 4.37808, acc 0.95\n","2019-04-04T20:36:22.659287: step 7930, loss 4.36088, acc 1\n","2019-04-04T20:36:24.970277: step 7940, loss 4.32177, acc 1\n","2019-04-04T20:36:27.129530: step 7950, loss 4.5199, acc 0.95\n","2019-04-04T20:36:29.496616: step 7960, loss 4.48141, acc 0.9\n","2019-04-04T20:36:31.950731: step 7970, loss 4.29747, acc 1\n","2019-04-04T20:36:34.390791: step 7980, loss 4.2767, acc 1\n","2019-04-04T20:36:36.734722: step 7990, loss 4.27366, acc 1\n","2019-04-04T20:36:39.168698: step 8000, loss 4.39298, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:36:49.126010: step 8000, loss 6.42889, acc 0.793858\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.37%, Best = 83.96%\n","\n","2019-04-04T20:36:51.460227: step 8010, loss 4.42056, acc 0.9\n","2019-04-04T20:36:53.821419: step 8020, loss 4.30353, acc 1\n","2019-04-04T20:36:56.162917: step 8030, loss 4.27707, acc 1\n","2019-04-04T20:36:58.467651: step 8040, loss 4.46241, acc 0.95\n","2019-04-04T20:37:00.936720: step 8050, loss 4.2848, acc 1\n","2019-04-04T20:37:03.092290: step 8060, loss 4.29532, acc 1\n","2019-04-04T20:37:05.424832: step 8070, loss 4.48157, acc 0.95\n","2019-04-04T20:37:07.984374: step 8080, loss 4.28687, acc 1\n","2019-04-04T20:37:10.170613: step 8090, loss 4.31105, acc 1\n","2019-04-04T20:37:12.454534: step 8100, loss 4.38483, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:37:22.444943: step 8100, loss 6.41861, acc 0.783932\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.34%, Best = 83.96%\n","\n","2019-04-04T20:37:24.788485: step 8110, loss 4.4225, acc 0.95\n","2019-04-04T20:37:27.164888: step 8120, loss 4.37152, acc 0.95\n","2019-04-04T20:37:29.711246: step 8130, loss 4.26836, acc 1\n","2019-04-04T20:37:32.313824: step 8140, loss 4.35179, acc 0.95\n","2019-04-04T20:37:34.822177: step 8150, loss 4.29487, acc 1\n","2019-04-04T20:37:37.159725: step 8160, loss 4.33294, acc 1\n","2019-04-04T20:37:39.404014: step 8170, loss 4.27063, acc 1\n","2019-04-04T20:37:41.795400: step 8180, loss 4.27503, acc 1\n","2019-04-04T20:37:44.114339: step 8190, loss 4.39345, acc 0.95\n","2019-04-04T20:37:46.611968: step 8200, loss 4.47822, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:37:56.644334: step 8200, loss 6.34363, acc 0.788343\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T20:37:58.928412: step 8210, loss 4.25588, acc 1\n","2019-04-04T20:38:01.181836: step 8220, loss 4.40969, acc 0.9\n","2019-04-04T20:38:03.403033: step 8230, loss 4.25861, acc 1\n","2019-04-04T20:38:05.725263: step 8240, loss 4.36588, acc 0.95\n","2019-04-04T20:38:08.105935: step 8250, loss 4.46596, acc 0.95\n","2019-04-04T20:38:10.661011: step 8260, loss 4.42618, acc 0.9\n","2019-04-04T20:38:12.898804: step 8270, loss 4.26302, acc 1\n","2019-04-04T20:38:15.462295: step 8280, loss 4.4028, acc 0.95\n","2019-04-04T20:38:17.795237: step 8290, loss 4.37113, acc 0.95\n","2019-04-04T20:38:20.017727: step 8300, loss 4.27191, acc 1\n","\n","Evaluation:\n","2019-04-04T20:38:30.003982: step 8300, loss 6.25588, acc 0.791652\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.14%, Best = 83.96%\n","\n","2019-04-04T20:38:32.434195: step 8310, loss 4.26197, acc 1\n","2019-04-04T20:38:35.073094: step 8320, loss 4.35423, acc 0.95\n","2019-04-04T20:38:37.590577: step 8330, loss 4.27051, acc 1\n","2019-04-04T20:38:39.980438: step 8340, loss 4.38195, acc 0.95\n","2019-04-04T20:38:42.396122: step 8350, loss 4.53214, acc 0.9\n","2019-04-04T20:38:44.690243: step 8360, loss 4.25585, acc 1\n","2019-04-04T20:38:47.014402: step 8370, loss 4.40373, acc 0.95\n","2019-04-04T20:38:49.305889: step 8380, loss 4.25002, acc 1\n","2019-04-04T20:38:51.592410: step 8390, loss 4.27649, acc 1\n","2019-04-04T20:38:54.116780: step 8400, loss 4.25389, acc 1\n","\n","Evaluation:\n","2019-04-04T20:39:04.192387: step 8400, loss 6.34512, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.31%, Best = 83.96%\n","\n","2019-04-04T20:39:06.614373: step 8410, loss 4.25533, acc 1\n","2019-04-04T20:39:08.880017: step 8420, loss 4.2464, acc 1\n","2019-04-04T20:39:11.397512: step 8430, loss 4.28541, acc 1\n","2019-04-04T20:39:13.679361: step 8440, loss 4.46748, acc 0.95\n","2019-04-04T20:39:16.209635: step 8450, loss 4.25036, acc 1\n","2019-04-04T20:39:18.425514: step 8460, loss 4.34, acc 0.95\n","2019-04-04T20:39:20.724746: step 8470, loss 4.45219, acc 0.95\n","2019-04-04T20:39:23.079788: step 8480, loss 4.3296, acc 0.95\n","2019-04-04T20:39:25.420445: step 8490, loss 4.31791, acc 1\n","2019-04-04T20:39:27.600305: step 8500, loss 4.35189, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:39:37.587690: step 8500, loss 6.36603, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.47%, Best = 83.96%\n","\n","2019-04-04T20:39:40.081065: step 8510, loss 4.34879, acc 0.95\n","2019-04-04T20:39:42.374861: step 8520, loss 4.28334, acc 0.95\n","2019-04-04T20:39:44.760825: step 8530, loss 4.28055, acc 1\n","2019-04-04T20:39:47.258835: step 8540, loss 4.3118, acc 1\n","2019-04-04T20:39:49.509382: step 8550, loss 4.2947, acc 0.95\n","2019-04-04T20:39:51.856594: step 8560, loss 4.22648, acc 1\n","2019-04-04T20:39:54.128399: step 8570, loss 4.2772, acc 0.95\n","2019-04-04T20:39:56.544738: step 8580, loss 4.341, acc 0.95\n","2019-04-04T20:39:58.968586: step 8590, loss 4.33145, acc 0.95\n","2019-04-04T20:40:01.267405: step 8600, loss 4.24806, acc 1\n","\n","Evaluation:\n","2019-04-04T20:40:11.357971: step 8600, loss 6.43074, acc 0.797167\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.58%, Best = 83.96%\n","\n","2019-04-04T20:40:13.644388: step 8610, loss 4.65322, acc 0.9\n","2019-04-04T20:40:16.017987: step 8620, loss 4.22482, acc 1\n","2019-04-04T20:40:18.260177: step 8630, loss 4.23618, acc 1\n","2019-04-04T20:40:20.711247: step 8640, loss 4.24156, acc 1\n","2019-04-04T20:40:23.296840: step 8650, loss 4.22564, acc 1\n","2019-04-04T20:40:25.515252: step 8660, loss 4.26875, acc 1\n","2019-04-04T20:40:27.811609: step 8670, loss 4.45606, acc 0.9\n","2019-04-04T20:40:30.263600: step 8680, loss 4.28484, acc 1\n","2019-04-04T20:40:32.537820: step 8690, loss 4.31819, acc 0.95\n","2019-04-04T20:40:35.192504: step 8700, loss 4.21764, acc 1\n","\n","Evaluation:\n","2019-04-04T20:40:45.149014: step 8700, loss 6.00859, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.96%\n","\n","2019-04-04T20:40:47.577443: step 8710, loss 4.27907, acc 0.95\n","2019-04-04T20:40:50.091771: step 8720, loss 4.24691, acc 1\n","2019-04-04T20:40:52.425339: step 8730, loss 4.25978, acc 1\n","2019-04-04T20:40:54.800549: step 8740, loss 4.30348, acc 0.95\n","2019-04-04T20:40:57.015934: step 8750, loss 4.2568, acc 0.95\n","2019-04-04T20:40:59.307848: step 8760, loss 4.22496, acc 1\n","2019-04-04T20:41:01.893009: step 8770, loss 4.24187, acc 1\n","2019-04-04T20:41:04.149770: step 8780, loss 4.26837, acc 0.95\n","2019-04-04T20:41:06.487922: step 8790, loss 4.27504, acc 1\n","2019-04-04T20:41:08.971570: step 8800, loss 4.25825, acc 1\n","\n","Evaluation:\n","2019-04-04T20:41:18.905789: step 8800, loss 6.02918, acc 0.791717\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T20:41:21.325962: step 8810, loss 4.30473, acc 0.95\n","2019-04-04T20:41:23.900287: step 8820, loss 4.21471, acc 1\n","2019-04-04T20:41:26.490131: step 8830, loss 4.39803, acc 0.9\n","2019-04-04T20:41:28.670306: step 8840, loss 4.23583, acc 1\n","2019-04-04T20:41:31.064216: step 8850, loss 4.25155, acc 0.95\n","2019-04-04T20:41:33.495585: step 8860, loss 4.20503, acc 1\n","2019-04-04T20:41:35.833326: step 8870, loss 4.37085, acc 0.9\n","2019-04-04T20:41:38.282969: step 8880, loss 4.22473, acc 1\n","2019-04-04T20:41:40.528271: step 8890, loss 4.29583, acc 0.95\n","2019-04-04T20:41:42.899249: step 8900, loss 4.22665, acc 1\n","\n","Evaluation:\n","2019-04-04T20:41:52.849640: step 8900, loss 6.00667, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.1%, Best = 83.96%\n","\n","2019-04-04T20:41:55.374231: step 8910, loss 4.1979, acc 1\n","2019-04-04T20:41:57.634699: step 8920, loss 4.20168, acc 1\n","2019-04-04T20:42:00.007642: step 8930, loss 4.24319, acc 1\n","2019-04-04T20:42:02.335359: step 8940, loss 4.46989, acc 0.95\n","2019-04-04T20:42:04.607176: step 8950, loss 4.22298, acc 1\n","2019-04-04T20:42:07.039465: step 8960, loss 4.20588, acc 1\n","2019-04-04T20:42:09.412808: step 8970, loss 4.25029, acc 0.95\n","2019-04-04T20:42:11.796721: step 8980, loss 4.2717, acc 0.95\n","2019-04-04T20:42:14.132855: step 8990, loss 4.19403, acc 1\n","2019-04-04T20:42:16.463345: step 9000, loss 4.37584, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:42:26.725748: step 9000, loss 6.08176, acc 0.797599\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.45%, Best = 83.96%\n","\n","2019-04-04T20:42:29.236909: step 9010, loss 4.28576, acc 0.95\n","2019-04-04T20:42:31.557502: step 9020, loss 4.19331, acc 1\n","2019-04-04T20:42:34.166666: step 9030, loss 4.19543, acc 1\n","2019-04-04T20:42:36.393291: step 9040, loss 4.32544, acc 0.9\n","2019-04-04T20:42:38.836106: step 9050, loss 4.18587, acc 1\n","2019-04-04T20:42:41.095464: step 9060, loss 4.20594, acc 1\n","2019-04-04T20:42:43.531421: step 9070, loss 4.19211, acc 1\n","2019-04-04T20:42:45.911238: step 9080, loss 4.26942, acc 0.95\n","2019-04-04T20:42:48.224483: step 9090, loss 4.49802, acc 0.85\n","2019-04-04T20:42:50.836932: step 9100, loss 4.23929, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:43:00.964008: step 9100, loss 6.04154, acc 0.79202\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.06%, Best = 83.96%\n","\n","2019-04-04T20:43:03.426472: step 9110, loss 4.23465, acc 1\n","2019-04-04T20:43:05.814090: step 9120, loss 4.17952, acc 1\n","2019-04-04T20:43:08.262744: step 9130, loss 4.26798, acc 0.95\n","2019-04-04T20:43:10.663061: step 9140, loss 4.21233, acc 1\n","2019-04-04T20:43:13.045167: step 9150, loss 4.46645, acc 0.85\n","2019-04-04T20:43:15.452056: step 9160, loss 4.40522, acc 0.9\n","2019-04-04T20:43:17.712432: step 9170, loss 4.20126, acc 1\n","2019-04-04T20:43:19.989488: step 9180, loss 4.18348, acc 1\n","2019-04-04T20:43:22.372446: step 9190, loss 4.18012, acc 1\n","2019-04-04T20:43:24.637673: step 9200, loss 4.19853, acc 1\n","\n","Evaluation:\n","2019-04-04T20:43:34.686326: step 9200, loss 6.18284, acc 0.797902\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.6%, Best = 83.96%\n","\n","2019-04-04T20:43:37.030453: step 9210, loss 4.22154, acc 0.95\n","2019-04-04T20:43:39.285926: step 9220, loss 4.23869, acc 0.95\n","2019-04-04T20:43:41.525871: step 9230, loss 4.47044, acc 0.9\n","2019-04-04T20:43:43.833705: step 9240, loss 4.26199, acc 0.95\n","2019-04-04T20:43:46.182832: step 9250, loss 4.20412, acc 1\n","2019-04-04T20:43:48.445352: step 9260, loss 4.19317, acc 1\n","2019-04-04T20:43:50.775497: step 9270, loss 4.17826, acc 1\n","2019-04-04T20:43:53.190120: step 9280, loss 4.33826, acc 0.95\n","2019-04-04T20:43:55.497566: step 9290, loss 4.22537, acc 0.95\n","2019-04-04T20:43:57.899841: step 9300, loss 4.45938, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:44:07.955602: step 9300, loss 6.41766, acc 0.791652\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.09%, Best = 83.96%\n","\n","2019-04-04T20:44:10.540228: step 9310, loss 4.25347, acc 0.95\n","2019-04-04T20:44:12.858526: step 9320, loss 4.18448, acc 1\n","2019-04-04T20:44:15.195342: step 9330, loss 4.40428, acc 0.9\n","2019-04-04T20:44:17.473980: step 9340, loss 4.17491, acc 1\n","2019-04-04T20:44:19.998752: step 9350, loss 4.22601, acc 0.95\n","2019-04-04T20:44:22.342707: step 9360, loss 4.16982, acc 1\n","2019-04-04T20:44:24.653922: step 9370, loss 4.2179, acc 1\n","2019-04-04T20:44:26.941669: step 9380, loss 4.21135, acc 1\n","2019-04-04T20:44:29.252934: step 9390, loss 4.19158, acc 1\n","2019-04-04T20:44:31.652537: step 9400, loss 4.28319, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:44:41.630900: step 9400, loss 6.15495, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T20:44:44.088206: step 9410, loss 4.2469, acc 0.9\n","2019-04-04T20:44:46.371710: step 9420, loss 4.27843, acc 0.95\n","2019-04-04T20:44:48.919965: step 9430, loss 4.20188, acc 1\n","2019-04-04T20:44:51.216379: step 9440, loss 4.28562, acc 0.95\n","2019-04-04T20:44:53.525581: step 9450, loss 4.24636, acc 0.95\n","2019-04-04T20:44:55.943889: step 9460, loss 4.17006, acc 1\n","2019-04-04T20:44:58.410496: step 9470, loss 4.40896, acc 0.9\n","2019-04-04T20:45:00.679867: step 9480, loss 4.19806, acc 1\n","2019-04-04T20:45:02.942096: step 9490, loss 4.18941, acc 1\n","2019-04-04T20:45:05.353461: step 9500, loss 4.1777, acc 1\n","\n","Evaluation:\n","2019-04-04T20:45:15.340903: step 9500, loss 6.09534, acc 0.79349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.02%, Best = 83.96%\n","\n","2019-04-04T20:45:17.733350: step 9510, loss 4.37345, acc 0.85\n","2019-04-04T20:45:20.207807: step 9520, loss 4.34599, acc 0.95\n","2019-04-04T20:45:22.775139: step 9530, loss 4.32303, acc 0.95\n","2019-04-04T20:45:25.277229: step 9540, loss 4.16512, acc 1\n","2019-04-04T20:45:27.627274: step 9550, loss 4.22733, acc 0.95\n","2019-04-04T20:45:30.081693: step 9560, loss 4.32213, acc 0.95\n","2019-04-04T20:45:32.562321: step 9570, loss 4.19478, acc 1\n","2019-04-04T20:45:34.962010: step 9580, loss 4.18168, acc 1\n","2019-04-04T20:45:37.090709: step 9590, loss 4.15139, acc 1\n","2019-04-04T20:45:39.331071: step 9600, loss 4.19344, acc 1\n","\n","Evaluation:\n","2019-04-04T20:45:49.318442: step 9600, loss 6.26898, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.29%, Best = 83.96%\n","\n","2019-04-04T20:45:51.894688: step 9610, loss 4.28995, acc 0.95\n","2019-04-04T20:45:54.347076: step 9620, loss 4.14524, acc 1\n","2019-04-04T20:45:56.900013: step 9630, loss 4.14922, acc 1\n","2019-04-04T20:45:59.329461: step 9640, loss 4.19988, acc 0.95\n","2019-04-04T20:46:01.705941: step 9650, loss 4.15409, acc 1\n","2019-04-04T20:46:04.300620: step 9660, loss 4.16313, acc 1\n","2019-04-04T20:46:06.625437: step 9670, loss 4.17488, acc 1\n","2019-04-04T20:46:08.957595: step 9680, loss 4.15359, acc 1\n","2019-04-04T20:46:11.264608: step 9690, loss 4.13647, acc 1\n","2019-04-04T20:46:13.624999: step 9700, loss 4.15415, acc 1\n","\n","Evaluation:\n","2019-04-04T20:46:23.534835: step 9700, loss 6.58806, acc 0.790549\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.71%, Best = 83.96%\n","\n","2019-04-04T20:46:26.030119: step 9710, loss 4.16716, acc 1\n","2019-04-04T20:46:28.348860: step 9720, loss 4.14795, acc 1\n","2019-04-04T20:46:30.733516: step 9730, loss 4.15881, acc 1\n","2019-04-04T20:46:32.989702: step 9740, loss 4.24244, acc 0.95\n","2019-04-04T20:46:35.320998: step 9750, loss 4.14296, acc 1\n","2019-04-04T20:46:37.599114: step 9760, loss 4.17968, acc 0.95\n","2019-04-04T20:46:40.328823: step 9770, loss 4.26004, acc 0.9\n","2019-04-04T20:46:42.601485: step 9780, loss 4.13561, acc 1\n","2019-04-04T20:46:44.908069: step 9790, loss 4.15202, acc 1\n","2019-04-04T20:46:47.461403: step 9800, loss 4.15697, acc 1\n","\n","Evaluation:\n","2019-04-04T20:46:57.389462: step 9800, loss 6.32031, acc 0.790982\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.88%, Best = 83.96%\n","\n","2019-04-04T20:46:59.827280: step 9810, loss 4.23375, acc 0.95\n","2019-04-04T20:47:02.194308: step 9820, loss 4.21904, acc 0.95\n","2019-04-04T20:47:04.591753: step 9830, loss 4.1898, acc 0.95\n","2019-04-04T20:47:06.826123: step 9840, loss 4.26597, acc 0.95\n","2019-04-04T20:47:09.189291: step 9850, loss 4.17285, acc 0.95\n","2019-04-04T20:47:11.419879: step 9860, loss 4.15585, acc 1\n","2019-04-04T20:47:13.593397: step 9870, loss 4.13726, acc 1\n","2019-04-04T20:47:15.898734: step 9880, loss 4.12037, acc 1\n","2019-04-04T20:47:18.105217: step 9890, loss 4.21749, acc 0.95\n","2019-04-04T20:47:20.446925: step 9900, loss 4.51116, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:47:30.351127: step 9900, loss 6.44565, acc 0.78577\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.43%, Best = 83.96%\n","\n","2019-04-04T20:47:32.680315: step 9910, loss 4.15166, acc 1\n","2019-04-04T20:47:35.147653: step 9920, loss 4.15744, acc 1\n","2019-04-04T20:47:37.599483: step 9930, loss 4.12502, acc 1\n","2019-04-04T20:47:39.913923: step 9940, loss 4.16603, acc 1\n","2019-04-04T20:47:42.263563: step 9950, loss 4.11421, acc 1\n","2019-04-04T20:47:44.793899: step 9960, loss 4.1891, acc 0.95\n","2019-04-04T20:47:47.092920: step 9970, loss 4.25156, acc 0.95\n","2019-04-04T20:47:49.522690: step 9980, loss 4.19277, acc 0.95\n","2019-04-04T20:47:52.046828: step 9990, loss 4.21203, acc 0.95\n","2019-04-04T20:47:54.333842: step 10000, loss 4.19773, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:48:04.262659: step 10000, loss 6.17771, acc 0.795761\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.51%, Best = 83.96%\n","\n","2019-04-04T20:48:06.718243: step 10010, loss 4.11926, acc 1\n","2019-04-04T20:48:09.036043: step 10020, loss 4.28733, acc 0.9\n","2019-04-04T20:48:11.390525: step 10030, loss 4.13521, acc 1\n","2019-04-04T20:48:13.810137: step 10040, loss 4.21372, acc 0.95\n","2019-04-04T20:48:16.162880: step 10050, loss 4.16046, acc 1\n","2019-04-04T20:48:18.603794: step 10060, loss 4.1201, acc 1\n","2019-04-04T20:48:21.281918: step 10070, loss 4.1207, acc 1\n","2019-04-04T20:48:23.547928: step 10080, loss 4.21199, acc 0.95\n","2019-04-04T20:48:26.066022: step 10090, loss 4.10436, acc 1\n","2019-04-04T20:48:28.426110: step 10100, loss 4.12551, acc 1\n","\n","Evaluation:\n","2019-04-04T20:48:38.367918: step 10100, loss 6.16208, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.91%, Best = 83.96%\n","\n","2019-04-04T20:48:40.673620: step 10110, loss 4.13516, acc 1\n","2019-04-04T20:48:43.036525: step 10120, loss 4.28692, acc 0.9\n","2019-04-04T20:48:45.459506: step 10130, loss 4.11333, acc 1\n","2019-04-04T20:48:47.746530: step 10140, loss 4.10984, acc 1\n","2019-04-04T20:48:50.298241: step 10150, loss 4.22687, acc 0.9\n","2019-04-04T20:48:52.631812: step 10160, loss 4.20436, acc 0.95\n","2019-04-04T20:48:54.928904: step 10170, loss 4.1949, acc 0.95\n","2019-04-04T20:48:57.238866: step 10180, loss 4.17146, acc 1\n","2019-04-04T20:48:59.636325: step 10190, loss 4.20932, acc 0.95\n","2019-04-04T20:49:01.899491: step 10200, loss 4.31671, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:49:11.794200: step 10200, loss 6.38975, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.98%, Best = 83.96%\n","\n","2019-04-04T20:49:14.154558: step 10210, loss 4.14364, acc 1\n","2019-04-04T20:49:16.581459: step 10220, loss 4.1962, acc 0.95\n","2019-04-04T20:49:19.024600: step 10230, loss 4.18769, acc 0.95\n","2019-04-04T20:49:21.261329: step 10240, loss 4.11894, acc 1\n","2019-04-04T20:49:23.983660: step 10250, loss 4.11821, acc 1\n","2019-04-04T20:49:26.259573: step 10260, loss 4.15001, acc 0.95\n","2019-04-04T20:49:28.394494: step 10270, loss 4.12353, acc 1\n","2019-04-04T20:49:30.637254: step 10280, loss 4.1016, acc 1\n","2019-04-04T20:49:33.419852: step 10290, loss 4.25303, acc 0.9\n","2019-04-04T20:49:35.826619: step 10300, loss 4.19151, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:49:45.800966: step 10300, loss 6.60821, acc 0.79269\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.96%\n","\n","2019-04-04T20:49:48.077799: step 10310, loss 4.16185, acc 0.95\n","2019-04-04T20:49:50.425031: step 10320, loss 4.22544, acc 0.9\n","2019-04-04T20:49:52.946278: step 10330, loss 4.45571, acc 0.85\n","2019-04-04T20:49:55.412290: step 10340, loss 4.09341, acc 1\n","2019-04-04T20:49:57.790961: step 10350, loss 4.14041, acc 0.95\n","2019-04-04T20:50:00.059243: step 10360, loss 4.13482, acc 1\n","2019-04-04T20:50:02.420944: step 10370, loss 4.12546, acc 1\n","2019-04-04T20:50:04.762029: step 10380, loss 4.10177, acc 1\n","2019-04-04T20:50:06.921743: step 10390, loss 4.21582, acc 0.95\n","2019-04-04T20:50:09.209683: step 10400, loss 4.09785, acc 1\n","\n","Evaluation:\n","2019-04-04T20:50:19.184309: step 10400, loss 6.46339, acc 0.789879\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.64%, Best = 83.96%\n","\n","2019-04-04T20:50:21.684010: step 10410, loss 4.12254, acc 0.95\n","2019-04-04T20:50:24.012067: step 10420, loss 4.1437, acc 1\n","2019-04-04T20:50:26.342960: step 10430, loss 4.10475, acc 1\n","2019-04-04T20:50:28.605395: step 10440, loss 4.09942, acc 1\n","2019-04-04T20:50:31.058104: step 10450, loss 4.10368, acc 1\n","2019-04-04T20:50:33.342239: step 10460, loss 4.15279, acc 0.95\n","2019-04-04T20:50:35.770986: step 10470, loss 4.16603, acc 0.95\n","2019-04-04T20:50:38.140995: step 10480, loss 4.09602, acc 1\n","2019-04-04T20:50:40.456603: step 10490, loss 4.12, acc 1\n","2019-04-04T20:50:42.901525: step 10500, loss 4.29736, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:50:52.889196: step 10500, loss 6.6576, acc 0.785402\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.49%, Best = 83.96%\n","\n","2019-04-04T20:50:55.538317: step 10510, loss 4.07553, acc 1\n","2019-04-04T20:50:57.775321: step 10520, loss 4.0767, acc 1\n","2019-04-04T20:51:00.152335: step 10530, loss 4.23844, acc 0.95\n","2019-04-04T20:51:02.618118: step 10540, loss 4.14868, acc 0.95\n","2019-04-04T20:51:04.847337: step 10550, loss 4.07746, acc 1\n","2019-04-04T20:51:07.133145: step 10560, loss 4.069, acc 1\n","2019-04-04T20:51:09.477241: step 10570, loss 4.10285, acc 1\n","2019-04-04T20:51:11.797458: step 10580, loss 4.25164, acc 0.9\n","2019-04-04T20:51:14.211738: step 10590, loss 4.25733, acc 0.95\n","2019-04-04T20:51:16.732414: step 10600, loss 4.24737, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:51:26.651420: step 10600, loss 6.62135, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.07%, Best = 83.96%\n","\n","2019-04-04T20:51:29.227096: step 10610, loss 4.09729, acc 1\n","2019-04-04T20:51:31.750743: step 10620, loss 4.23049, acc 0.9\n","2019-04-04T20:51:34.094423: step 10630, loss 4.10812, acc 0.95\n","2019-04-04T20:51:36.584800: step 10640, loss 4.06044, acc 1\n","2019-04-04T20:51:38.896475: step 10650, loss 4.09815, acc 0.95\n","2019-04-04T20:51:41.162252: step 10660, loss 4.34726, acc 0.95\n","2019-04-04T20:51:43.538186: step 10670, loss 4.25559, acc 0.95\n","2019-04-04T20:51:45.839021: step 10680, loss 4.14748, acc 0.95\n","2019-04-04T20:51:48.210326: step 10690, loss 4.084, acc 1\n","2019-04-04T20:51:50.492315: step 10700, loss 4.05905, acc 1\n","\n","Evaluation:\n","2019-04-04T20:52:00.514058: step 10700, loss 6.65155, acc 0.793858\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.19%, Best = 83.96%\n","\n","2019-04-04T20:52:02.813093: step 10710, loss 4.28531, acc 0.95\n","2019-04-04T20:52:05.378136: step 10720, loss 4.08468, acc 1\n","2019-04-04T20:52:07.867578: step 10730, loss 4.07512, acc 1\n","2019-04-04T20:52:10.382579: step 10740, loss 4.12381, acc 0.95\n","2019-04-04T20:52:12.802244: step 10750, loss 4.18529, acc 0.95\n","2019-04-04T20:52:14.993174: step 10760, loss 4.05765, acc 1\n","2019-04-04T20:52:17.253964: step 10770, loss 4.08539, acc 1\n","2019-04-04T20:52:19.543181: step 10780, loss 4.12431, acc 0.95\n","2019-04-04T20:52:21.987607: step 10790, loss 4.07388, acc 1\n","2019-04-04T20:52:24.287981: step 10800, loss 4.08609, acc 1\n","\n","Evaluation:\n","2019-04-04T20:52:34.268691: step 10800, loss 6.43111, acc 0.792755\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.96%\n","\n","2019-04-04T20:52:36.526194: step 10810, loss 4.08784, acc 0.95\n","2019-04-04T20:52:39.042236: step 10820, loss 4.13403, acc 0.95\n","2019-04-04T20:52:41.376827: step 10830, loss 4.07289, acc 1\n","2019-04-04T20:52:43.936508: step 10840, loss 4.07639, acc 1\n","2019-04-04T20:52:46.079858: step 10850, loss 4.05043, acc 1\n","2019-04-04T20:52:48.328234: step 10860, loss 4.1711, acc 0.95\n","2019-04-04T20:52:50.635255: step 10870, loss 4.05638, acc 1\n","2019-04-04T20:52:53.142225: step 10880, loss 4.05835, acc 1\n","2019-04-04T20:52:55.543370: step 10890, loss 4.12038, acc 0.95\n","2019-04-04T20:52:58.114622: step 10900, loss 4.15747, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:53:08.086407: step 10900, loss 6.09354, acc 0.793923\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.29%, Best = 83.96%\n","\n","2019-04-04T20:53:10.457375: step 10910, loss 4.0402, acc 1\n","2019-04-04T20:53:12.883569: step 10920, loss 4.09107, acc 1\n","2019-04-04T20:53:15.199404: step 10930, loss 4.09632, acc 0.95\n","2019-04-04T20:53:17.664847: step 10940, loss 4.13609, acc 0.95\n","2019-04-04T20:53:19.921298: step 10950, loss 4.06914, acc 1\n","2019-04-04T20:53:22.479397: step 10960, loss 4.03677, acc 1\n","2019-04-04T20:53:24.837440: step 10970, loss 4.12278, acc 0.95\n","2019-04-04T20:53:27.145091: step 10980, loss 4.10864, acc 1\n","2019-04-04T20:53:29.647741: step 10990, loss 4.26738, acc 0.95\n","2019-04-04T20:53:31.938565: step 11000, loss 4.21996, acc 0.9\n","\n","Evaluation:\n","2019-04-04T20:53:41.920694: step 11000, loss 6.16374, acc 0.790982\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.23%, Best = 83.96%\n","\n","2019-04-04T20:53:44.260313: step 11010, loss 4.04896, acc 1\n","2019-04-04T20:53:46.505409: step 11020, loss 4.05537, acc 1\n","2019-04-04T20:53:49.002139: step 11030, loss 4.11334, acc 0.95\n","2019-04-04T20:53:51.303099: step 11040, loss 4.11267, acc 0.95\n","2019-04-04T20:53:53.617883: step 11050, loss 4.03056, acc 1\n","2019-04-04T20:53:56.311422: step 11060, loss 4.05775, acc 1\n","2019-04-04T20:53:58.685531: step 11070, loss 4.03048, acc 1\n","2019-04-04T20:54:01.045482: step 11080, loss 4.08076, acc 0.95\n","2019-04-04T20:54:03.387299: step 11090, loss 4.07196, acc 0.95\n","2019-04-04T20:54:05.816722: step 11100, loss 4.31904, acc 0.85\n","\n","Evaluation:\n","2019-04-04T20:54:15.821553: step 11100, loss 6.17381, acc 0.791717\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T20:54:18.396727: step 11110, loss 4.05716, acc 1\n","2019-04-04T20:54:20.643444: step 11120, loss 4.10943, acc 0.95\n","2019-04-04T20:54:23.086319: step 11130, loss 4.04162, acc 1\n","2019-04-04T20:54:25.403085: step 11140, loss 4.14952, acc 0.95\n","2019-04-04T20:54:27.698081: step 11150, loss 4.0453, acc 1\n","2019-04-04T20:54:30.064070: step 11160, loss 4.29633, acc 0.95\n","2019-04-04T20:54:32.414883: step 11170, loss 4.02197, acc 1\n","2019-04-04T20:54:34.981314: step 11180, loss 4.02406, acc 1\n","2019-04-04T20:54:37.261138: step 11190, loss 4.02631, acc 1\n","2019-04-04T20:54:39.485890: step 11200, loss 4.13372, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:54:49.454130: step 11200, loss 6.20953, acc 0.796064\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.96%\n","\n","2019-04-04T20:54:51.808089: step 11210, loss 4.19997, acc 0.95\n","2019-04-04T20:54:54.032913: step 11220, loss 4.15832, acc 0.95\n","2019-04-04T20:54:56.348634: step 11230, loss 4.0984, acc 0.95\n","2019-04-04T20:54:58.561630: step 11240, loss 4.04265, acc 1\n","2019-04-04T20:55:00.991192: step 11250, loss 4.04255, acc 1\n","2019-04-04T20:55:03.479034: step 11260, loss 4.01226, acc 1\n","2019-04-04T20:55:05.827198: step 11270, loss 4.15014, acc 0.9\n","2019-04-04T20:55:08.368663: step 11280, loss 4.04262, acc 1\n","2019-04-04T20:55:10.693282: step 11290, loss 4.02996, acc 1\n","2019-04-04T20:55:12.980823: step 11300, loss 4.01045, acc 1\n","\n","Evaluation:\n","2019-04-04T20:55:22.878463: step 11300, loss 6.35987, acc 0.794593\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.26%, Best = 83.96%\n","\n","2019-04-04T20:55:25.188689: step 11310, loss 4.01149, acc 1\n","2019-04-04T20:55:27.431400: step 11320, loss 4.04515, acc 1\n","2019-04-04T20:55:29.710699: step 11330, loss 4.09342, acc 0.95\n","2019-04-04T20:55:32.019477: step 11340, loss 4.0339, acc 1\n","2019-04-04T20:55:34.330723: step 11350, loss 4.00798, acc 1\n","2019-04-04T20:55:36.566645: step 11360, loss 4.07859, acc 0.95\n","2019-04-04T20:55:38.931309: step 11370, loss 4.0156, acc 1\n","2019-04-04T20:55:41.192577: step 11380, loss 4.19134, acc 0.9\n","2019-04-04T20:55:43.404352: step 11390, loss 4.15969, acc 0.95\n","2019-04-04T20:55:45.790137: step 11400, loss 4.15695, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:55:55.796097: step 11400, loss 6.53264, acc 0.787911\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.66%, Best = 83.96%\n","\n","2019-04-04T20:55:58.210488: step 11410, loss 4.03367, acc 1\n","2019-04-04T20:56:00.733017: step 11420, loss 4.03266, acc 1\n","2019-04-04T20:56:03.144287: step 11430, loss 4.02511, acc 1\n","2019-04-04T20:56:05.407367: step 11440, loss 4.09629, acc 0.95\n","2019-04-04T20:56:07.658340: step 11450, loss 4.02064, acc 1\n","2019-04-04T20:56:09.909079: step 11460, loss 4.04515, acc 1\n","2019-04-04T20:56:12.441719: step 11470, loss 3.99836, acc 1\n","2019-04-04T20:56:14.766510: step 11480, loss 4.00483, acc 1\n","2019-04-04T20:56:17.063715: step 11490, loss 4.11196, acc 0.95\n","2019-04-04T20:56:19.384180: step 11500, loss 4.00293, acc 1\n","\n","Evaluation:\n","2019-04-04T20:56:29.356572: step 11500, loss 6.52918, acc 0.789079\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.94%, Best = 83.96%\n","\n","2019-04-04T20:56:31.929931: step 11510, loss 4.01249, acc 1\n","2019-04-04T20:56:34.459633: step 11520, loss 4.00154, acc 1\n","2019-04-04T20:56:36.813800: step 11530, loss 4.09998, acc 0.95\n","2019-04-04T20:56:39.134328: step 11540, loss 4.16343, acc 0.95\n","2019-04-04T20:56:41.588969: step 11550, loss 4.00736, acc 1\n","2019-04-04T20:56:43.981538: step 11560, loss 4.17377, acc 0.9\n","2019-04-04T20:56:46.385893: step 11570, loss 3.9914, acc 1\n","2019-04-04T20:56:49.088479: step 11580, loss 4.01218, acc 1\n","2019-04-04T20:56:51.610833: step 11590, loss 4.03291, acc 1\n","2019-04-04T20:56:54.083645: step 11600, loss 3.99313, acc 1\n","\n","Evaluation:\n","2019-04-04T20:57:04.067427: step 11600, loss 6.53339, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.96%\n","\n","2019-04-04T20:57:06.614755: step 11610, loss 4.03651, acc 1\n","2019-04-04T20:57:08.949168: step 11620, loss 3.99786, acc 1\n","2019-04-04T20:57:11.193137: step 11630, loss 3.98587, acc 1\n","2019-04-04T20:57:13.436837: step 11640, loss 4.03354, acc 0.95\n","2019-04-04T20:57:15.613184: step 11650, loss 3.99188, acc 1\n","2019-04-04T20:57:17.951096: step 11660, loss 3.9826, acc 1\n","2019-04-04T20:57:20.181345: step 11670, loss 3.98762, acc 1\n","2019-04-04T20:57:22.560864: step 11680, loss 4.04451, acc 1\n","2019-04-04T20:57:24.905186: step 11690, loss 4.06792, acc 0.95\n","2019-04-04T20:57:27.232651: step 11700, loss 3.99101, acc 1\n","\n","Evaluation:\n","2019-04-04T20:57:37.139498: step 11700, loss 5.99076, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.09%, Best = 83.96%\n","\n","2019-04-04T20:57:39.414024: step 11710, loss 4.08181, acc 0.95\n","2019-04-04T20:57:41.828414: step 11720, loss 3.99079, acc 1\n","2019-04-04T20:57:44.130190: step 11730, loss 3.98134, acc 1\n","2019-04-04T20:57:46.612483: step 11740, loss 3.98852, acc 1\n","2019-04-04T20:57:48.974306: step 11750, loss 4.12376, acc 0.95\n","2019-04-04T20:57:51.339652: step 11760, loss 3.97887, acc 1\n","2019-04-04T20:57:53.837820: step 11770, loss 4.0466, acc 0.95\n","2019-04-04T20:57:56.203850: step 11780, loss 3.99894, acc 1\n","2019-04-04T20:57:58.731314: step 11790, loss 4.01815, acc 1\n","2019-04-04T20:58:00.986134: step 11800, loss 3.98367, acc 1\n","\n","Evaluation:\n","2019-04-04T20:58:10.937887: step 11800, loss 5.97548, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.36%, Best = 83.96%\n","\n","2019-04-04T20:58:13.365805: step 11810, loss 4.02319, acc 0.95\n","2019-04-04T20:58:15.880044: step 11820, loss 3.97045, acc 1\n","2019-04-04T20:58:18.168809: step 11830, loss 3.97122, acc 1\n","2019-04-04T20:58:20.371089: step 11840, loss 3.97423, acc 1\n","2019-04-04T20:58:22.733409: step 11850, loss 3.97945, acc 1\n","2019-04-04T20:58:25.123339: step 11860, loss 3.99919, acc 1\n","2019-04-04T20:58:27.409796: step 11870, loss 3.96563, acc 1\n","2019-04-04T20:58:29.675939: step 11880, loss 3.97245, acc 1\n","2019-04-04T20:58:32.141955: step 11890, loss 4.13114, acc 0.9\n","2019-04-04T20:58:34.441308: step 11900, loss 3.97713, acc 1\n","\n","Evaluation:\n","2019-04-04T20:58:44.414104: step 11900, loss 6.26482, acc 0.794226\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.27%, Best = 83.96%\n","\n","2019-04-04T20:58:46.996481: step 11910, loss 4.10927, acc 0.95\n","2019-04-04T20:58:49.225435: step 11920, loss 4.12377, acc 0.9\n","2019-04-04T20:58:51.647736: step 11930, loss 3.98678, acc 1\n","2019-04-04T20:58:53.978587: step 11940, loss 3.97238, acc 1\n","2019-04-04T20:58:56.442700: step 11950, loss 3.96362, acc 1\n","2019-04-04T20:58:58.897404: step 11960, loss 4.16491, acc 0.95\n","2019-04-04T20:59:01.227063: step 11970, loss 4.00593, acc 0.95\n","2019-04-04T20:59:03.458289: step 11980, loss 3.97099, acc 1\n","2019-04-04T20:59:05.897627: step 11990, loss 3.98112, acc 1\n","2019-04-04T20:59:08.451240: step 12000, loss 3.95567, acc 1\n","\n","Evaluation:\n","2019-04-04T20:59:18.428540: step 12000, loss 6.01117, acc 0.795026\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.4%, Best = 83.96%\n","\n","2019-04-04T20:59:20.906533: step 12010, loss 3.96339, acc 1\n","2019-04-04T20:59:23.298518: step 12020, loss 3.9637, acc 1\n","2019-04-04T20:59:25.691638: step 12030, loss 3.95942, acc 1\n","2019-04-04T20:59:28.246452: step 12040, loss 3.98514, acc 1\n","2019-04-04T20:59:30.517191: step 12050, loss 4.00361, acc 1\n","2019-04-04T20:59:32.818138: step 12060, loss 4.06494, acc 0.95\n","2019-04-04T20:59:35.141212: step 12070, loss 4.01706, acc 0.95\n","2019-04-04T20:59:37.513233: step 12080, loss 4.06184, acc 0.95\n","2019-04-04T20:59:39.683215: step 12090, loss 3.95287, acc 1\n","2019-04-04T20:59:42.107027: step 12100, loss 4.08506, acc 0.95\n","\n","Evaluation:\n","2019-04-04T20:59:52.097257: step 12100, loss 6.02453, acc 0.795026\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.35%, Best = 83.96%\n","\n","2019-04-04T20:59:54.604362: step 12110, loss 3.95298, acc 1\n","2019-04-04T20:59:56.902524: step 12120, loss 3.9823, acc 1\n","2019-04-04T20:59:59.133064: step 12130, loss 3.96812, acc 1\n","2019-04-04T21:00:01.529555: step 12140, loss 3.9881, acc 1\n","2019-04-04T21:00:03.945599: step 12150, loss 3.95357, acc 1\n","2019-04-04T21:00:06.279190: step 12160, loss 3.95124, acc 1\n","2019-04-04T21:00:08.783222: step 12170, loss 3.95639, acc 1\n","2019-04-04T21:00:10.999225: step 12180, loss 3.97237, acc 1\n","2019-04-04T21:00:13.403195: step 12190, loss 3.94993, acc 1\n","2019-04-04T21:00:15.812899: step 12200, loss 3.94064, acc 1\n","\n","Evaluation:\n","2019-04-04T21:00:25.810858: step 12200, loss 6.44424, acc 0.786505\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.52%, Best = 83.96%\n","\n","2019-04-04T21:00:28.190342: step 12210, loss 3.94128, acc 1\n","2019-04-04T21:00:30.679514: step 12220, loss 3.94031, acc 1\n","2019-04-04T21:00:32.912636: step 12230, loss 3.95459, acc 1\n","2019-04-04T21:00:35.250083: step 12240, loss 3.93694, acc 1\n","2019-04-04T21:00:37.717219: step 12250, loss 3.94746, acc 1\n","2019-04-04T21:00:40.117016: step 12260, loss 4.04823, acc 0.95\n","2019-04-04T21:00:42.618487: step 12270, loss 3.94617, acc 1\n","2019-04-04T21:00:44.956468: step 12280, loss 4.19751, acc 0.9\n","2019-04-04T21:00:47.309693: step 12290, loss 4.18742, acc 0.9\n","2019-04-04T21:00:49.735316: step 12300, loss 4.10679, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:00:59.899974: step 12300, loss 6.26328, acc 0.789814\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.83%, Best = 83.96%\n","\n","2019-04-04T21:01:02.283344: step 12310, loss 4.07968, acc 0.95\n","2019-04-04T21:01:04.591991: step 12320, loss 3.94817, acc 1\n","2019-04-04T21:01:07.016432: step 12330, loss 3.95496, acc 1\n","2019-04-04T21:01:09.281588: step 12340, loss 3.99884, acc 0.95\n","2019-04-04T21:01:11.797872: step 12350, loss 3.93517, acc 1\n","2019-04-04T21:01:14.201556: step 12360, loss 4.06978, acc 0.95\n","2019-04-04T21:01:16.507335: step 12370, loss 3.98485, acc 1\n","2019-04-04T21:01:18.869274: step 12380, loss 4.11276, acc 0.95\n","2019-04-04T21:01:21.157881: step 12390, loss 3.94912, acc 1\n","2019-04-04T21:01:23.481794: step 12400, loss 3.93003, acc 1\n","\n","Evaluation:\n","2019-04-04T21:01:33.426431: step 12400, loss 6.07932, acc 0.787976\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.92%, Best = 83.96%\n","\n","2019-04-04T21:01:35.721842: step 12410, loss 3.95246, acc 1\n","2019-04-04T21:01:38.187926: step 12420, loss 3.92638, acc 1\n","2019-04-04T21:01:40.483987: step 12430, loss 4.0618, acc 0.95\n","2019-04-04T21:01:42.727069: step 12440, loss 4.0137, acc 0.95\n","2019-04-04T21:01:45.257948: step 12450, loss 3.9601, acc 1\n","2019-04-04T21:01:47.680711: step 12460, loss 3.98537, acc 1\n","2019-04-04T21:01:49.944564: step 12470, loss 4.04441, acc 0.95\n","2019-04-04T21:01:52.251138: step 12480, loss 4.00171, acc 0.95\n","2019-04-04T21:01:54.650565: step 12490, loss 3.94683, acc 1\n","2019-04-04T21:01:56.902449: step 12500, loss 3.94826, acc 1\n","\n","Evaluation:\n","2019-04-04T21:02:06.947298: step 12500, loss 6.48181, acc 0.79202\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.17%, Best = 83.96%\n","\n","2019-04-04T21:02:09.401919: step 12510, loss 4.0519, acc 0.95\n","2019-04-04T21:02:11.804889: step 12520, loss 4.02187, acc 0.95\n","2019-04-04T21:02:14.245797: step 12530, loss 3.92758, acc 1\n","2019-04-04T21:02:16.698419: step 12540, loss 3.91701, acc 1\n","2019-04-04T21:02:19.105572: step 12550, loss 3.92458, acc 1\n","2019-04-04T21:02:21.463258: step 12560, loss 3.91729, acc 1\n","2019-04-04T21:02:23.698195: step 12570, loss 3.92244, acc 1\n","2019-04-04T21:02:25.960922: step 12580, loss 3.94355, acc 1\n","2019-04-04T21:02:28.428080: step 12590, loss 3.9215, acc 1\n","2019-04-04T21:02:30.963789: step 12600, loss 3.92916, acc 1\n","\n","Evaluation:\n","2019-04-04T21:02:40.917264: step 12600, loss 6.43955, acc 0.79202\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.92%, Best = 83.96%\n","\n","2019-04-04T21:02:43.393413: step 12610, loss 3.91281, acc 1\n","2019-04-04T21:02:45.675916: step 12620, loss 3.95073, acc 1\n","2019-04-04T21:02:48.000326: step 12630, loss 3.95416, acc 1\n","2019-04-04T21:02:50.329660: step 12640, loss 3.90667, acc 1\n","2019-04-04T21:02:52.631027: step 12650, loss 3.91359, acc 1\n","2019-04-04T21:02:54.904405: step 12660, loss 4.00402, acc 0.95\n","2019-04-04T21:02:57.316107: step 12670, loss 4.04681, acc 0.9\n","2019-04-04T21:02:59.716802: step 12680, loss 3.91335, acc 1\n","2019-04-04T21:03:02.114228: step 12690, loss 3.92104, acc 1\n","2019-04-04T21:03:04.631080: step 12700, loss 3.99782, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:03:14.552494: step 12700, loss 6.23026, acc 0.794291\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.43%, Best = 83.96%\n","\n","2019-04-04T21:03:16.921985: step 12710, loss 3.92908, acc 1\n","2019-04-04T21:03:19.375651: step 12720, loss 4.00162, acc 0.9\n","2019-04-04T21:03:21.788869: step 12730, loss 3.90211, acc 1\n","2019-04-04T21:03:24.073545: step 12740, loss 3.92957, acc 1\n","2019-04-04T21:03:26.527496: step 12750, loss 4.02109, acc 0.95\n","2019-04-04T21:03:28.762250: step 12760, loss 3.92734, acc 1\n","2019-04-04T21:03:31.014753: step 12770, loss 3.91118, acc 1\n","2019-04-04T21:03:33.285848: step 12780, loss 3.90708, acc 1\n","2019-04-04T21:03:35.838535: step 12790, loss 3.92398, acc 1\n","2019-04-04T21:03:38.089357: step 12800, loss 3.89954, acc 1\n","\n","Evaluation:\n","2019-04-04T21:03:48.027012: step 12800, loss 6.156, acc 0.796432\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.36%, Best = 83.96%\n","\n","2019-04-04T21:03:50.508052: step 12810, loss 3.89545, acc 1\n","2019-04-04T21:03:52.853449: step 12820, loss 3.89969, acc 1\n","2019-04-04T21:03:55.374469: step 12830, loss 3.89402, acc 1\n","2019-04-04T21:03:57.808554: step 12840, loss 3.95291, acc 0.95\n","2019-04-04T21:04:00.264279: step 12850, loss 3.90484, acc 1\n","2019-04-04T21:04:02.590223: step 12860, loss 3.98459, acc 0.95\n","2019-04-04T21:04:04.910527: step 12870, loss 3.97609, acc 0.95\n","2019-04-04T21:04:07.136710: step 12880, loss 3.90347, acc 1\n","2019-04-04T21:04:09.610725: step 12890, loss 3.92345, acc 1\n","2019-04-04T21:04:11.999265: step 12900, loss 3.90071, acc 1\n","\n","Evaluation:\n","2019-04-04T21:04:22.036058: step 12900, loss 6.39544, acc 0.793555\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.96%\n","\n","2019-04-04T21:04:24.511650: step 12910, loss 3.90379, acc 1\n","2019-04-04T21:04:27.071416: step 12920, loss 3.8972, acc 1\n","2019-04-04T21:04:29.477348: step 12930, loss 3.89141, acc 1\n","2019-04-04T21:04:31.751186: step 12940, loss 4.02738, acc 0.95\n","2019-04-04T21:04:34.032567: step 12950, loss 3.97748, acc 0.95\n","2019-04-04T21:04:36.495847: step 12960, loss 3.99505, acc 0.95\n","2019-04-04T21:04:38.839005: step 12970, loss 3.89588, acc 1\n","2019-04-04T21:04:41.250765: step 12980, loss 3.93141, acc 1\n","2019-04-04T21:04:43.530812: step 12990, loss 3.89092, acc 1\n","2019-04-04T21:04:45.974038: step 13000, loss 3.88214, acc 1\n","\n","Evaluation:\n","2019-04-04T21:04:55.836555: step 13000, loss 6.43446, acc 0.79282\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.24%, Best = 83.96%\n","\n","2019-04-04T21:04:58.230642: step 13010, loss 3.8813, acc 1\n","2019-04-04T21:05:00.495569: step 13020, loss 3.93953, acc 1\n","2019-04-04T21:05:02.856544: step 13030, loss 3.88414, acc 1\n","2019-04-04T21:05:05.110018: step 13040, loss 3.89576, acc 1\n","2019-04-04T21:05:07.522302: step 13050, loss 3.95405, acc 0.95\n","2019-04-04T21:05:09.770401: step 13060, loss 3.89768, acc 1\n","2019-04-04T21:05:12.000628: step 13070, loss 3.89756, acc 1\n","2019-04-04T21:05:14.331346: step 13080, loss 3.91287, acc 0.95\n","2019-04-04T21:05:16.720184: step 13090, loss 3.87704, acc 1\n","2019-04-04T21:05:19.031199: step 13100, loss 4.10293, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:05:29.005464: step 13100, loss 6.34272, acc 0.788041\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.82%, Best = 83.96%\n","\n","2019-04-04T21:05:31.458682: step 13110, loss 3.93705, acc 0.95\n","2019-04-04T21:05:33.735512: step 13120, loss 3.88413, acc 1\n","2019-04-04T21:05:35.999959: step 13130, loss 3.92383, acc 0.95\n","2019-04-04T21:05:38.480815: step 13140, loss 3.9356, acc 0.95\n","2019-04-04T21:05:40.953762: step 13150, loss 3.91616, acc 1\n","2019-04-04T21:05:43.524330: step 13160, loss 3.87676, acc 1\n","2019-04-04T21:05:45.683396: step 13170, loss 4.16484, acc 0.95\n","2019-04-04T21:05:48.055988: step 13180, loss 3.88332, acc 1\n","2019-04-04T21:05:50.428602: step 13190, loss 3.90612, acc 0.95\n","2019-04-04T21:05:52.862683: step 13200, loss 3.87586, acc 1\n","\n","Evaluation:\n","2019-04-04T21:06:02.924184: step 13200, loss 6.51863, acc 0.794961\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.41%, Best = 83.96%\n","\n","2019-04-04T21:06:05.350892: step 13210, loss 3.88118, acc 1\n","2019-04-04T21:06:07.674244: step 13220, loss 4.0448, acc 0.95\n","2019-04-04T21:06:09.961114: step 13230, loss 3.8712, acc 1\n","2019-04-04T21:06:12.246143: step 13240, loss 3.86714, acc 1\n","2019-04-04T21:06:14.451611: step 13250, loss 3.91595, acc 0.95\n","2019-04-04T21:06:16.899975: step 13260, loss 3.87565, acc 1\n","2019-04-04T21:06:19.193377: step 13270, loss 3.94895, acc 0.95\n","2019-04-04T21:06:21.731684: step 13280, loss 3.88263, acc 1\n","2019-04-04T21:06:23.889254: step 13290, loss 3.98493, acc 0.95\n","2019-04-04T21:06:26.252190: step 13300, loss 3.85898, acc 1\n","\n","Evaluation:\n","2019-04-04T21:06:36.210677: step 13300, loss 6.42571, acc 0.790247\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.91%, Best = 83.96%\n","\n","2019-04-04T21:06:38.765925: step 13310, loss 3.86138, acc 1\n","2019-04-04T21:06:41.200403: step 13320, loss 3.8851, acc 1\n","2019-04-04T21:06:43.548440: step 13330, loss 3.86965, acc 1\n","2019-04-04T21:06:45.794412: step 13340, loss 3.85924, acc 1\n","2019-04-04T21:06:47.993903: step 13350, loss 3.88654, acc 1\n","2019-04-04T21:06:50.368707: step 13360, loss 3.86421, acc 1\n","2019-04-04T21:06:52.713419: step 13370, loss 4.01704, acc 0.95\n","2019-04-04T21:06:55.002351: step 13380, loss 3.8537, acc 1\n","2019-04-04T21:06:57.627663: step 13390, loss 4.14316, acc 0.9\n","2019-04-04T21:06:59.885869: step 13400, loss 3.95856, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:07:09.787749: step 13400, loss 6.30387, acc 0.798335\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.72%, Best = 83.96%\n","\n","2019-04-04T21:07:12.353490: step 13410, loss 3.85906, acc 1\n","2019-04-04T21:07:14.814409: step 13420, loss 4.04897, acc 0.85\n","2019-04-04T21:07:17.152914: step 13430, loss 3.89481, acc 1\n","2019-04-04T21:07:19.846607: step 13440, loss 4.02695, acc 0.95\n","2019-04-04T21:07:22.422665: step 13450, loss 3.93582, acc 1\n","2019-04-04T21:07:24.675753: step 13460, loss 3.85466, acc 1\n","2019-04-04T21:07:26.899469: step 13470, loss 3.92497, acc 0.95\n","2019-04-04T21:07:29.134327: step 13480, loss 3.86675, acc 1\n","2019-04-04T21:07:31.613100: step 13490, loss 3.87468, acc 1\n","2019-04-04T21:07:33.858430: step 13500, loss 3.87366, acc 1\n","\n","Evaluation:\n","2019-04-04T21:07:43.830797: step 13500, loss 6.27487, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.5%, Best = 83.96%\n","\n","2019-04-04T21:07:46.318625: step 13510, loss 3.85043, acc 1\n","2019-04-04T21:07:48.619129: step 13520, loss 3.87978, acc 1\n","2019-04-04T21:07:51.097358: step 13530, loss 3.84998, acc 1\n","2019-04-04T21:07:53.371596: step 13540, loss 3.84648, acc 1\n","2019-04-04T21:07:55.996695: step 13550, loss 3.84956, acc 1\n","2019-04-04T21:07:58.303930: step 13560, loss 3.97281, acc 0.95\n","2019-04-04T21:08:00.751617: step 13570, loss 3.84519, acc 1\n","2019-04-04T21:08:03.132053: step 13580, loss 3.83882, acc 1\n","2019-04-04T21:08:05.598028: step 13590, loss 3.83693, acc 1\n","2019-04-04T21:08:07.884755: step 13600, loss 3.96444, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:08:17.850751: step 13600, loss 5.9808, acc 0.795329\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.48%, Best = 83.96%\n","\n","2019-04-04T21:08:20.296719: step 13610, loss 3.83721, acc 1\n","2019-04-04T21:08:22.839080: step 13620, loss 3.8378, acc 1\n","2019-04-04T21:08:25.367433: step 13630, loss 3.84035, acc 1\n","2019-04-04T21:08:27.775677: step 13640, loss 3.83492, acc 1\n","2019-04-04T21:08:29.951772: step 13650, loss 3.85086, acc 1\n","2019-04-04T21:08:32.288839: step 13660, loss 3.84705, acc 1\n","2019-04-04T21:08:34.702343: step 13670, loss 3.83281, acc 1\n","2019-04-04T21:08:37.074095: step 13680, loss 3.85346, acc 1\n","2019-04-04T21:08:39.546941: step 13690, loss 3.90799, acc 0.95\n","2019-04-04T21:08:41.911737: step 13700, loss 3.82901, acc 1\n","\n","Evaluation:\n","2019-04-04T21:08:51.862962: step 13700, loss 6.36927, acc 0.79827\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.7%, Best = 83.96%\n","\n","2019-04-04T21:08:54.374742: step 13710, loss 3.83405, acc 1\n","2019-04-04T21:08:56.708749: step 13720, loss 3.93086, acc 0.95\n","2019-04-04T21:08:59.114746: step 13730, loss 3.84763, acc 1\n","2019-04-04T21:09:01.524553: step 13740, loss 3.83071, acc 1\n","2019-04-04T21:09:03.639308: step 13750, loss 4.05947, acc 0.95\n","2019-04-04T21:09:05.944805: step 13760, loss 3.82863, acc 1\n","2019-04-04T21:09:08.474621: step 13770, loss 3.82409, acc 1\n","2019-04-04T21:09:10.842970: step 13780, loss 3.91756, acc 0.95\n","2019-04-04T21:09:13.265672: step 13790, loss 3.88219, acc 0.95\n","2019-04-04T21:09:15.536921: step 13800, loss 3.82091, acc 1\n","\n","Evaluation:\n","2019-04-04T21:09:25.485677: step 13800, loss 6.25956, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.23%, Best = 83.96%\n","\n","2019-04-04T21:09:27.720434: step 13810, loss 3.82158, acc 1\n","2019-04-04T21:09:30.198109: step 13820, loss 3.84079, acc 1\n","2019-04-04T21:09:32.606723: step 13830, loss 3.87164, acc 0.95\n","2019-04-04T21:09:34.936235: step 13840, loss 3.82408, acc 1\n","2019-04-04T21:09:37.091678: step 13850, loss 3.89195, acc 0.95\n","2019-04-04T21:09:39.400053: step 13860, loss 3.8169, acc 1\n","2019-04-04T21:09:41.585267: step 13870, loss 4.08961, acc 0.95\n","2019-04-04T21:09:43.803880: step 13880, loss 3.82517, acc 1\n","2019-04-04T21:09:46.395275: step 13890, loss 3.82897, acc 1\n","2019-04-04T21:09:48.669213: step 13900, loss 4.18956, acc 0.9\n","\n","Evaluation:\n","2019-04-04T21:09:58.671196: step 13900, loss 6.06442, acc 0.792755\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.96%\n","\n","2019-04-04T21:10:01.154254: step 13910, loss 3.81316, acc 1\n","2019-04-04T21:10:03.520862: step 13920, loss 3.92516, acc 0.95\n","2019-04-04T21:10:05.935805: step 13930, loss 3.82597, acc 1\n","2019-04-04T21:10:08.425049: step 13940, loss 3.81552, acc 1\n","2019-04-04T21:10:10.707597: step 13950, loss 3.93103, acc 0.95\n","2019-04-04T21:10:12.987016: step 13960, loss 3.8365, acc 1\n","2019-04-04T21:10:15.290412: step 13970, loss 3.80828, acc 1\n","2019-04-04T21:10:17.654425: step 13980, loss 3.91347, acc 0.95\n","2019-04-04T21:10:20.180562: step 13990, loss 3.81054, acc 1\n","2019-04-04T21:10:22.623975: step 14000, loss 3.81731, acc 1\n","\n","Evaluation:\n","2019-04-04T21:10:32.582764: step 14000, loss 6.04424, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.76%, Best = 83.96%\n","\n","2019-04-04T21:10:34.946549: step 14010, loss 3.81434, acc 1\n","2019-04-04T21:10:37.320800: step 14020, loss 3.91591, acc 0.9\n","2019-04-04T21:10:39.574056: step 14030, loss 3.86484, acc 0.95\n","2019-04-04T21:10:41.955296: step 14040, loss 3.82868, acc 1\n","2019-04-04T21:10:44.408419: step 14050, loss 3.80534, acc 1\n","2019-04-04T21:10:46.921097: step 14060, loss 3.80215, acc 1\n","2019-04-04T21:10:49.221963: step 14070, loss 3.80055, acc 1\n","2019-04-04T21:10:51.490000: step 14080, loss 3.80081, acc 1\n","2019-04-04T21:10:53.835743: step 14090, loss 3.81436, acc 1\n","2019-04-04T21:10:56.110453: step 14100, loss 3.80864, acc 1\n","\n","Evaluation:\n","2019-04-04T21:11:06.061881: step 14100, loss 6.19283, acc 0.794226\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.99%, Best = 83.96%\n","\n","2019-04-04T21:11:08.564210: step 14110, loss 3.88059, acc 0.95\n","2019-04-04T21:11:10.874770: step 14120, loss 3.80429, acc 1\n","2019-04-04T21:11:13.199033: step 14130, loss 3.8012, acc 1\n","2019-04-04T21:11:15.671431: step 14140, loss 3.80998, acc 1\n","2019-04-04T21:11:18.266103: step 14150, loss 3.8011, acc 1\n","2019-04-04T21:11:20.467602: step 14160, loss 3.79437, acc 1\n","2019-04-04T21:11:22.923972: step 14170, loss 3.79701, acc 1\n","2019-04-04T21:11:25.324826: step 14180, loss 3.81082, acc 1\n","2019-04-04T21:11:27.659713: step 14190, loss 3.80353, acc 1\n","2019-04-04T21:11:30.263035: step 14200, loss 3.82281, acc 1\n","\n","Evaluation:\n","2019-04-04T21:11:40.232075: step 14200, loss 5.96085, acc 0.795394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.39%, Best = 83.96%\n","\n","2019-04-04T21:11:42.473363: step 14210, loss 3.80783, acc 1\n","2019-04-04T21:11:44.856633: step 14220, loss 3.79947, acc 1\n","2019-04-04T21:11:47.298100: step 14230, loss 4.20204, acc 0.95\n","2019-04-04T21:11:49.560004: step 14240, loss 3.87771, acc 0.95\n","2019-04-04T21:11:51.936641: step 14250, loss 3.83378, acc 0.95\n","2019-04-04T21:11:54.184832: step 14260, loss 3.83567, acc 1\n","2019-04-04T21:11:56.565166: step 14270, loss 3.78999, acc 1\n","2019-04-04T21:11:59.048304: step 14280, loss 3.81979, acc 1\n","2019-04-04T21:12:01.516945: step 14290, loss 3.9601, acc 0.9\n","2019-04-04T21:12:03.774551: step 14300, loss 3.80988, acc 1\n","\n","Evaluation:\n","2019-04-04T21:12:13.757679: step 14300, loss 5.89302, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.09%, Best = 83.96%\n","\n","2019-04-04T21:12:16.161936: step 14310, loss 3.84849, acc 1\n","2019-04-04T21:12:18.462318: step 14320, loss 3.78946, acc 1\n","2019-04-04T21:12:20.701358: step 14330, loss 3.97276, acc 0.9\n","2019-04-04T21:12:23.144313: step 14340, loss 3.85939, acc 0.95\n","2019-04-04T21:12:25.683535: step 14350, loss 3.86092, acc 0.95\n","2019-04-04T21:12:27.938950: step 14360, loss 3.78226, acc 1\n","2019-04-04T21:12:30.286030: step 14370, loss 3.8797, acc 0.95\n","2019-04-04T21:12:32.650811: step 14380, loss 3.80375, acc 1\n","2019-04-04T21:12:35.020835: step 14390, loss 3.8677, acc 0.95\n","2019-04-04T21:12:37.354589: step 14400, loss 3.78245, acc 1\n","\n","Evaluation:\n","2019-04-04T21:12:47.354086: step 14400, loss 6.24442, acc 0.796497\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.48%, Best = 83.96%\n","\n","2019-04-04T21:12:50.057205: step 14410, loss 3.83712, acc 0.95\n","2019-04-04T21:12:52.356765: step 14420, loss 3.87881, acc 0.95\n","2019-04-04T21:12:54.854966: step 14430, loss 3.87838, acc 0.95\n","2019-04-04T21:12:57.302595: step 14440, loss 3.79338, acc 1\n","2019-04-04T21:12:59.600548: step 14450, loss 3.77785, acc 1\n","2019-04-04T21:13:01.893573: step 14460, loss 3.80648, acc 1\n","2019-04-04T21:13:04.464588: step 14470, loss 3.77992, acc 1\n","2019-04-04T21:13:06.817664: step 14480, loss 3.77662, acc 1\n","2019-04-04T21:13:09.286241: step 14490, loss 3.82087, acc 1\n","2019-04-04T21:13:11.617791: step 14500, loss 3.79145, acc 1\n","\n","Evaluation:\n","2019-04-04T21:13:21.584566: step 14500, loss 6.22408, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.61%, Best = 83.96%\n","\n","2019-04-04T21:13:24.007482: step 14510, loss 3.8599, acc 0.95\n","2019-04-04T21:13:26.489451: step 14520, loss 4.04513, acc 0.95\n","2019-04-04T21:13:28.863413: step 14530, loss 3.7742, acc 1\n","2019-04-04T21:13:31.134364: step 14540, loss 3.82723, acc 0.95\n","2019-04-04T21:13:33.335872: step 14550, loss 3.76908, acc 1\n","2019-04-04T21:13:35.694746: step 14560, loss 3.83181, acc 0.95\n","2019-04-04T21:13:37.948042: step 14570, loss 3.95244, acc 0.95\n","2019-04-04T21:13:40.425765: step 14580, loss 3.81649, acc 1\n","2019-04-04T21:13:42.644196: step 14590, loss 3.78989, acc 1\n","2019-04-04T21:13:44.859060: step 14600, loss 3.95867, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:13:54.810766: step 14600, loss 5.92904, acc 0.796129\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.46%, Best = 83.96%\n","\n","2019-04-04T21:13:57.477419: step 14610, loss 3.76506, acc 1\n","2019-04-04T21:13:59.792723: step 14620, loss 3.76408, acc 1\n","2019-04-04T21:14:02.063290: step 14630, loss 3.76248, acc 1\n","2019-04-04T21:14:04.731523: step 14640, loss 3.76354, acc 1\n","2019-04-04T21:14:07.088893: step 14650, loss 3.78337, acc 1\n","2019-04-04T21:14:09.509580: step 14660, loss 3.86541, acc 0.95\n","2019-04-04T21:14:11.794337: step 14670, loss 3.83052, acc 0.95\n","2019-04-04T21:14:14.059447: step 14680, loss 3.75865, acc 1\n","2019-04-04T21:14:16.332650: step 14690, loss 3.76449, acc 1\n","2019-04-04T21:14:18.739489: step 14700, loss 3.75782, acc 1\n","\n","Evaluation:\n","2019-04-04T21:14:28.688698: step 14700, loss 5.98936, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.37%, Best = 83.96%\n","\n","2019-04-04T21:14:31.023012: step 14710, loss 3.78316, acc 1\n","2019-04-04T21:14:33.198685: step 14720, loss 4.04142, acc 0.95\n","2019-04-04T21:14:35.557402: step 14730, loss 3.7543, acc 1\n","2019-04-04T21:14:37.995395: step 14740, loss 3.75549, acc 1\n","2019-04-04T21:14:40.530730: step 14750, loss 3.8697, acc 0.95\n","2019-04-04T21:14:43.078055: step 14760, loss 3.75408, acc 1\n","2019-04-04T21:14:45.930736: step 14770, loss 3.75315, acc 1\n","2019-04-04T21:14:48.208908: step 14780, loss 3.86271, acc 0.95\n","2019-04-04T21:14:50.571206: step 14790, loss 3.75382, acc 1\n","2019-04-04T21:14:53.004302: step 14800, loss 3.88872, acc 0.9\n","\n","Evaluation:\n","2019-04-04T21:15:02.998425: step 14800, loss 6.03306, acc 0.794291\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.11%, Best = 83.96%\n","\n","2019-04-04T21:15:05.426413: step 14810, loss 3.75837, acc 1\n","2019-04-04T21:15:07.762831: step 14820, loss 3.74722, acc 1\n","2019-04-04T21:15:10.094672: step 14830, loss 3.76527, acc 1\n","2019-04-04T21:15:12.404325: step 14840, loss 3.74975, acc 1\n","2019-04-04T21:15:14.663449: step 14850, loss 3.74605, acc 1\n","2019-04-04T21:15:17.050013: step 14860, loss 3.74371, acc 1\n","2019-04-04T21:15:19.373817: step 14870, loss 3.75268, acc 1\n","2019-04-04T21:15:21.824745: step 14880, loss 3.81271, acc 0.95\n","2019-04-04T21:15:24.161472: step 14890, loss 3.74327, acc 1\n","2019-04-04T21:15:26.456721: step 14900, loss 3.78179, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:15:36.335248: step 14900, loss 6.17722, acc 0.791349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.99%, Best = 83.96%\n","\n","2019-04-04T21:15:38.887049: step 14910, loss 3.76091, acc 1\n","2019-04-04T21:15:41.210207: step 14920, loss 3.74817, acc 1\n","2019-04-04T21:15:43.448080: step 14930, loss 3.73913, acc 1\n","2019-04-04T21:15:45.711754: step 14940, loss 3.7418, acc 1\n","2019-04-04T21:15:48.242453: step 14950, loss 3.73949, acc 1\n","2019-04-04T21:15:50.648082: step 14960, loss 3.86809, acc 0.95\n","2019-04-04T21:15:52.925771: step 14970, loss 3.76632, acc 1\n","2019-04-04T21:15:55.301561: step 14980, loss 3.79469, acc 0.95\n","2019-04-04T21:15:57.491832: step 14990, loss 3.77529, acc 1\n","2019-04-04T21:15:59.717020: step 15000, loss 3.73744, acc 1\n","\n","Evaluation:\n","2019-04-04T21:16:09.746646: step 15000, loss 6.13536, acc 0.793555\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.96%\n","\n","2019-04-04T21:16:11.947687: step 15010, loss 3.86727, acc 0.95\n","2019-04-04T21:16:14.149172: step 15020, loss 3.90683, acc 0.9\n","2019-04-04T21:16:16.464241: step 15030, loss 3.7756, acc 0.95\n","2019-04-04T21:16:18.748419: step 15040, loss 3.90984, acc 0.9\n","2019-04-04T21:16:21.185658: step 15050, loss 3.85382, acc 0.95\n","2019-04-04T21:16:23.637085: step 15060, loss 3.74596, acc 1\n","2019-04-04T21:16:26.034026: step 15070, loss 3.77201, acc 0.95\n","2019-04-04T21:16:28.548108: step 15080, loss 3.73412, acc 1\n","2019-04-04T21:16:30.805121: step 15090, loss 3.72741, acc 1\n","2019-04-04T21:16:32.993129: step 15100, loss 3.72923, acc 1\n","\n","Evaluation:\n","2019-04-04T21:16:42.991075: step 15100, loss 6.24209, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.96%\n","\n","2019-04-04T21:16:45.410269: step 15110, loss 3.75544, acc 1\n","2019-04-04T21:16:47.900299: step 15120, loss 3.73629, acc 1\n","2019-04-04T21:16:50.583429: step 15130, loss 3.79092, acc 0.95\n","2019-04-04T21:16:52.968404: step 15140, loss 3.76133, acc 1\n","2019-04-04T21:16:55.305264: step 15150, loss 3.72787, acc 1\n","2019-04-04T21:16:57.685902: step 15160, loss 3.74627, acc 1\n","2019-04-04T21:17:00.254213: step 15170, loss 3.86099, acc 0.9\n","2019-04-04T21:17:02.856538: step 15180, loss 3.72233, acc 1\n","2019-04-04T21:17:05.123641: step 15190, loss 3.74776, acc 1\n","2019-04-04T21:17:07.478641: step 15200, loss 3.73226, acc 1\n","\n","Evaluation:\n","2019-04-04T21:17:17.356909: step 15200, loss 6.28293, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.96%\n","\n","2019-04-04T21:17:19.880664: step 15210, loss 3.82955, acc 0.95\n","2019-04-04T21:17:22.140378: step 15220, loss 3.72344, acc 1\n","2019-04-04T21:17:24.298679: step 15230, loss 3.95913, acc 0.95\n","2019-04-04T21:17:26.670751: step 15240, loss 3.72587, acc 1\n","2019-04-04T21:17:29.154255: step 15250, loss 3.71961, acc 1\n","2019-04-04T21:17:31.521032: step 15260, loss 3.95563, acc 0.95\n","2019-04-04T21:17:33.891565: step 15270, loss 3.71975, acc 1\n","2019-04-04T21:17:36.207077: step 15280, loss 3.74672, acc 1\n","2019-04-04T21:17:38.451299: step 15290, loss 3.71869, acc 1\n","2019-04-04T21:17:40.737980: step 15300, loss 3.80238, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:17:50.710369: step 15300, loss 6.33782, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.97%, Best = 83.96%\n","\n","2019-04-04T21:17:53.077643: step 15310, loss 3.71289, acc 1\n","2019-04-04T21:17:55.590353: step 15320, loss 3.72635, acc 1\n","2019-04-04T21:17:57.793318: step 15330, loss 3.72397, acc 1\n","2019-04-04T21:18:00.214222: step 15340, loss 3.75047, acc 1\n","2019-04-04T21:18:02.944894: step 15350, loss 3.71844, acc 1\n","2019-04-04T21:18:05.342968: step 15360, loss 3.7301, acc 1\n","2019-04-04T21:18:07.812488: step 15370, loss 3.70764, acc 1\n","2019-04-04T21:18:09.914574: step 15380, loss 3.71662, acc 1\n","2019-04-04T21:18:12.481310: step 15390, loss 3.82593, acc 0.95\n","2019-04-04T21:18:14.881206: step 15400, loss 3.70972, acc 1\n","\n","Evaluation:\n","2019-04-04T21:18:24.776672: step 15400, loss 6.0389, acc 0.791349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.11%, Best = 83.96%\n","\n","2019-04-04T21:18:27.143500: step 15410, loss 3.70374, acc 1\n","2019-04-04T21:18:29.400125: step 15420, loss 3.72343, acc 1\n","2019-04-04T21:18:31.763400: step 15430, loss 3.70283, acc 1\n","2019-04-04T21:18:33.984334: step 15440, loss 3.89965, acc 0.85\n","2019-04-04T21:18:36.229229: step 15450, loss 3.72875, acc 1\n","2019-04-04T21:18:38.709733: step 15460, loss 3.8219, acc 0.95\n","2019-04-04T21:18:41.102551: step 15470, loss 3.72774, acc 1\n","2019-04-04T21:18:43.232278: step 15480, loss 3.7137, acc 1\n","2019-04-04T21:18:45.526565: step 15490, loss 3.7254, acc 1\n","2019-04-04T21:18:47.800127: step 15500, loss 3.71456, acc 1\n","\n","Evaluation:\n","2019-04-04T21:18:57.784440: step 15500, loss 6.09342, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.41%, Best = 83.96%\n","\n","2019-04-04T21:19:00.129739: step 15510, loss 3.70526, acc 1\n","2019-04-04T21:19:02.347001: step 15520, loss 3.71254, acc 1\n","2019-04-04T21:19:04.825006: step 15530, loss 3.70597, acc 1\n","2019-04-04T21:19:07.477805: step 15540, loss 3.78335, acc 0.95\n","2019-04-04T21:19:09.866608: step 15550, loss 3.73113, acc 1\n","2019-04-04T21:19:12.402513: step 15560, loss 3.71852, acc 1\n","2019-04-04T21:19:14.627187: step 15570, loss 3.69381, acc 1\n","2019-04-04T21:19:16.947113: step 15580, loss 3.72265, acc 1\n","2019-04-04T21:19:19.388450: step 15590, loss 3.70483, acc 1\n","2019-04-04T21:19:21.870436: step 15600, loss 3.86214, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:19:31.836099: step 15600, loss 6.01435, acc 0.798335\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.57%, Best = 83.96%\n","\n","2019-04-04T21:19:34.234735: step 15610, loss 3.72502, acc 1\n","2019-04-04T21:19:36.451788: step 15620, loss 3.91091, acc 0.95\n","2019-04-04T21:19:38.473923: step 15630, loss 3.8054, acc 0.95\n","2019-04-04T21:19:40.869273: step 15640, loss 3.6895, acc 1\n","2019-04-04T21:19:43.220660: step 15650, loss 3.69992, acc 1\n","2019-04-04T21:19:45.537297: step 15660, loss 3.68823, acc 1\n","2019-04-04T21:19:47.993129: step 15670, loss 3.70507, acc 1\n","2019-04-04T21:19:50.282388: step 15680, loss 3.68468, acc 1\n","2019-04-04T21:19:52.673325: step 15690, loss 3.68385, acc 1\n","2019-04-04T21:19:55.124715: step 15700, loss 3.68551, acc 1\n","\n","Evaluation:\n","2019-04-04T21:20:05.098107: step 15700, loss 5.84878, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.89%, Best = 83.96%\n","\n","2019-04-04T21:20:07.422813: step 15710, loss 3.69015, acc 1\n","2019-04-04T21:20:09.649662: step 15720, loss 3.69457, acc 1\n","2019-04-04T21:20:11.994185: step 15730, loss 3.68393, acc 1\n","2019-04-04T21:20:14.665679: step 15740, loss 3.72777, acc 0.95\n","2019-04-04T21:20:16.942920: step 15750, loss 3.71635, acc 1\n","2019-04-04T21:20:19.546172: step 15760, loss 3.68968, acc 1\n","2019-04-04T21:20:22.041465: step 15770, loss 3.68404, acc 1\n","2019-04-04T21:20:24.637498: step 15780, loss 3.68614, acc 1\n","2019-04-04T21:20:26.887095: step 15790, loss 3.67801, acc 1\n","2019-04-04T21:20:29.379425: step 15800, loss 3.69637, acc 1\n","\n","Evaluation:\n","2019-04-04T21:20:39.338493: step 15800, loss 6.07537, acc 0.794961\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.21%, Best = 83.96%\n","\n","2019-04-04T21:20:41.726600: step 15810, loss 3.70539, acc 1\n","2019-04-04T21:20:43.998951: step 15820, loss 3.8158, acc 0.95\n","2019-04-04T21:20:46.112714: step 15830, loss 3.7009, acc 1\n","2019-04-04T21:20:48.526999: step 15840, loss 3.69173, acc 1\n","2019-04-04T21:20:50.975612: step 15850, loss 3.67481, acc 1\n","2019-04-04T21:20:53.279767: step 15860, loss 3.68986, acc 1\n","2019-04-04T21:20:55.810488: step 15870, loss 3.67485, acc 1\n","2019-04-04T21:20:58.143300: step 15880, loss 3.67177, acc 1\n","2019-04-04T21:21:00.392867: step 15890, loss 3.67887, acc 1\n","2019-04-04T21:21:02.593514: step 15900, loss 3.73153, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:21:12.625791: step 15900, loss 6.06074, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.12%, Best = 83.96%\n","\n","2019-04-04T21:21:14.963391: step 15910, loss 3.68789, acc 1\n","2019-04-04T21:21:17.386926: step 15920, loss 3.67104, acc 1\n","2019-04-04T21:21:19.836966: step 15930, loss 3.66693, acc 1\n","2019-04-04T21:21:22.144808: step 15940, loss 3.66628, acc 1\n","2019-04-04T21:21:24.655771: step 15950, loss 3.66887, acc 1\n","2019-04-04T21:21:26.988518: step 15960, loss 3.6646, acc 1\n","2019-04-04T21:21:29.309641: step 15970, loss 3.80615, acc 0.95\n","2019-04-04T21:21:31.819368: step 15980, loss 3.66577, acc 1\n","2019-04-04T21:21:34.069865: step 15990, loss 3.67449, acc 1\n","2019-04-04T21:21:36.407441: step 16000, loss 3.67425, acc 1\n","\n","Evaluation:\n","2019-04-04T21:21:46.330890: step 16000, loss 6.2191, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.04%, Best = 83.96%\n","\n","2019-04-04T21:21:48.679175: step 16010, loss 3.66371, acc 1\n","2019-04-04T21:21:50.953432: step 16020, loss 3.68103, acc 1\n","2019-04-04T21:21:53.462059: step 16030, loss 3.66806, acc 1\n","2019-04-04T21:21:55.867585: step 16040, loss 3.66411, acc 1\n","2019-04-04T21:21:58.133469: step 16050, loss 3.6858, acc 1\n","2019-04-04T21:22:00.485951: step 16060, loss 3.90406, acc 0.9\n","2019-04-04T21:22:02.673090: step 16070, loss 3.65778, acc 1\n","2019-04-04T21:22:05.374314: step 16080, loss 3.65841, acc 1\n","2019-04-04T21:22:07.693072: step 16090, loss 3.79952, acc 0.95\n","2019-04-04T21:22:10.063224: step 16100, loss 3.66461, acc 1\n","\n","Evaluation:\n","2019-04-04T21:22:20.023698: step 16100, loss 6.27582, acc 0.796799\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.62%, Best = 83.96%\n","\n","2019-04-04T21:22:22.502133: step 16110, loss 3.65488, acc 1\n","2019-04-04T21:22:24.839297: step 16120, loss 3.65576, acc 1\n","2019-04-04T21:22:27.029199: step 16130, loss 3.65962, acc 1\n","2019-04-04T21:22:29.530848: step 16140, loss 3.65228, acc 1\n","2019-04-04T21:22:32.063187: step 16150, loss 3.66575, acc 1\n","2019-04-04T21:22:34.445998: step 16160, loss 3.68806, acc 1\n","2019-04-04T21:22:36.879963: step 16170, loss 3.66005, acc 1\n","2019-04-04T21:22:39.371219: step 16180, loss 3.65271, acc 1\n","2019-04-04T21:22:41.750641: step 16190, loss 3.75219, acc 0.95\n","2019-04-04T21:22:44.037523: step 16200, loss 3.74096, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:22:54.024601: step 16200, loss 6.09125, acc 0.785099\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.58%, Best = 83.96%\n","\n","2019-04-04T21:22:56.472245: step 16210, loss 3.6504, acc 1\n","2019-04-04T21:22:58.798791: step 16220, loss 3.75189, acc 0.95\n","2019-04-04T21:23:01.136990: step 16230, loss 3.65124, acc 1\n","2019-04-04T21:23:03.608430: step 16240, loss 3.68584, acc 0.95\n","2019-04-04T21:23:06.155374: step 16250, loss 3.64563, acc 1\n","2019-04-04T21:23:08.524078: step 16260, loss 3.64615, acc 1\n","2019-04-04T21:23:10.877037: step 16270, loss 3.64661, acc 1\n","2019-04-04T21:23:13.159248: step 16280, loss 3.65884, acc 1\n","2019-04-04T21:23:15.395474: step 16290, loss 3.65304, acc 1\n","2019-04-04T21:23:17.866957: step 16300, loss 3.66812, acc 1\n","\n","Evaluation:\n","2019-04-04T21:23:27.877834: step 16300, loss 6.51673, acc 0.795329\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.38%, Best = 83.96%\n","\n","2019-04-04T21:23:30.448609: step 16310, loss 3.68775, acc 0.95\n","2019-04-04T21:23:32.710320: step 16320, loss 4.19841, acc 0.95\n","2019-04-04T21:23:35.072560: step 16330, loss 3.64155, acc 1\n","2019-04-04T21:23:37.438693: step 16340, loss 3.70924, acc 0.95\n","2019-04-04T21:23:39.773608: step 16350, loss 3.66012, acc 1\n","2019-04-04T21:23:42.128867: step 16360, loss 3.69239, acc 0.95\n","2019-04-04T21:23:44.410357: step 16370, loss 3.63676, acc 1\n","2019-04-04T21:23:46.775881: step 16380, loss 3.84454, acc 0.95\n","2019-04-04T21:23:49.040341: step 16390, loss 3.64771, acc 1\n","2019-04-04T21:23:51.673021: step 16400, loss 3.6354, acc 1\n","\n","Evaluation:\n","2019-04-04T21:24:01.701805: step 16400, loss 6.53706, acc 0.796064\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.38%, Best = 83.96%\n","\n","2019-04-04T21:24:04.041528: step 16410, loss 3.6338, acc 1\n","2019-04-04T21:24:06.205057: step 16420, loss 3.67778, acc 1\n","2019-04-04T21:24:08.388965: step 16430, loss 3.6446, acc 1\n","2019-04-04T21:24:10.730231: step 16440, loss 3.64126, acc 1\n","2019-04-04T21:24:13.276559: step 16450, loss 3.63329, acc 1\n","2019-04-04T21:24:15.639546: step 16460, loss 3.63048, acc 1\n","2019-04-04T21:24:17.961439: step 16470, loss 3.63193, acc 1\n","2019-04-04T21:24:20.290208: step 16480, loss 3.68496, acc 0.95\n","2019-04-04T21:24:22.790996: step 16490, loss 3.84627, acc 0.95\n","2019-04-04T21:24:25.357942: step 16500, loss 3.69337, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:24:35.399076: step 16500, loss 6.33269, acc 0.792755\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.87%, Best = 83.96%\n","\n","2019-04-04T21:24:38.135050: step 16510, loss 3.63996, acc 1\n","2019-04-04T21:24:40.572691: step 16520, loss 3.62573, acc 1\n","2019-04-04T21:24:42.766577: step 16530, loss 3.73695, acc 0.95\n","2019-04-04T21:24:45.061035: step 16540, loss 3.63133, acc 1\n","2019-04-04T21:24:47.270272: step 16550, loss 3.62427, acc 1\n","2019-04-04T21:24:49.661509: step 16560, loss 3.63758, acc 1\n","2019-04-04T21:24:51.974959: step 16570, loss 3.62496, acc 1\n","2019-04-04T21:24:54.374336: step 16580, loss 3.62874, acc 1\n","2019-04-04T21:24:56.916602: step 16590, loss 3.62388, acc 1\n","2019-04-04T21:24:59.240416: step 16600, loss 3.63997, acc 1\n","\n","Evaluation:\n","2019-04-04T21:25:09.216770: step 16600, loss 6.18698, acc 0.79349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.17%, Best = 83.96%\n","\n","2019-04-04T21:25:11.544631: step 16610, loss 3.74349, acc 0.9\n","2019-04-04T21:25:14.180660: step 16620, loss 3.62032, acc 1\n","2019-04-04T21:25:16.557349: step 16630, loss 3.64072, acc 1\n","2019-04-04T21:25:19.060162: step 16640, loss 3.69061, acc 0.95\n","2019-04-04T21:25:21.464560: step 16650, loss 3.62144, acc 1\n","2019-04-04T21:25:23.656184: step 16660, loss 3.61909, acc 1\n","2019-04-04T21:25:25.936231: step 16670, loss 3.61986, acc 1\n","2019-04-04T21:25:28.252301: step 16680, loss 3.62909, acc 1\n","2019-04-04T21:25:30.626005: step 16690, loss 3.6375, acc 1\n","2019-04-04T21:25:32.818662: step 16700, loss 3.62357, acc 1\n","\n","Evaluation:\n","2019-04-04T21:25:42.836868: step 16700, loss 5.96167, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.23%, Best = 83.96%\n","\n","2019-04-04T21:25:45.272788: step 16710, loss 3.61893, acc 1\n","2019-04-04T21:25:47.838951: step 16720, loss 3.62395, acc 1\n","2019-04-04T21:25:50.103843: step 16730, loss 3.61237, acc 1\n","2019-04-04T21:25:52.527685: step 16740, loss 3.61188, acc 1\n","2019-04-04T21:25:54.982082: step 16750, loss 3.61714, acc 1\n","2019-04-04T21:25:57.285565: step 16760, loss 3.60875, acc 1\n","2019-04-04T21:25:59.672629: step 16770, loss 3.61308, acc 1\n","2019-04-04T21:26:02.078898: step 16780, loss 3.60737, acc 1\n","2019-04-04T21:26:04.514082: step 16790, loss 3.99038, acc 0.95\n","2019-04-04T21:26:06.840671: step 16800, loss 3.60756, acc 1\n","\n","Evaluation:\n","2019-04-04T21:26:16.824040: step 16800, loss 6.29956, acc 0.79269\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.96%\n","\n","2019-04-04T21:26:19.156405: step 16810, loss 3.61962, acc 1\n","2019-04-04T21:26:21.563714: step 16820, loss 3.60423, acc 1\n","2019-04-04T21:26:23.816986: step 16830, loss 3.60356, acc 1\n","2019-04-04T21:26:26.251512: step 16840, loss 3.60491, acc 1\n","2019-04-04T21:26:28.518252: step 16850, loss 3.60444, acc 1\n","2019-04-04T21:26:30.838240: step 16860, loss 3.62844, acc 1\n","2019-04-04T21:26:33.159520: step 16870, loss 3.61558, acc 1\n","2019-04-04T21:26:35.411386: step 16880, loss 3.71792, acc 0.95\n","2019-04-04T21:26:37.600942: step 16890, loss 3.62059, acc 1\n","2019-04-04T21:26:39.983543: step 16900, loss 3.60993, acc 1\n","\n","Evaluation:\n","2019-04-04T21:26:49.989007: step 16900, loss 6.15197, acc 0.797167\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.49%, Best = 83.96%\n","\n","2019-04-04T21:26:52.344052: step 16910, loss 3.77953, acc 0.95\n","2019-04-04T21:26:54.709525: step 16920, loss 3.62269, acc 1\n","2019-04-04T21:26:57.171342: step 16930, loss 3.64013, acc 1\n","2019-04-04T21:26:59.448220: step 16940, loss 3.59724, acc 1\n","2019-04-04T21:27:01.663922: step 16950, loss 3.59868, acc 1\n","2019-04-04T21:27:03.851137: step 16960, loss 3.59718, acc 1\n","2019-04-04T21:27:06.293205: step 16970, loss 3.59672, acc 1\n","2019-04-04T21:27:09.077784: step 16980, loss 3.63266, acc 0.95\n","2019-04-04T21:27:11.332909: step 16990, loss 3.5963, acc 1\n","2019-04-04T21:27:13.583128: step 17000, loss 3.59544, acc 1\n","\n","Evaluation:\n","2019-04-04T21:27:23.582502: step 17000, loss 6.30492, acc 0.79349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.1%, Best = 83.96%\n","\n","2019-04-04T21:27:26.082908: step 17010, loss 3.62903, acc 0.95\n","2019-04-04T21:27:28.331462: step 17020, loss 3.61792, acc 1\n","2019-04-04T21:27:30.728903: step 17030, loss 3.59227, acc 1\n","2019-04-04T21:27:32.940790: step 17040, loss 3.59441, acc 1\n","2019-04-04T21:27:35.425592: step 17050, loss 3.60453, acc 1\n","2019-04-04T21:27:37.735942: step 17060, loss 3.59786, acc 1\n","2019-04-04T21:27:40.118745: step 17070, loss 3.59028, acc 1\n","2019-04-04T21:27:42.430260: step 17080, loss 3.58783, acc 1\n","2019-04-04T21:27:45.032304: step 17090, loss 3.58514, acc 1\n","2019-04-04T21:27:47.262939: step 17100, loss 3.58755, acc 1\n","\n","Evaluation:\n","2019-04-04T21:27:57.224067: step 17100, loss 5.85144, acc 0.793858\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.35%, Best = 83.96%\n","\n","2019-04-04T21:27:59.551906: step 17110, loss 3.59396, acc 1\n","2019-04-04T21:28:02.041264: step 17120, loss 3.59774, acc 1\n","2019-04-04T21:28:04.310211: step 17130, loss 3.60328, acc 1\n","2019-04-04T21:28:06.551360: step 17140, loss 3.61483, acc 1\n","2019-04-04T21:28:09.061522: step 17150, loss 3.62566, acc 1\n","2019-04-04T21:28:11.378691: step 17160, loss 3.5811, acc 1\n","2019-04-04T21:28:13.725892: step 17170, loss 3.58826, acc 1\n","2019-04-04T21:28:16.260953: step 17180, loss 3.58215, acc 1\n","2019-04-04T21:28:19.200224: step 17190, loss 3.65054, acc 0.95\n","2019-04-04T21:28:21.755019: step 17200, loss 3.58376, acc 1\n","\n","Evaluation:\n","2019-04-04T21:28:31.692732: step 17200, loss 6.07365, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.33%, Best = 83.96%\n","\n","2019-04-04T21:28:33.966079: step 17210, loss 3.58056, acc 1\n","2019-04-04T21:28:36.542744: step 17220, loss 3.65713, acc 0.95\n","2019-04-04T21:28:38.867044: step 17230, loss 3.58238, acc 1\n","2019-04-04T21:28:41.149397: step 17240, loss 3.62537, acc 1\n","2019-04-04T21:28:43.437398: step 17250, loss 3.6195, acc 1\n","2019-04-04T21:28:45.747016: step 17260, loss 3.58295, acc 1\n","2019-04-04T21:28:47.893207: step 17270, loss 3.58486, acc 1\n","2019-04-04T21:28:50.276830: step 17280, loss 3.57436, acc 1\n","2019-04-04T21:28:52.745967: step 17290, loss 3.57286, acc 1\n","2019-04-04T21:28:55.107748: step 17300, loss 3.57218, acc 1\n","\n","Evaluation:\n","2019-04-04T21:29:05.011192: step 17300, loss 6.10795, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.29%, Best = 83.96%\n","\n","2019-04-04T21:29:07.436855: step 17310, loss 3.57752, acc 1\n","2019-04-04T21:29:09.800989: step 17320, loss 3.57445, acc 1\n","2019-04-04T21:29:12.220823: step 17330, loss 3.59193, acc 1\n","2019-04-04T21:29:14.458514: step 17340, loss 3.60323, acc 1\n","2019-04-04T21:29:16.959026: step 17350, loss 3.57508, acc 1\n","2019-04-04T21:29:19.339883: step 17360, loss 3.58376, acc 1\n","2019-04-04T21:29:21.664473: step 17370, loss 3.56806, acc 1\n","2019-04-04T21:29:23.974199: step 17380, loss 3.61483, acc 0.95\n","2019-04-04T21:29:26.303288: step 17390, loss 3.57925, acc 1\n","2019-04-04T21:29:28.827912: step 17400, loss 3.56443, acc 1\n","\n","Evaluation:\n","2019-04-04T21:29:38.743136: step 17400, loss 6.09011, acc 0.789079\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.88%, Best = 83.96%\n","\n","2019-04-04T21:29:41.166074: step 17410, loss 3.56572, acc 1\n","2019-04-04T21:29:43.694238: step 17420, loss 3.56855, acc 1\n","2019-04-04T21:29:46.270142: step 17430, loss 3.57357, acc 1\n","2019-04-04T21:29:48.627597: step 17440, loss 3.56433, acc 1\n","2019-04-04T21:29:50.979608: step 17450, loss 3.5729, acc 1\n","2019-04-04T21:29:53.359528: step 17460, loss 3.57214, acc 1\n","2019-04-04T21:29:55.761139: step 17470, loss 3.56453, acc 1\n","2019-04-04T21:29:57.975743: step 17480, loss 3.55904, acc 1\n","2019-04-04T21:30:00.310005: step 17490, loss 3.55864, acc 1\n","2019-04-04T21:30:02.735416: step 17500, loss 3.5662, acc 1\n","\n","Evaluation:\n","2019-04-04T21:30:12.686967: step 17500, loss 6.10907, acc 0.789381\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.96%\n","\n","2019-04-04T21:30:15.088194: step 17510, loss 3.56179, acc 1\n","2019-04-04T21:30:17.449296: step 17520, loss 3.5557, acc 1\n","2019-04-04T21:30:19.819317: step 17530, loss 3.55744, acc 1\n","2019-04-04T21:30:22.051143: step 17540, loss 3.55767, acc 1\n","2019-04-04T21:30:24.564634: step 17550, loss 3.59869, acc 1\n","2019-04-04T21:30:26.901498: step 17560, loss 3.55394, acc 1\n","2019-04-04T21:30:29.132723: step 17570, loss 3.55462, acc 1\n","2019-04-04T21:30:31.469275: step 17580, loss 3.77024, acc 0.95\n","2019-04-04T21:30:33.913899: step 17590, loss 3.6027, acc 0.95\n","2019-04-04T21:30:36.270511: step 17600, loss 3.60021, acc 1\n","\n","Evaluation:\n","2019-04-04T21:30:46.272278: step 17600, loss 6.27443, acc 0.798638\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.63%, Best = 83.96%\n","\n","2019-04-04T21:30:48.707057: step 17610, loss 4.06075, acc 0.9\n","2019-04-04T21:30:51.313222: step 17620, loss 3.58184, acc 1\n","2019-04-04T21:30:53.689473: step 17630, loss 3.56302, acc 1\n","2019-04-04T21:30:55.824045: step 17640, loss 3.56458, acc 1\n","2019-04-04T21:30:58.077752: step 17650, loss 3.55235, acc 1\n","2019-04-04T21:31:00.263733: step 17660, loss 3.54602, acc 1\n","2019-04-04T21:31:02.825967: step 17670, loss 3.64257, acc 0.95\n","2019-04-04T21:31:05.057014: step 17680, loss 3.57091, acc 1\n","2019-04-04T21:31:07.360487: step 17690, loss 3.5511, acc 1\n","2019-04-04T21:31:09.692545: step 17700, loss 3.6619, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:31:19.666708: step 17700, loss 6.22986, acc 0.797902\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.58%, Best = 83.96%\n","\n","2019-04-04T21:31:21.974352: step 17710, loss 3.54526, acc 1\n","2019-04-04T21:31:24.598510: step 17720, loss 3.70823, acc 0.95\n","2019-04-04T21:31:26.894546: step 17730, loss 3.54384, acc 1\n","2019-04-04T21:31:29.248299: step 17740, loss 3.56543, acc 1\n","2019-04-04T21:31:31.521374: step 17750, loss 3.5625, acc 1\n","2019-04-04T21:31:33.803033: step 17760, loss 3.54427, acc 1\n","2019-04-04T21:31:36.125186: step 17770, loss 3.5982, acc 0.95\n","2019-04-04T21:31:38.592758: step 17780, loss 3.55244, acc 1\n","2019-04-04T21:31:41.095173: step 17790, loss 3.55558, acc 1\n","2019-04-04T21:31:43.335884: step 17800, loss 3.54677, acc 1\n","\n","Evaluation:\n","2019-04-04T21:31:53.285510: step 17800, loss 6.32687, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.8%, Best = 83.96%\n","\n","2019-04-04T21:31:55.747530: step 17810, loss 3.55008, acc 1\n","2019-04-04T21:31:58.252297: step 17820, loss 3.5596, acc 1\n","2019-04-04T21:32:00.553220: step 17830, loss 3.79337, acc 0.9\n","2019-04-04T21:32:02.968093: step 17840, loss 3.55192, acc 1\n","2019-04-04T21:32:05.281540: step 17850, loss 3.62831, acc 0.95\n","2019-04-04T21:32:07.631239: step 17860, loss 3.53265, acc 1\n","2019-04-04T21:32:09.871934: step 17870, loss 3.58236, acc 1\n","2019-04-04T21:32:12.128856: step 17880, loss 3.55544, acc 1\n","2019-04-04T21:32:14.418743: step 17890, loss 3.53232, acc 1\n","2019-04-04T21:32:16.785416: step 17900, loss 3.62657, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:32:26.658285: step 17900, loss 6.3627, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.89%, Best = 83.96%\n","\n","2019-04-04T21:32:29.087677: step 17910, loss 3.61712, acc 0.95\n","2019-04-04T21:32:31.491250: step 17920, loss 3.53027, acc 1\n","2019-04-04T21:32:33.697405: step 17930, loss 3.7575, acc 0.9\n","2019-04-04T21:32:36.128416: step 17940, loss 3.52941, acc 1\n","2019-04-04T21:32:38.582911: step 17950, loss 3.53127, acc 1\n","2019-04-04T21:32:40.931398: step 17960, loss 3.62647, acc 0.95\n","2019-04-04T21:32:43.320934: step 17970, loss 3.53293, acc 1\n","2019-04-04T21:32:45.476929: step 17980, loss 3.64743, acc 0.95\n","2019-04-04T21:32:47.979859: step 17990, loss 3.62982, acc 0.95\n","2019-04-04T21:32:50.396232: step 18000, loss 3.60164, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:33:00.379474: step 18000, loss 6.0718, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.04%, Best = 83.96%\n","\n","2019-04-04T21:33:02.937735: step 18010, loss 3.52754, acc 1\n","2019-04-04T21:33:05.193856: step 18020, loss 3.56363, acc 0.95\n","2019-04-04T21:33:07.530577: step 18030, loss 3.52182, acc 1\n","2019-04-04T21:33:09.750707: step 18040, loss 3.61285, acc 0.95\n","2019-04-04T21:33:12.506329: step 18050, loss 3.53563, acc 1\n","2019-04-04T21:33:14.955394: step 18060, loss 3.51899, acc 1\n","2019-04-04T21:33:17.342010: step 18070, loss 3.52863, acc 1\n","2019-04-04T21:33:19.614585: step 18080, loss 3.51782, acc 1\n","2019-04-04T21:33:21.946620: step 18090, loss 3.53395, acc 1\n","2019-04-04T21:33:24.374929: step 18100, loss 3.55114, acc 1\n","\n","Evaluation:\n","2019-04-04T21:33:34.318424: step 18100, loss 6.39315, acc 0.796497\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.44%, Best = 83.96%\n","\n","2019-04-04T21:33:36.810102: step 18110, loss 3.52046, acc 1\n","2019-04-04T21:33:39.061392: step 18120, loss 3.54724, acc 1\n","2019-04-04T21:33:41.358820: step 18130, loss 3.52284, acc 1\n","2019-04-04T21:33:43.697025: step 18140, loss 3.57997, acc 0.95\n","2019-04-04T21:33:45.909198: step 18150, loss 3.53525, acc 1\n","2019-04-04T21:33:48.155395: step 18160, loss 3.52018, acc 1\n","2019-04-04T21:33:50.774475: step 18170, loss 3.53464, acc 1\n","2019-04-04T21:33:53.391308: step 18180, loss 3.51862, acc 1\n","2019-04-04T21:33:55.494356: step 18190, loss 3.51168, acc 1\n","2019-04-04T21:33:57.930407: step 18200, loss 3.51153, acc 1\n","\n","Evaluation:\n","2019-04-04T21:34:07.943813: step 18200, loss 6.18771, acc 0.796064\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.27%, Best = 83.96%\n","\n","2019-04-04T21:34:10.423140: step 18210, loss 3.54127, acc 1\n","2019-04-04T21:34:12.817795: step 18220, loss 3.50912, acc 1\n","2019-04-04T21:34:15.184212: step 18230, loss 3.75668, acc 0.9\n","2019-04-04T21:34:17.552928: step 18240, loss 3.51322, acc 1\n","2019-04-04T21:34:20.001619: step 18250, loss 3.52164, acc 1\n","2019-04-04T21:34:22.309028: step 18260, loss 3.51457, acc 1\n","2019-04-04T21:34:24.674657: step 18270, loss 3.50489, acc 1\n","2019-04-04T21:34:26.956471: step 18280, loss 3.55146, acc 0.95\n","2019-04-04T21:34:29.233703: step 18290, loss 3.51175, acc 1\n","2019-04-04T21:34:31.548937: step 18300, loss 3.50493, acc 1\n","\n","Evaluation:\n","2019-04-04T21:34:41.528550: step 18300, loss 6.14003, acc 0.793555\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.25%, Best = 83.96%\n","\n","2019-04-04T21:34:43.957020: step 18310, loss 3.5029, acc 1\n","2019-04-04T21:34:46.519372: step 18320, loss 3.51208, acc 1\n","2019-04-04T21:34:48.912353: step 18330, loss 3.50841, acc 1\n","2019-04-04T21:34:51.467487: step 18340, loss 3.5005, acc 1\n","2019-04-04T21:34:53.646679: step 18350, loss 3.50248, acc 1\n","2019-04-04T21:34:55.906383: step 18360, loss 3.50693, acc 1\n","2019-04-04T21:34:58.256993: step 18370, loss 3.7089, acc 0.95\n","2019-04-04T21:35:00.674388: step 18380, loss 3.50181, acc 1\n","2019-04-04T21:35:02.949842: step 18390, loss 3.5032, acc 1\n","2019-04-04T21:35:05.353785: step 18400, loss 3.50688, acc 1\n","\n","Evaluation:\n","2019-04-04T21:35:15.316958: step 18400, loss 6.0933, acc 0.795026\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.26%, Best = 83.96%\n","\n","2019-04-04T21:35:17.760910: step 18410, loss 3.49701, acc 1\n","2019-04-04T21:35:19.968256: step 18420, loss 3.50387, acc 1\n","2019-04-04T21:35:22.405612: step 18430, loss 3.49794, acc 1\n","2019-04-04T21:35:25.018517: step 18440, loss 3.514, acc 1\n","2019-04-04T21:35:27.362279: step 18450, loss 3.5504, acc 0.95\n","2019-04-04T21:35:30.152114: step 18460, loss 3.49346, acc 1\n","2019-04-04T21:35:32.400760: step 18470, loss 3.52784, acc 1\n","2019-04-04T21:35:34.618236: step 18480, loss 3.49989, acc 1\n","2019-04-04T21:35:37.131208: step 18490, loss 3.49507, acc 1\n","2019-04-04T21:35:39.356013: step 18500, loss 3.55975, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:35:49.343477: step 18500, loss 5.95809, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.46%, Best = 83.96%\n","\n","2019-04-04T21:35:51.634665: step 18510, loss 3.5619, acc 0.95\n","2019-04-04T21:35:54.053934: step 18520, loss 3.49083, acc 1\n","2019-04-04T21:35:56.505002: step 18530, loss 3.70883, acc 0.9\n","2019-04-04T21:35:58.916070: step 18540, loss 3.48745, acc 1\n","2019-04-04T21:36:01.309135: step 18550, loss 3.65453, acc 0.9\n","2019-04-04T21:36:03.550030: step 18560, loss 3.50311, acc 1\n","2019-04-04T21:36:06.014809: step 18570, loss 3.49326, acc 1\n","2019-04-04T21:36:08.257619: step 18580, loss 3.65353, acc 0.95\n","2019-04-04T21:36:10.766506: step 18590, loss 3.49862, acc 1\n","2019-04-04T21:36:13.061059: step 18600, loss 3.48253, acc 1\n","\n","Evaluation:\n","2019-04-04T21:36:23.086781: step 18600, loss 6.07546, acc 0.797599\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.37%, Best = 83.96%\n","\n","2019-04-04T21:36:25.500560: step 18610, loss 3.48421, acc 1\n","2019-04-04T21:36:27.782273: step 18620, loss 3.48134, acc 1\n","2019-04-04T21:36:30.309224: step 18630, loss 3.5007, acc 1\n","2019-04-04T21:36:32.632573: step 18640, loss 3.48035, acc 1\n","2019-04-04T21:36:34.875060: step 18650, loss 3.4788, acc 1\n","2019-04-04T21:36:37.253952: step 18660, loss 3.54751, acc 1\n","2019-04-04T21:36:39.639452: step 18670, loss 3.47842, acc 1\n","2019-04-04T21:36:41.958904: step 18680, loss 3.53588, acc 0.95\n","2019-04-04T21:36:44.279244: step 18690, loss 3.47863, acc 1\n","2019-04-04T21:36:46.712281: step 18700, loss 3.48178, acc 1\n","\n","Evaluation:\n","2019-04-04T21:36:56.712230: step 18700, loss 6.50599, acc 0.796799\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.34%, Best = 83.96%\n","\n","2019-04-04T21:36:59.186682: step 18710, loss 3.55464, acc 0.95\n","2019-04-04T21:37:01.576242: step 18720, loss 3.47724, acc 1\n","2019-04-04T21:37:04.098516: step 18730, loss 3.51713, acc 1\n","2019-04-04T21:37:06.383010: step 18740, loss 3.47297, acc 1\n","2019-04-04T21:37:08.652869: step 18750, loss 3.47788, acc 1\n","2019-04-04T21:37:10.912177: step 18760, loss 3.47121, acc 1\n","2019-04-04T21:37:13.298753: step 18770, loss 3.91282, acc 0.95\n","2019-04-04T21:37:15.874883: step 18780, loss 3.47194, acc 1\n","2019-04-04T21:37:18.234963: step 18790, loss 3.55564, acc 0.95\n","2019-04-04T21:37:20.561866: step 18800, loss 3.47234, acc 1\n","\n","Evaluation:\n","2019-04-04T21:37:30.523642: step 18800, loss 5.99412, acc 0.797599\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.58%, Best = 83.96%\n","\n","2019-04-04T21:37:32.899047: step 18810, loss 3.62007, acc 0.95\n","2019-04-04T21:37:35.250194: step 18820, loss 3.46841, acc 1\n","2019-04-04T21:37:37.650869: step 18830, loss 3.46697, acc 1\n","2019-04-04T21:37:40.239693: step 18840, loss 3.51611, acc 0.95\n","2019-04-04T21:37:42.703415: step 18850, loss 3.46715, acc 1\n","2019-04-04T21:37:45.286445: step 18860, loss 3.6048, acc 0.95\n","2019-04-04T21:37:47.525222: step 18870, loss 3.47346, acc 1\n","2019-04-04T21:37:49.739276: step 18880, loss 3.46735, acc 1\n","2019-04-04T21:37:51.975086: step 18890, loss 3.54812, acc 0.95\n","2019-04-04T21:37:54.483488: step 18900, loss 3.46892, acc 1\n","\n","Evaluation:\n","2019-04-04T21:38:04.447768: step 18900, loss 6.19882, acc 0.795761\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.3%, Best = 83.96%\n","\n","2019-04-04T21:38:06.734613: step 18910, loss 3.46657, acc 1\n","2019-04-04T21:38:09.114025: step 18920, loss 3.47386, acc 1\n","2019-04-04T21:38:11.336438: step 18930, loss 3.47347, acc 1\n","2019-04-04T21:38:13.777205: step 18940, loss 3.45916, acc 1\n","2019-04-04T21:38:16.201950: step 18950, loss 3.45892, acc 1\n","2019-04-04T21:38:18.619378: step 18960, loss 3.46226, acc 1\n","2019-04-04T21:38:20.944424: step 18970, loss 3.46332, acc 1\n","2019-04-04T21:38:23.261487: step 18980, loss 3.55522, acc 0.95\n","2019-04-04T21:38:25.590763: step 18990, loss 3.47399, acc 1\n","2019-04-04T21:38:27.886741: step 19000, loss 3.5133, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:38:37.847213: step 19000, loss 5.7861, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.95%, Best = 83.96%\n","\n","2019-04-04T21:38:40.351850: step 19010, loss 3.49209, acc 1\n","2019-04-04T21:38:42.983571: step 19020, loss 3.45633, acc 1\n","2019-04-04T21:38:45.239264: step 19030, loss 3.56121, acc 0.9\n","2019-04-04T21:38:47.478877: step 19040, loss 3.458, acc 1\n","2019-04-04T21:38:49.765697: step 19050, loss 3.47641, acc 1\n","2019-04-04T21:38:52.126576: step 19060, loss 3.49603, acc 1\n","2019-04-04T21:38:54.431835: step 19070, loss 3.45148, acc 1\n","2019-04-04T21:38:56.779072: step 19080, loss 3.46991, acc 1\n","2019-04-04T21:38:59.085948: step 19090, loss 3.53096, acc 1\n","2019-04-04T21:39:01.588064: step 19100, loss 3.44895, acc 1\n","\n","Evaluation:\n","2019-04-04T21:39:11.548625: step 19100, loss 6.12164, acc 0.796064\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.19%, Best = 83.96%\n","\n","2019-04-04T21:39:14.098614: step 19110, loss 3.6653, acc 0.95\n","2019-04-04T21:39:16.480330: step 19120, loss 3.52925, acc 0.95\n","2019-04-04T21:39:18.880061: step 19130, loss 3.45445, acc 1\n","2019-04-04T21:39:21.256425: step 19140, loss 3.44615, acc 1\n","2019-04-04T21:39:23.439213: step 19150, loss 3.45044, acc 1\n","2019-04-04T21:39:25.817221: step 19160, loss 3.45155, acc 1\n","2019-04-04T21:39:28.058607: step 19170, loss 3.4748, acc 1\n","2019-04-04T21:39:30.513281: step 19180, loss 3.45333, acc 1\n","2019-04-04T21:39:32.972515: step 19190, loss 3.65916, acc 0.95\n","2019-04-04T21:39:35.372290: step 19200, loss 3.46137, acc 1\n","\n","Evaluation:\n","2019-04-04T21:39:45.292981: step 19200, loss 6.17218, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.82%, Best = 83.96%\n","\n","2019-04-04T21:39:47.815031: step 19210, loss 3.44423, acc 1\n","2019-04-04T21:39:50.036395: step 19220, loss 3.47325, acc 1\n","2019-04-04T21:39:52.338989: step 19230, loss 3.50533, acc 0.95\n","2019-04-04T21:39:54.935580: step 19240, loss 3.4851, acc 0.95\n","2019-04-04T21:39:57.269344: step 19250, loss 3.45878, acc 1\n","2019-04-04T21:39:59.631362: step 19260, loss 3.46216, acc 1\n","2019-04-04T21:40:01.858199: step 19270, loss 3.44284, acc 1\n","2019-04-04T21:40:04.111794: step 19280, loss 3.45085, acc 1\n","2019-04-04T21:40:06.673258: step 19290, loss 3.43727, acc 1\n","2019-04-04T21:40:09.010746: step 19300, loss 3.43798, acc 1\n","\n","Evaluation:\n","2019-04-04T21:40:19.005253: step 19300, loss 5.90346, acc 0.794896\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.99%, Best = 83.96%\n","\n","2019-04-04T21:40:21.484171: step 19310, loss 3.4456, acc 1\n","2019-04-04T21:40:23.842785: step 19320, loss 3.44586, acc 1\n","2019-04-04T21:40:26.044286: step 19330, loss 3.49939, acc 0.95\n","2019-04-04T21:40:28.456262: step 19340, loss 3.4378, acc 1\n","2019-04-04T21:40:30.766849: step 19350, loss 3.46625, acc 1\n","2019-04-04T21:40:33.055186: step 19360, loss 3.43612, acc 1\n","2019-04-04T21:40:35.438359: step 19370, loss 3.43144, acc 1\n","2019-04-04T21:40:38.061858: step 19380, loss 3.43182, acc 1\n","2019-04-04T21:40:40.424323: step 19390, loss 3.46585, acc 1\n","2019-04-04T21:40:42.902846: step 19400, loss 3.4327, acc 1\n","\n","Evaluation:\n","2019-04-04T21:40:52.873015: step 19400, loss 5.86572, acc 0.788041\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.65%, Best = 83.96%\n","\n","2019-04-04T21:40:55.329605: step 19410, loss 3.46162, acc 1\n","2019-04-04T21:40:57.868966: step 19420, loss 3.43191, acc 1\n","2019-04-04T21:41:00.458188: step 19430, loss 3.48502, acc 1\n","2019-04-04T21:41:02.749538: step 19440, loss 3.44848, acc 1\n","2019-04-04T21:41:05.191575: step 19450, loss 3.43067, acc 1\n","2019-04-04T21:41:07.423728: step 19460, loss 3.42503, acc 1\n","2019-04-04T21:41:10.007601: step 19470, loss 3.49375, acc 0.95\n","2019-04-04T21:41:12.206322: step 19480, loss 3.65766, acc 0.95\n","2019-04-04T21:41:14.574709: step 19490, loss 3.4256, acc 1\n","2019-04-04T21:41:16.972861: step 19500, loss 3.42207, acc 1\n","\n","Evaluation:\n","2019-04-04T21:41:26.894301: step 19500, loss 6.28081, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.34%, Best = 83.96%\n","\n","2019-04-04T21:41:29.295882: step 19510, loss 3.71755, acc 0.95\n","2019-04-04T21:41:31.543511: step 19520, loss 3.44362, acc 1\n","2019-04-04T21:41:33.800878: step 19530, loss 3.64239, acc 0.95\n","2019-04-04T21:41:36.273714: step 19540, loss 3.43231, acc 1\n","2019-04-04T21:41:38.690789: step 19550, loss 3.4342, acc 1\n","2019-04-04T21:41:40.902024: step 19560, loss 3.48738, acc 0.95\n","2019-04-04T21:41:43.098223: step 19570, loss 3.42242, acc 1\n","2019-04-04T21:41:45.448411: step 19580, loss 3.41716, acc 1\n","2019-04-04T21:41:47.684471: step 19590, loss 3.41641, acc 1\n","2019-04-04T21:41:50.028990: step 19600, loss 3.42135, acc 1\n","\n","Evaluation:\n","2019-04-04T21:41:59.964123: step 19600, loss 6.04087, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.84%, Best = 83.96%\n","\n","2019-04-04T21:42:02.292190: step 19610, loss 3.43834, acc 1\n","2019-04-04T21:42:04.663352: step 19620, loss 3.57738, acc 0.95\n","2019-04-04T21:42:07.109434: step 19630, loss 3.53416, acc 0.95\n","2019-04-04T21:42:09.496278: step 19640, loss 3.41591, acc 1\n","2019-04-04T21:42:11.958428: step 19650, loss 3.41382, acc 1\n","2019-04-04T21:42:14.254454: step 19660, loss 3.49187, acc 0.95\n","2019-04-04T21:42:16.516239: step 19670, loss 3.41805, acc 1\n","2019-04-04T21:42:18.763730: step 19680, loss 3.44856, acc 1\n","2019-04-04T21:42:21.055557: step 19690, loss 3.47105, acc 0.95\n","2019-04-04T21:42:23.512592: step 19700, loss 3.41805, acc 1\n","\n","Evaluation:\n","2019-04-04T21:42:33.531849: step 19700, loss 6.15951, acc 0.790549\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.84%, Best = 83.96%\n","\n","2019-04-04T21:42:35.797576: step 19710, loss 3.41065, acc 1\n","2019-04-04T21:42:38.282186: step 19720, loss 3.42348, acc 1\n","2019-04-04T21:42:40.618479: step 19730, loss 3.41154, acc 1\n","2019-04-04T21:42:43.009324: step 19740, loss 3.41798, acc 1\n","2019-04-04T21:42:45.436758: step 19750, loss 3.43402, acc 1\n","2019-04-04T21:42:47.642002: step 19760, loss 3.41098, acc 1\n","2019-04-04T21:42:49.954072: step 19770, loss 3.40462, acc 1\n","2019-04-04T21:42:52.516128: step 19780, loss 3.40935, acc 1\n","2019-04-04T21:42:54.987293: step 19790, loss 3.41992, acc 1\n","2019-04-04T21:42:57.379599: step 19800, loss 3.42315, acc 1\n","\n","Evaluation:\n","2019-04-04T21:43:07.372366: step 19800, loss 6.3963, acc 0.784299\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.32%, Best = 83.96%\n","\n","2019-04-04T21:43:09.744228: step 19810, loss 3.43193, acc 1\n","2019-04-04T21:43:12.032259: step 19820, loss 3.40176, acc 1\n","2019-04-04T21:43:14.361961: step 19830, loss 3.40021, acc 1\n","2019-04-04T21:43:16.575296: step 19840, loss 3.40946, acc 1\n","2019-04-04T21:43:19.028178: step 19850, loss 3.52745, acc 0.95\n","2019-04-04T21:43:21.574040: step 19860, loss 3.39913, acc 1\n","2019-04-04T21:43:24.156967: step 19870, loss 3.47626, acc 0.95\n","2019-04-04T21:43:26.585614: step 19880, loss 3.41218, acc 1\n","2019-04-04T21:43:28.973435: step 19890, loss 3.44296, acc 0.95\n","2019-04-04T21:43:31.352685: step 19900, loss 3.40278, acc 1\n","\n","Evaluation:\n","2019-04-04T21:43:42.234870: step 19900, loss 6.03961, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.78%, Best = 83.96%\n","\n","2019-04-04T21:43:44.682087: step 19910, loss 3.42283, acc 1\n","2019-04-04T21:43:46.992870: step 19920, loss 3.41751, acc 1\n","2019-04-04T21:43:49.328252: step 19930, loss 3.41238, acc 1\n","2019-04-04T21:43:51.676851: step 19940, loss 3.40741, acc 1\n","2019-04-04T21:43:53.983446: step 19950, loss 3.41484, acc 1\n","2019-04-04T21:43:56.353600: step 19960, loss 3.40414, acc 1\n","2019-04-04T21:43:58.565203: step 19970, loss 3.40494, acc 1\n","2019-04-04T21:44:00.919662: step 19980, loss 3.39103, acc 1\n","2019-04-04T21:44:03.338548: step 19990, loss 3.43391, acc 0.95\n","2019-04-04T21:44:05.646288: step 20000, loss 3.39081, acc 1\n","\n","Evaluation:\n","2019-04-04T21:44:15.630863: step 20000, loss 6.43391, acc 0.789014\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.68%, Best = 83.96%\n","\n","2019-04-04T21:44:18.074010: step 20010, loss 3.38856, acc 1\n","2019-04-04T21:44:20.709555: step 20020, loss 3.39407, acc 1\n","2019-04-04T21:44:23.045225: step 20030, loss 3.39264, acc 1\n","2019-04-04T21:44:25.368131: step 20040, loss 3.39383, acc 1\n","2019-04-04T21:44:27.754911: step 20050, loss 3.38695, acc 1\n","2019-04-04T21:44:29.913590: step 20060, loss 3.38686, acc 1\n","2019-04-04T21:44:32.259279: step 20070, loss 3.40352, acc 1\n","2019-04-04T21:44:34.919266: step 20080, loss 3.38691, acc 1\n","2019-04-04T21:44:37.226209: step 20090, loss 3.38475, acc 1\n","2019-04-04T21:44:39.664963: step 20100, loss 3.38532, acc 1\n","\n","Evaluation:\n","2019-04-04T21:44:49.642095: step 20100, loss 6.35583, acc 0.79122\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.92%, Best = 83.96%\n","\n","2019-04-04T21:44:52.205650: step 20110, loss 3.38233, acc 1\n","2019-04-04T21:44:54.807885: step 20120, loss 3.38111, acc 1\n","2019-04-04T21:44:57.178227: step 20130, loss 3.38068, acc 1\n","2019-04-04T21:44:59.446039: step 20140, loss 3.38006, acc 1\n","2019-04-04T21:45:02.015524: step 20150, loss 3.37955, acc 1\n","2019-04-04T21:45:04.523535: step 20160, loss 3.38004, acc 1\n","2019-04-04T21:45:07.054537: step 20170, loss 3.38287, acc 1\n","2019-04-04T21:45:09.393070: step 20180, loss 3.37735, acc 1\n","2019-04-04T21:45:11.830044: step 20190, loss 3.38317, acc 1\n","2019-04-04T21:45:14.294710: step 20200, loss 3.38836, acc 1\n","\n","Evaluation:\n","2019-04-04T21:45:24.322205: step 20200, loss 6.3137, acc 0.797535\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.52%, Best = 83.96%\n","\n","2019-04-04T21:45:26.574130: step 20210, loss 3.41163, acc 0.95\n","2019-04-04T21:45:28.858201: step 20220, loss 3.38187, acc 1\n","2019-04-04T21:45:31.232428: step 20230, loss 3.41979, acc 0.95\n","2019-04-04T21:45:33.668128: step 20240, loss 3.51409, acc 0.95\n","2019-04-04T21:45:35.904830: step 20250, loss 3.38329, acc 1\n","2019-04-04T21:45:38.213205: step 20260, loss 3.41079, acc 0.95\n","2019-04-04T21:45:40.636331: step 20270, loss 3.37683, acc 1\n","2019-04-04T21:45:42.926905: step 20280, loss 3.37661, acc 1\n","2019-04-04T21:45:45.342194: step 20290, loss 3.37658, acc 1\n","2019-04-04T21:45:47.605995: step 20300, loss 3.39506, acc 1\n","\n","Evaluation:\n","2019-04-04T21:45:57.724436: step 20300, loss 6.2248, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.06%, Best = 83.96%\n","\n","2019-04-04T21:46:00.165619: step 20310, loss 3.36941, acc 1\n","2019-04-04T21:46:02.666032: step 20320, loss 3.37883, acc 1\n","2019-04-04T21:46:04.815882: step 20330, loss 3.46111, acc 0.95\n","2019-04-04T21:46:07.329695: step 20340, loss 3.39102, acc 1\n","2019-04-04T21:46:09.606613: step 20350, loss 3.46438, acc 0.95\n","2019-04-04T21:46:11.812052: step 20360, loss 3.37207, acc 1\n","2019-04-04T21:46:14.058467: step 20370, loss 3.38832, acc 1\n","2019-04-04T21:46:16.296723: step 20380, loss 3.41098, acc 1\n","2019-04-04T21:46:18.443746: step 20390, loss 3.42262, acc 1\n","2019-04-04T21:46:20.734225: step 20400, loss 3.4467, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:46:30.887202: step 20400, loss 5.89642, acc 0.782093\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.34%, Best = 83.96%\n","\n","2019-04-04T21:46:33.272288: step 20410, loss 3.37337, acc 1\n","2019-04-04T21:46:35.778533: step 20420, loss 3.37326, acc 1\n","2019-04-04T21:46:38.159876: step 20430, loss 3.40859, acc 0.95\n","2019-04-04T21:46:40.447385: step 20440, loss 3.39498, acc 1\n","2019-04-04T21:46:42.993556: step 20450, loss 3.37477, acc 1\n","2019-04-04T21:46:45.468377: step 20460, loss 3.36031, acc 1\n","2019-04-04T21:46:47.807809: step 20470, loss 3.35859, acc 1\n","2019-04-04T21:46:50.054093: step 20480, loss 3.52422, acc 0.95\n","2019-04-04T21:46:52.247225: step 20490, loss 3.35836, acc 1\n","2019-04-04T21:46:54.503777: step 20500, loss 3.37234, acc 1\n","\n","Evaluation:\n","2019-04-04T21:47:04.475428: step 20500, loss 5.95116, acc 0.79202\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.02%, Best = 83.96%\n","\n","2019-04-04T21:47:06.839703: step 20510, loss 3.36021, acc 1\n","2019-04-04T21:47:09.145487: step 20520, loss 3.39923, acc 0.95\n","2019-04-04T21:47:11.347297: step 20530, loss 3.36046, acc 1\n","2019-04-04T21:47:13.689435: step 20540, loss 3.35443, acc 1\n","2019-04-04T21:47:16.301076: step 20550, loss 3.35536, acc 1\n","2019-04-04T21:47:18.514310: step 20560, loss 3.36316, acc 1\n","2019-04-04T21:47:20.919183: step 20570, loss 3.35229, acc 1\n","2019-04-04T21:47:23.297103: step 20580, loss 3.35406, acc 1\n","2019-04-04T21:47:25.493926: step 20590, loss 3.35825, acc 1\n","2019-04-04T21:47:27.798675: step 20600, loss 3.35476, acc 1\n","\n","Evaluation:\n","2019-04-04T21:47:37.778900: step 20600, loss 5.84294, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.24%, Best = 83.96%\n","\n","2019-04-04T21:47:40.279125: step 20610, loss 3.39609, acc 1\n","2019-04-04T21:47:42.911196: step 20620, loss 3.36036, acc 1\n","2019-04-04T21:47:45.271629: step 20630, loss 3.35153, acc 1\n","2019-04-04T21:47:47.871276: step 20640, loss 3.35192, acc 1\n","2019-04-04T21:47:50.182034: step 20650, loss 3.35168, acc 1\n","2019-04-04T21:47:52.617319: step 20660, loss 3.36081, acc 1\n","2019-04-04T21:47:54.798721: step 20670, loss 3.34598, acc 1\n","2019-04-04T21:47:57.014195: step 20680, loss 3.34818, acc 1\n","2019-04-04T21:47:59.192015: step 20690, loss 3.38145, acc 1\n","2019-04-04T21:48:01.690489: step 20700, loss 3.36223, acc 1\n","\n","Evaluation:\n","2019-04-04T21:48:11.685610: step 20700, loss 5.67061, acc 0.79202\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.93%, Best = 83.96%\n","\n","2019-04-04T21:48:14.079412: step 20710, loss 3.35039, acc 1\n","2019-04-04T21:48:16.588198: step 20720, loss 3.34599, acc 1\n","2019-04-04T21:48:18.929970: step 20730, loss 3.48717, acc 0.95\n","2019-04-04T21:48:21.254884: step 20740, loss 3.34174, acc 1\n","2019-04-04T21:48:23.632228: step 20750, loss 3.34003, acc 1\n","2019-04-04T21:48:26.170821: step 20760, loss 3.33985, acc 1\n","2019-04-04T21:48:28.607242: step 20770, loss 3.34754, acc 1\n","2019-04-04T21:48:30.994608: step 20780, loss 3.36063, acc 1\n","2019-04-04T21:48:33.441571: step 20790, loss 3.33789, acc 1\n","2019-04-04T21:48:35.796899: step 20800, loss 3.3823, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:48:45.848893: step 20800, loss 5.6561, acc 0.792452\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.89%, Best = 83.96%\n","\n","2019-04-04T21:48:48.335493: step 20810, loss 3.41664, acc 0.95\n","2019-04-04T21:48:50.790920: step 20820, loss 3.58962, acc 0.9\n","2019-04-04T21:48:53.274617: step 20830, loss 3.33512, acc 1\n","2019-04-04T21:48:55.799018: step 20840, loss 3.52352, acc 0.85\n","2019-04-04T21:48:58.102815: step 20850, loss 3.33623, acc 1\n","2019-04-04T21:49:00.523036: step 20860, loss 3.76175, acc 0.9\n","2019-04-04T21:49:02.868473: step 20870, loss 3.3335, acc 1\n","2019-04-04T21:49:05.461692: step 20880, loss 3.3413, acc 1\n","2019-04-04T21:49:07.543626: step 20890, loss 3.33237, acc 1\n","2019-04-04T21:49:09.731670: step 20900, loss 3.4452, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:49:19.677337: step 20900, loss 5.82705, acc 0.788711\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.9%, Best = 83.96%\n","\n","2019-04-04T21:49:22.082545: step 20910, loss 3.57975, acc 0.95\n","2019-04-04T21:49:24.417475: step 20920, loss 3.33453, acc 1\n","2019-04-04T21:49:26.737467: step 20930, loss 3.33051, acc 1\n","2019-04-04T21:49:29.107819: step 20940, loss 3.33162, acc 1\n","2019-04-04T21:49:31.448127: step 20950, loss 3.33399, acc 1\n","2019-04-04T21:49:33.769061: step 20960, loss 3.32962, acc 1\n","2019-04-04T21:49:36.168754: step 20970, loss 3.32724, acc 1\n","2019-04-04T21:49:38.423953: step 20980, loss 3.42355, acc 0.95\n","2019-04-04T21:49:41.045046: step 20990, loss 3.32481, acc 1\n","2019-04-04T21:49:43.623601: step 21000, loss 3.33134, acc 1\n","\n","Evaluation:\n","2019-04-04T21:49:53.627357: step 21000, loss 5.9863, acc 0.788776\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.77%, Best = 83.96%\n","\n","2019-04-04T21:49:56.166284: step 21010, loss 3.37503, acc 1\n","2019-04-04T21:49:58.391539: step 21020, loss 3.32743, acc 1\n","2019-04-04T21:50:00.831772: step 21030, loss 3.32265, acc 1\n","2019-04-04T21:50:03.078324: step 21040, loss 3.33746, acc 1\n","2019-04-04T21:50:05.438426: step 21050, loss 3.37382, acc 1\n","2019-04-04T21:50:07.900729: step 21060, loss 3.32819, acc 1\n","2019-04-04T21:50:10.246781: step 21070, loss 3.45219, acc 0.9\n","2019-04-04T21:50:12.521489: step 21080, loss 3.34084, acc 1\n","2019-04-04T21:50:14.819240: step 21090, loss 3.32062, acc 1\n","2019-04-04T21:50:17.141443: step 21100, loss 3.33464, acc 1\n","\n","Evaluation:\n","2019-04-04T21:50:27.138238: step 21100, loss 5.93, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.94%, Best = 83.96%\n","\n","2019-04-04T21:50:29.530673: step 21110, loss 3.32063, acc 1\n","2019-04-04T21:50:31.834185: step 21120, loss 3.32061, acc 1\n","2019-04-04T21:50:34.148042: step 21130, loss 3.34581, acc 1\n","2019-04-04T21:50:36.563931: step 21140, loss 3.31736, acc 1\n","2019-04-04T21:50:38.961029: step 21150, loss 3.31467, acc 1\n","2019-04-04T21:50:41.274586: step 21160, loss 3.31368, acc 1\n","2019-04-04T21:50:43.639734: step 21170, loss 3.33452, acc 1\n","2019-04-04T21:50:45.848125: step 21180, loss 3.31477, acc 1\n","2019-04-04T21:50:48.178048: step 21190, loss 3.32477, acc 1\n","2019-04-04T21:50:50.653797: step 21200, loss 3.41534, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:51:00.618990: step 21200, loss 6.03433, acc 0.790614\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T21:51:03.277697: step 21210, loss 3.31126, acc 1\n","2019-04-04T21:51:05.559229: step 21220, loss 3.31229, acc 1\n","2019-04-04T21:51:07.958842: step 21230, loss 3.31244, acc 1\n","2019-04-04T21:51:10.315754: step 21240, loss 3.32181, acc 1\n","2019-04-04T21:51:12.855086: step 21250, loss 3.32172, acc 1\n","2019-04-04T21:51:15.184351: step 21260, loss 3.51783, acc 0.95\n","2019-04-04T21:51:17.517907: step 21270, loss 3.30661, acc 1\n","2019-04-04T21:51:19.968657: step 21280, loss 3.30677, acc 1\n","2019-04-04T21:51:22.156555: step 21290, loss 3.30592, acc 1\n","2019-04-04T21:51:24.406861: step 21300, loss 3.30825, acc 1\n","\n","Evaluation:\n","2019-04-04T21:51:34.423901: step 21300, loss 6.29817, acc 0.793188\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.96%\n","\n","2019-04-04T21:51:36.829036: step 21310, loss 3.34197, acc 1\n","2019-04-04T21:51:39.302471: step 21320, loss 3.3232, acc 1\n","2019-04-04T21:51:41.907115: step 21330, loss 3.30293, acc 1\n","2019-04-04T21:51:44.192161: step 21340, loss 3.30198, acc 1\n","2019-04-04T21:51:46.540877: step 21350, loss 3.30677, acc 1\n","2019-04-04T21:51:48.850805: step 21360, loss 3.30799, acc 1\n","2019-04-04T21:51:51.229654: step 21370, loss 3.30417, acc 1\n","2019-04-04T21:51:53.551661: step 21380, loss 3.32992, acc 1\n","2019-04-04T21:51:55.811057: step 21390, loss 3.29898, acc 1\n","2019-04-04T21:51:58.151335: step 21400, loss 3.32017, acc 1\n","\n","Evaluation:\n","2019-04-04T21:52:08.130456: step 21400, loss 6.27163, acc 0.789879\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83%, Best = 83.96%\n","\n","2019-04-04T21:52:10.564719: step 21410, loss 3.32073, acc 1\n","2019-04-04T21:52:12.976129: step 21420, loss 3.30041, acc 1\n","2019-04-04T21:52:15.394461: step 21430, loss 3.29906, acc 1\n","2019-04-04T21:52:17.653389: step 21440, loss 3.30888, acc 1\n","2019-04-04T21:52:20.167419: step 21450, loss 3.29866, acc 1\n","2019-04-04T21:52:22.713607: step 21460, loss 3.47012, acc 0.95\n","2019-04-04T21:52:24.937805: step 21470, loss 3.30779, acc 1\n","2019-04-04T21:52:27.502347: step 21480, loss 3.46514, acc 0.9\n","2019-04-04T21:52:29.988784: step 21490, loss 3.2929, acc 1\n","2019-04-04T21:52:32.228762: step 21500, loss 3.29938, acc 1\n","\n","Evaluation:\n","2019-04-04T21:52:42.269167: step 21500, loss 6.08506, acc 0.791717\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.96%\n","\n","2019-04-04T21:52:44.511736: step 21510, loss 3.30595, acc 1\n","2019-04-04T21:52:46.856572: step 21520, loss 3.3765, acc 0.95\n","2019-04-04T21:52:49.336389: step 21530, loss 3.36999, acc 0.95\n","2019-04-04T21:52:51.778824: step 21540, loss 3.29491, acc 1\n","2019-04-04T21:52:54.186597: step 21550, loss 3.28931, acc 1\n","2019-04-04T21:52:56.589805: step 21560, loss 3.29373, acc 1\n","2019-04-04T21:52:58.761109: step 21570, loss 3.29862, acc 1\n","2019-04-04T21:53:01.009259: step 21580, loss 3.2976, acc 1\n","2019-04-04T21:53:03.478067: step 21590, loss 3.35259, acc 0.95\n","2019-04-04T21:53:05.780959: step 21600, loss 3.28986, acc 1\n","\n","Evaluation:\n","2019-04-04T21:53:15.745472: step 21600, loss 5.99791, acc 0.794593\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T21:53:18.040205: step 21610, loss 3.28479, acc 1\n","2019-04-04T21:53:20.358286: step 21620, loss 3.44024, acc 0.95\n","2019-04-04T21:53:22.652896: step 21630, loss 3.28441, acc 1\n","2019-04-04T21:53:25.133415: step 21640, loss 3.35364, acc 0.95\n","2019-04-04T21:53:27.430605: step 21650, loss 3.35926, acc 0.95\n","2019-04-04T21:53:29.719540: step 21660, loss 3.28317, acc 1\n","2019-04-04T21:53:31.940416: step 21670, loss 3.28604, acc 1\n","2019-04-04T21:53:34.298883: step 21680, loss 3.28219, acc 1\n","2019-04-04T21:53:36.744131: step 21690, loss 3.37692, acc 0.95\n","2019-04-04T21:53:39.076499: step 21700, loss 3.28002, acc 1\n","\n","Evaluation:\n","2019-04-04T21:53:49.092380: step 21700, loss 6.3498, acc 0.794161\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.2%, Best = 83.96%\n","\n","2019-04-04T21:53:51.417644: step 21710, loss 3.30433, acc 1\n","2019-04-04T21:53:53.906243: step 21720, loss 3.453, acc 0.95\n","2019-04-04T21:53:56.574212: step 21730, loss 3.39585, acc 0.95\n","2019-04-04T21:53:58.908291: step 21740, loss 3.27926, acc 1\n","2019-04-04T21:54:01.420457: step 21750, loss 3.29434, acc 1\n","2019-04-04T21:54:03.789728: step 21760, loss 3.27722, acc 1\n","2019-04-04T21:54:06.090333: step 21770, loss 3.28253, acc 1\n","2019-04-04T21:54:08.479926: step 21780, loss 3.27432, acc 1\n","2019-04-04T21:54:10.762587: step 21790, loss 3.28507, acc 1\n","2019-04-04T21:54:13.227713: step 21800, loss 3.34211, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:54:23.226253: step 21800, loss 5.99853, acc 0.790247\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.94%, Best = 83.96%\n","\n","2019-04-04T21:54:25.649191: step 21810, loss 3.27347, acc 1\n","2019-04-04T21:54:28.030769: step 21820, loss 3.27176, acc 1\n","2019-04-04T21:54:30.419663: step 21830, loss 3.30466, acc 1\n","2019-04-04T21:54:32.873183: step 21840, loss 3.29173, acc 1\n","2019-04-04T21:54:35.242416: step 21850, loss 3.2697, acc 1\n","2019-04-04T21:54:37.601226: step 21860, loss 3.31152, acc 1\n","2019-04-04T21:54:39.890721: step 21870, loss 3.26896, acc 1\n","2019-04-04T21:54:42.292670: step 21880, loss 3.40455, acc 0.95\n","2019-04-04T21:54:44.530682: step 21890, loss 3.27676, acc 1\n","2019-04-04T21:54:47.026327: step 21900, loss 3.30134, acc 1\n","\n","Evaluation:\n","2019-04-04T21:54:57.076685: step 21900, loss 6.0599, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.95%, Best = 83.96%\n","\n","2019-04-04T21:54:59.421840: step 21910, loss 3.26766, acc 1\n","2019-04-04T21:55:01.695289: step 21920, loss 3.29274, acc 1\n","2019-04-04T21:55:04.037641: step 21930, loss 3.26623, acc 1\n","2019-04-04T21:55:06.368339: step 21940, loss 3.44399, acc 0.95\n","2019-04-04T21:55:08.735539: step 21950, loss 3.26361, acc 1\n","2019-04-04T21:55:11.030374: step 21960, loss 3.30548, acc 1\n","2019-04-04T21:55:13.648296: step 21970, loss 3.2688, acc 1\n","2019-04-04T21:55:16.196564: step 21980, loss 3.26867, acc 1\n","2019-04-04T21:55:18.539273: step 21990, loss 3.43282, acc 0.95\n","2019-04-04T21:55:20.645955: step 22000, loss 3.26129, acc 1\n","\n","Evaluation:\n","2019-04-04T21:55:30.660373: step 22000, loss 6.62721, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T21:55:32.991164: step 22010, loss 3.25966, acc 1\n","2019-04-04T21:55:35.220921: step 22020, loss 3.26886, acc 1\n","2019-04-04T21:55:37.716989: step 22030, loss 3.26083, acc 1\n","2019-04-04T21:55:40.001732: step 22040, loss 3.28284, acc 1\n","2019-04-04T21:55:42.272383: step 22050, loss 3.2573, acc 1\n","2019-04-04T21:55:44.605967: step 22060, loss 3.25715, acc 1\n","2019-04-04T21:55:46.949377: step 22070, loss 3.25996, acc 1\n","2019-04-04T21:55:49.175463: step 22080, loss 3.2809, acc 1\n","2019-04-04T21:55:51.351381: step 22090, loss 3.25491, acc 1\n","2019-04-04T21:55:53.795459: step 22100, loss 3.27901, acc 1\n","\n","Evaluation:\n","2019-04-04T21:56:03.856060: step 22100, loss 6.13161, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.56%, Best = 83.96%\n","\n","2019-04-04T21:56:06.363871: step 22110, loss 3.31763, acc 0.95\n","2019-04-04T21:56:08.803685: step 22120, loss 3.30594, acc 0.95\n","2019-04-04T21:56:11.070287: step 22130, loss 3.25284, acc 1\n","2019-04-04T21:56:13.490268: step 22140, loss 3.29906, acc 0.95\n","2019-04-04T21:56:15.610066: step 22150, loss 3.35352, acc 0.95\n","2019-04-04T21:56:18.020713: step 22160, loss 3.2514, acc 1\n","2019-04-04T21:56:20.417816: step 22170, loss 3.26759, acc 1\n","2019-04-04T21:56:22.832852: step 22180, loss 3.26472, acc 1\n","2019-04-04T21:56:25.056141: step 22190, loss 3.24943, acc 1\n","2019-04-04T21:56:27.414679: step 22200, loss 3.28939, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:56:37.429056: step 22200, loss 6.23233, acc 0.793188\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.1%, Best = 83.96%\n","\n","2019-04-04T21:56:39.895316: step 22210, loss 3.2557, acc 1\n","2019-04-04T21:56:42.171591: step 22220, loss 3.24698, acc 1\n","2019-04-04T21:56:44.513087: step 22230, loss 3.25559, acc 1\n","2019-04-04T21:56:46.850993: step 22240, loss 3.29731, acc 0.95\n","2019-04-04T21:56:49.199884: step 22250, loss 3.24438, acc 1\n","2019-04-04T21:56:51.726015: step 22260, loss 3.24874, acc 1\n","2019-04-04T21:56:54.152000: step 22270, loss 3.34856, acc 0.95\n","2019-04-04T21:56:56.479021: step 22280, loss 3.24411, acc 1\n","2019-04-04T21:56:58.668544: step 22290, loss 3.32058, acc 1\n","2019-04-04T21:57:01.216334: step 22300, loss 3.24231, acc 1\n","\n","Evaluation:\n","2019-04-04T21:57:11.208874: step 22300, loss 6.02698, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.84%, Best = 83.96%\n","\n","2019-04-04T21:57:13.665548: step 22310, loss 3.24114, acc 1\n","2019-04-04T21:57:15.961725: step 22320, loss 3.24959, acc 1\n","2019-04-04T21:57:18.521981: step 22330, loss 3.25206, acc 1\n","2019-04-04T21:57:21.102953: step 22340, loss 3.23922, acc 1\n","2019-04-04T21:57:23.296469: step 22350, loss 3.24272, acc 1\n","2019-04-04T21:57:25.664504: step 22360, loss 3.24003, acc 1\n","2019-04-04T21:57:28.160660: step 22370, loss 3.23723, acc 1\n","2019-04-04T21:57:30.672866: step 22380, loss 3.23826, acc 1\n","2019-04-04T21:57:32.947628: step 22390, loss 3.25611, acc 1\n","2019-04-04T21:57:35.278523: step 22400, loss 3.42237, acc 0.95\n","\n","Evaluation:\n","2019-04-04T21:57:45.262949: step 22400, loss 6.06528, acc 0.789879\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.86%, Best = 83.96%\n","\n","2019-04-04T21:57:47.568388: step 22410, loss 3.23909, acc 1\n","2019-04-04T21:57:49.921844: step 22420, loss 3.33086, acc 0.95\n","2019-04-04T21:57:52.266443: step 22430, loss 3.23613, acc 1\n","2019-04-04T21:57:54.460999: step 22440, loss 3.2375, acc 1\n","2019-04-04T21:57:56.928434: step 22450, loss 3.23253, acc 1\n","2019-04-04T21:57:59.350051: step 22460, loss 3.23183, acc 1\n","2019-04-04T21:58:01.653732: step 22470, loss 3.25461, acc 1\n","2019-04-04T21:58:04.066077: step 22480, loss 3.23098, acc 1\n","2019-04-04T21:58:06.483301: step 22490, loss 3.23281, acc 1\n","2019-04-04T21:58:08.752065: step 22500, loss 3.22859, acc 1\n","\n","Evaluation:\n","2019-04-04T21:58:18.761549: step 22500, loss 6.21931, acc 0.791587\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.78%, Best = 83.96%\n","\n","2019-04-04T21:58:21.200580: step 22510, loss 3.22989, acc 1\n","2019-04-04T21:58:23.502283: step 22520, loss 3.22929, acc 1\n","2019-04-04T21:58:25.801214: step 22530, loss 3.23169, acc 1\n","2019-04-04T21:58:28.235539: step 22540, loss 3.23329, acc 1\n","2019-04-04T21:58:30.653337: step 22550, loss 3.31872, acc 0.95\n","2019-04-04T21:58:33.083076: step 22560, loss 3.22719, acc 1\n","2019-04-04T21:58:35.329552: step 22570, loss 3.22965, acc 1\n","2019-04-04T21:58:37.584461: step 22580, loss 3.22368, acc 1\n","2019-04-04T21:58:40.239185: step 22590, loss 3.22277, acc 1\n","2019-04-04T21:58:42.484909: step 22600, loss 3.2253, acc 1\n","\n","Evaluation:\n","2019-04-04T21:58:52.426966: step 22600, loss 5.98881, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.59%, Best = 83.96%\n","\n","2019-04-04T21:58:54.905246: step 22610, loss 3.22411, acc 1\n","2019-04-04T21:58:57.296683: step 22620, loss 3.25534, acc 1\n","2019-04-04T21:58:59.480798: step 22630, loss 3.22199, acc 1\n","2019-04-04T21:59:01.946507: step 22640, loss 3.23051, acc 1\n","2019-04-04T21:59:04.145270: step 22650, loss 3.42086, acc 0.95\n","2019-04-04T21:59:06.679923: step 22660, loss 3.33201, acc 0.95\n","2019-04-04T21:59:09.370747: step 22670, loss 3.22128, acc 1\n","2019-04-04T21:59:12.012172: step 22680, loss 3.23649, acc 1\n","2019-04-04T21:59:14.468406: step 22690, loss 3.39874, acc 0.95\n","2019-04-04T21:59:16.850216: step 22700, loss 3.21634, acc 1\n","\n","Evaluation:\n","2019-04-04T21:59:26.799665: step 22700, loss 6.20259, acc 0.789079\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.62%, Best = 83.96%\n","\n","2019-04-04T21:59:29.343839: step 22710, loss 3.21743, acc 1\n","2019-04-04T21:59:31.612179: step 22720, loss 3.26046, acc 0.95\n","2019-04-04T21:59:33.802015: step 22730, loss 3.21474, acc 1\n","2019-04-04T21:59:36.037822: step 22740, loss 3.23849, acc 1\n","2019-04-04T21:59:38.464825: step 22750, loss 3.21555, acc 1\n","2019-04-04T21:59:40.914619: step 22760, loss 3.24541, acc 1\n","2019-04-04T21:59:43.262885: step 22770, loss 3.22391, acc 1\n","2019-04-04T21:59:45.540768: step 22780, loss 3.23109, acc 1\n","2019-04-04T21:59:47.935630: step 22790, loss 3.21745, acc 1\n","2019-04-04T21:59:50.473294: step 22800, loss 3.21264, acc 1\n","\n","Evaluation:\n","2019-04-04T22:00:00.405360: step 22800, loss 5.89892, acc 0.787305\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.48%, Best = 83.96%\n","\n","2019-04-04T22:00:02.810747: step 22810, loss 3.3433, acc 0.95\n","2019-04-04T22:00:05.027647: step 22820, loss 3.20869, acc 1\n","2019-04-04T22:00:07.837041: step 22830, loss 3.20906, acc 1\n","2019-04-04T22:00:10.168623: step 22840, loss 3.2224, acc 1\n","2019-04-04T22:00:12.608080: step 22850, loss 3.20696, acc 1\n","2019-04-04T22:00:15.072533: step 22860, loss 3.20704, acc 1\n","2019-04-04T22:00:17.414451: step 22870, loss 3.22573, acc 1\n","2019-04-04T22:00:19.686339: step 22880, loss 3.42955, acc 0.95\n","2019-04-04T22:00:21.908508: step 22890, loss 3.20644, acc 1\n","2019-04-04T22:00:24.123642: step 22900, loss 3.20358, acc 1\n","\n","Evaluation:\n","2019-04-04T22:00:34.136027: step 22900, loss 5.86104, acc 0.787673\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.48%, Best = 83.96%\n","\n","2019-04-04T22:00:36.681741: step 22910, loss 3.2053, acc 1\n","2019-04-04T22:00:39.219401: step 22920, loss 3.20323, acc 1\n","2019-04-04T22:00:41.569539: step 22930, loss 3.20159, acc 1\n","2019-04-04T22:00:43.996417: step 22940, loss 3.29978, acc 0.95\n","2019-04-04T22:00:46.471706: step 22950, loss 3.20476, acc 1\n","2019-04-04T22:00:48.826278: step 22960, loss 3.19966, acc 1\n","2019-04-04T22:00:51.083436: step 22970, loss 3.30039, acc 0.95\n","2019-04-04T22:00:53.372960: step 22980, loss 3.19871, acc 1\n","2019-04-04T22:00:55.742590: step 22990, loss 3.22173, acc 1\n","2019-04-04T22:00:58.096940: step 23000, loss 3.33955, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:01:08.077105: step 23000, loss 6.47572, acc 0.788343\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.54%, Best = 83.96%\n","\n","2019-04-04T22:01:10.466007: step 23010, loss 3.1985, acc 1\n","2019-04-04T22:01:12.732393: step 23020, loss 3.19675, acc 1\n","2019-04-04T22:01:15.108007: step 23030, loss 3.203, acc 1\n","2019-04-04T22:01:17.682521: step 23040, loss 3.20835, acc 1\n","2019-04-04T22:01:19.912530: step 23050, loss 3.27198, acc 0.95\n","2019-04-04T22:01:22.413502: step 23060, loss 3.21276, acc 1\n","2019-04-04T22:01:24.801087: step 23070, loss 3.47441, acc 0.95\n","2019-04-04T22:01:27.380575: step 23080, loss 3.21918, acc 1\n","2019-04-04T22:01:29.965849: step 23090, loss 3.19988, acc 1\n","2019-04-04T22:01:32.395185: step 23100, loss 3.19617, acc 1\n","\n","Evaluation:\n","2019-04-04T22:01:42.453786: step 23100, loss 6.23669, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.7%, Best = 83.96%\n","\n","2019-04-04T22:01:44.786364: step 23110, loss 3.23161, acc 1\n","2019-04-04T22:01:47.191200: step 23120, loss 3.1903, acc 1\n","2019-04-04T22:01:49.567228: step 23130, loss 3.19496, acc 1\n","2019-04-04T22:01:51.889576: step 23140, loss 3.18945, acc 1\n","2019-04-04T22:01:54.182041: step 23150, loss 3.18846, acc 1\n","2019-04-04T22:01:56.413637: step 23160, loss 3.19779, acc 1\n","2019-04-04T22:01:58.763868: step 23170, loss 3.19234, acc 1\n","2019-04-04T22:02:01.109178: step 23180, loss 3.21041, acc 1\n","2019-04-04T22:02:03.402957: step 23190, loss 3.23285, acc 1\n","2019-04-04T22:02:05.588165: step 23200, loss 3.2964, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:02:15.595320: step 23200, loss 6.13294, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.76%, Best = 83.96%\n","\n","2019-04-04T22:02:17.952848: step 23210, loss 3.32404, acc 0.95\n","2019-04-04T22:02:20.295741: step 23220, loss 3.18832, acc 1\n","2019-04-04T22:02:22.649538: step 23230, loss 3.19059, acc 1\n","2019-04-04T22:02:24.950406: step 23240, loss 3.18442, acc 1\n","2019-04-04T22:02:27.251068: step 23250, loss 3.18875, acc 1\n","2019-04-04T22:02:29.514975: step 23260, loss 3.18152, acc 1\n","2019-04-04T22:02:31.751741: step 23270, loss 3.1897, acc 1\n","2019-04-04T22:02:33.986280: step 23280, loss 3.18627, acc 1\n","2019-04-04T22:02:36.237998: step 23290, loss 3.24975, acc 0.95\n","2019-04-04T22:02:38.577595: step 23300, loss 3.18168, acc 1\n","\n","Evaluation:\n","2019-04-04T22:02:48.527796: step 23300, loss 6.03849, acc 0.788711\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.72%, Best = 83.96%\n","\n","2019-04-04T22:02:50.963683: step 23310, loss 3.18639, acc 1\n","2019-04-04T22:02:53.310484: step 23320, loss 3.17797, acc 1\n","2019-04-04T22:02:55.833021: step 23330, loss 3.1913, acc 1\n","2019-04-04T22:02:57.984759: step 23340, loss 3.17719, acc 1\n","2019-04-04T22:03:00.221525: step 23350, loss 3.17925, acc 1\n","2019-04-04T22:03:02.525649: step 23360, loss 3.20695, acc 1\n","2019-04-04T22:03:04.913257: step 23370, loss 3.17833, acc 1\n","2019-04-04T22:03:07.569256: step 23380, loss 3.17434, acc 1\n","2019-04-04T22:03:09.897806: step 23390, loss 3.20668, acc 1\n","2019-04-04T22:03:12.546477: step 23400, loss 3.17248, acc 1\n","\n","Evaluation:\n","2019-04-04T22:03:22.562431: step 23400, loss 6.2217, acc 0.790549\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.85%, Best = 83.96%\n","\n","2019-04-04T22:03:24.882956: step 23410, loss 3.22039, acc 0.95\n","2019-04-04T22:03:27.160640: step 23420, loss 3.17142, acc 1\n","2019-04-04T22:03:29.415624: step 23430, loss 3.19099, acc 1\n","2019-04-04T22:03:31.696667: step 23440, loss 3.1759, acc 1\n","2019-04-04T22:03:34.003288: step 23450, loss 3.285, acc 0.9\n","2019-04-04T22:03:36.316845: step 23460, loss 3.19838, acc 1\n","2019-04-04T22:03:38.774478: step 23470, loss 3.27637, acc 0.95\n","2019-04-04T22:03:41.185142: step 23480, loss 3.16819, acc 1\n","2019-04-04T22:03:43.633237: step 23490, loss 3.17101, acc 1\n","2019-04-04T22:03:45.856214: step 23500, loss 3.16788, acc 1\n","\n","Evaluation:\n","2019-04-04T22:03:55.879231: step 23500, loss 6.08945, acc 0.788776\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.53%, Best = 83.96%\n","\n","2019-04-04T22:03:58.894698: step 23510, loss 3.20233, acc 1\n","2019-04-04T22:04:01.242658: step 23520, loss 3.17091, acc 1\n","2019-04-04T22:04:03.627002: step 23530, loss 3.1718, acc 1\n","2019-04-04T22:04:06.007747: step 23540, loss 3.16554, acc 1\n","2019-04-04T22:04:08.459196: step 23550, loss 3.17874, acc 1\n","2019-04-04T22:04:10.711927: step 23560, loss 3.29156, acc 0.95\n","2019-04-04T22:04:13.197736: step 23570, loss 3.16222, acc 1\n","2019-04-04T22:04:15.660454: step 23580, loss 3.23624, acc 0.95\n","2019-04-04T22:04:18.014346: step 23590, loss 3.16304, acc 1\n","2019-04-04T22:04:20.474293: step 23600, loss 3.16209, acc 1\n","\n","Evaluation:\n","2019-04-04T22:04:30.467726: step 23600, loss 6.03272, acc 0.792085\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.61%, Best = 83.96%\n","\n","2019-04-04T22:04:32.970207: step 23610, loss 3.15963, acc 1\n","2019-04-04T22:04:35.366291: step 23620, loss 3.1598, acc 1\n","2019-04-04T22:04:37.647243: step 23630, loss 3.21098, acc 0.95\n","2019-04-04T22:04:40.109523: step 23640, loss 3.16401, acc 1\n","2019-04-04T22:04:42.430795: step 23650, loss 3.15732, acc 1\n","2019-04-04T22:04:44.926397: step 23660, loss 3.16863, acc 1\n","2019-04-04T22:04:47.372460: step 23670, loss 3.15767, acc 1\n","2019-04-04T22:04:49.833591: step 23680, loss 3.15885, acc 1\n","2019-04-04T22:04:52.226003: step 23690, loss 3.15502, acc 1\n","2019-04-04T22:04:54.664560: step 23700, loss 3.15615, acc 1\n","\n","Evaluation:\n","2019-04-04T22:05:04.640060: step 23700, loss 6.02474, acc 0.790614\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.56%, Best = 83.96%\n","\n","2019-04-04T22:05:07.151768: step 23710, loss 3.16285, acc 1\n","2019-04-04T22:05:09.416672: step 23720, loss 3.16792, acc 1\n","2019-04-04T22:05:11.961084: step 23730, loss 3.16299, acc 1\n","2019-04-04T22:05:14.263131: step 23740, loss 3.28035, acc 0.95\n","2019-04-04T22:05:16.685129: step 23750, loss 3.15257, acc 1\n","2019-04-04T22:05:18.875967: step 23760, loss 3.1522, acc 1\n","2019-04-04T22:05:21.154193: step 23770, loss 3.15951, acc 1\n","2019-04-04T22:05:23.477866: step 23780, loss 3.23946, acc 0.95\n","2019-04-04T22:05:25.582196: step 23790, loss 3.17407, acc 1\n","2019-04-04T22:05:27.981397: step 23800, loss 3.14832, acc 1\n","\n","Evaluation:\n","2019-04-04T22:05:37.935214: step 23800, loss 5.85818, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.57%, Best = 83.96%\n","\n","2019-04-04T22:05:40.127370: step 23810, loss 3.16523, acc 1\n","2019-04-04T22:05:42.798005: step 23820, loss 3.1527, acc 1\n","2019-04-04T22:05:45.132452: step 23830, loss 3.20408, acc 0.95\n","2019-04-04T22:05:47.366221: step 23840, loss 3.14598, acc 1\n","2019-04-04T22:05:49.626241: step 23850, loss 3.14996, acc 1\n","2019-04-04T22:05:51.927778: step 23860, loss 3.33906, acc 0.95\n","2019-04-04T22:05:54.300643: step 23870, loss 3.14412, acc 1\n","2019-04-04T22:05:56.515296: step 23880, loss 3.14554, acc 1\n","2019-04-04T22:05:59.074636: step 23890, loss 3.18256, acc 1\n","2019-04-04T22:06:01.415196: step 23900, loss 3.15282, acc 1\n","\n","Evaluation:\n","2019-04-04T22:06:11.415211: step 23900, loss 5.96316, acc 0.788343\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.35%, Best = 83.96%\n","\n","2019-04-04T22:06:13.909276: step 23910, loss 3.14657, acc 1\n","2019-04-04T22:06:16.227399: step 23920, loss 3.14522, acc 1\n","2019-04-04T22:06:18.537128: step 23930, loss 3.17239, acc 1\n","2019-04-04T22:06:20.870093: step 23940, loss 3.14723, acc 1\n","2019-04-04T22:06:23.235228: step 23950, loss 3.14137, acc 1\n","2019-04-04T22:06:25.843271: step 23960, loss 3.13923, acc 1\n","2019-04-04T22:06:28.073730: step 23970, loss 3.14158, acc 1\n","2019-04-04T22:06:30.405800: step 23980, loss 3.13739, acc 1\n","2019-04-04T22:06:32.696889: step 23990, loss 3.13882, acc 1\n","2019-04-04T22:06:34.982075: step 24000, loss 3.1591, acc 1\n","\n","Evaluation:\n","2019-04-04T22:06:44.964647: step 24000, loss 6.01682, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.69%, Best = 83.96%\n","\n","2019-04-04T22:06:47.435511: step 24010, loss 3.13529, acc 1\n","2019-04-04T22:06:49.907737: step 24020, loss 3.13964, acc 1\n","2019-04-04T22:06:52.161221: step 24030, loss 3.13583, acc 1\n","2019-04-04T22:06:54.512538: step 24040, loss 3.13409, acc 1\n","2019-04-04T22:06:56.739686: step 24050, loss 3.13974, acc 1\n","2019-04-04T22:06:59.178194: step 24060, loss 3.13681, acc 1\n","2019-04-04T22:07:01.561036: step 24070, loss 3.35475, acc 0.95\n","2019-04-04T22:07:03.999955: step 24080, loss 3.13656, acc 1\n","2019-04-04T22:07:06.480849: step 24090, loss 3.13221, acc 1\n","2019-04-04T22:07:08.750351: step 24100, loss 3.1317, acc 1\n","\n","Evaluation:\n","2019-04-04T22:07:18.766985: step 24100, loss 5.8808, acc 0.795761\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.4%, Best = 83.96%\n","\n","2019-04-04T22:07:21.430271: step 24110, loss 3.13009, acc 1\n","2019-04-04T22:07:24.050806: step 24120, loss 3.14361, acc 1\n","2019-04-04T22:07:26.473233: step 24130, loss 3.13406, acc 1\n","2019-04-04T22:07:28.986685: step 24140, loss 3.12739, acc 1\n","2019-04-04T22:07:31.337318: step 24150, loss 3.1266, acc 1\n","2019-04-04T22:07:33.651558: step 24160, loss 3.14727, acc 1\n","2019-04-04T22:07:35.944038: step 24170, loss 3.13847, acc 1\n","2019-04-04T22:07:38.270089: step 24180, loss 3.1316, acc 1\n","2019-04-04T22:07:40.554063: step 24190, loss 3.15022, acc 1\n","2019-04-04T22:07:43.005047: step 24200, loss 3.13212, acc 1\n","\n","Evaluation:\n","2019-04-04T22:07:53.002497: step 24200, loss 5.94531, acc 0.795394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.26%, Best = 83.96%\n","\n","2019-04-04T22:07:55.375802: step 24210, loss 3.15856, acc 0.95\n","2019-04-04T22:07:57.671039: step 24220, loss 3.19506, acc 0.95\n","2019-04-04T22:08:00.271929: step 24230, loss 3.12186, acc 1\n","2019-04-04T22:08:02.531183: step 24240, loss 3.12439, acc 1\n","2019-04-04T22:08:04.845019: step 24250, loss 3.12099, acc 1\n","2019-04-04T22:08:07.192953: step 24260, loss 3.12449, acc 1\n","2019-04-04T22:08:09.421047: step 24270, loss 3.15384, acc 1\n","2019-04-04T22:08:11.720220: step 24280, loss 3.12076, acc 1\n","2019-04-04T22:08:14.265523: step 24290, loss 3.11837, acc 1\n","2019-04-04T22:08:16.619334: step 24300, loss 3.12163, acc 1\n","\n","Evaluation:\n","2019-04-04T22:08:26.611176: step 24300, loss 6.13473, acc 0.796064\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.28%, Best = 83.96%\n","\n","2019-04-04T22:08:28.919348: step 24310, loss 3.14154, acc 1\n","2019-04-04T22:08:31.281086: step 24320, loss 3.12308, acc 1\n","2019-04-04T22:08:33.626492: step 24330, loss 3.11751, acc 1\n","2019-04-04T22:08:35.911309: step 24340, loss 3.11706, acc 1\n","2019-04-04T22:08:38.494450: step 24350, loss 3.11524, acc 1\n","2019-04-04T22:08:40.827667: step 24360, loss 3.11874, acc 1\n","2019-04-04T22:08:43.139987: step 24370, loss 3.1426, acc 1\n","2019-04-04T22:08:45.359105: step 24380, loss 3.18692, acc 1\n","2019-04-04T22:08:47.658989: step 24390, loss 3.11511, acc 1\n","2019-04-04T22:08:50.208080: step 24400, loss 3.11388, acc 1\n","\n","Evaluation:\n","2019-04-04T22:09:00.222770: step 24400, loss 5.86056, acc 0.795394\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.26%, Best = 83.96%\n","\n","2019-04-04T22:09:02.689603: step 24410, loss 3.11225, acc 1\n","2019-04-04T22:09:05.149013: step 24420, loss 3.12253, acc 1\n","2019-04-04T22:09:07.615281: step 24430, loss 3.11076, acc 1\n","2019-04-04T22:09:09.851050: step 24440, loss 3.19613, acc 0.95\n","2019-04-04T22:09:12.691080: step 24450, loss 3.16397, acc 0.95\n","2019-04-04T22:09:15.060814: step 24460, loss 3.10793, acc 1\n","2019-04-04T22:09:17.467455: step 24470, loss 3.10761, acc 1\n","2019-04-04T22:09:19.850066: step 24480, loss 3.12063, acc 1\n","2019-04-04T22:09:21.901852: step 24490, loss 3.10646, acc 1\n","2019-04-04T22:09:24.139498: step 24500, loss 3.10642, acc 1\n","\n","Evaluation:\n","2019-04-04T22:09:34.133184: step 24500, loss 5.96708, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.04%, Best = 83.96%\n","\n","2019-04-04T22:09:36.491520: step 24510, loss 3.10483, acc 1\n","2019-04-04T22:09:39.023783: step 24520, loss 3.11187, acc 1\n","2019-04-04T22:09:41.376594: step 24530, loss 3.10492, acc 1\n","2019-04-04T22:09:43.662169: step 24540, loss 3.12091, acc 1\n","2019-04-04T22:09:45.761044: step 24550, loss 3.10281, acc 1\n","2019-04-04T22:09:48.116871: step 24560, loss 3.10544, acc 1\n","2019-04-04T22:09:50.375915: step 24570, loss 3.10292, acc 1\n","2019-04-04T22:09:53.105976: step 24580, loss 3.15503, acc 1\n","2019-04-04T22:09:55.361738: step 24590, loss 3.11135, acc 1\n","2019-04-04T22:09:57.705249: step 24600, loss 3.12342, acc 1\n","\n","Evaluation:\n","2019-04-04T22:10:07.673941: step 24600, loss 5.8852, acc 0.788776\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.56%, Best = 83.96%\n","\n","2019-04-04T22:10:10.356818: step 24610, loss 3.12323, acc 1\n","2019-04-04T22:10:12.708374: step 24620, loss 3.09815, acc 1\n","2019-04-04T22:10:15.027868: step 24630, loss 3.10147, acc 1\n","2019-04-04T22:10:17.172890: step 24640, loss 3.26577, acc 0.9\n","2019-04-04T22:10:19.374003: step 24650, loss 3.10643, acc 1\n","2019-04-04T22:10:21.844040: step 24660, loss 3.23903, acc 0.95\n","2019-04-04T22:10:24.444258: step 24670, loss 3.10301, acc 1\n","2019-04-04T22:10:26.786088: step 24680, loss 3.09495, acc 1\n","2019-04-04T22:10:29.071005: step 24690, loss 3.09984, acc 1\n","2019-04-04T22:10:31.388552: step 24700, loss 3.28644, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:10:41.409486: step 24700, loss 6.0121, acc 0.796864\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.36%, Best = 83.96%\n","\n","2019-04-04T22:10:43.768275: step 24710, loss 3.18146, acc 0.95\n","2019-04-04T22:10:45.917487: step 24720, loss 3.09382, acc 1\n","2019-04-04T22:10:48.368192: step 24730, loss 3.09173, acc 1\n","2019-04-04T22:10:50.640218: step 24740, loss 3.09137, acc 1\n","2019-04-04T22:10:52.998945: step 24750, loss 3.09334, acc 1\n","2019-04-04T22:10:55.181354: step 24760, loss 3.14114, acc 1\n","2019-04-04T22:10:57.611612: step 24770, loss 3.13258, acc 0.95\n","2019-04-04T22:11:00.213836: step 24780, loss 3.20311, acc 0.95\n","2019-04-04T22:11:02.657922: step 24790, loss 3.12563, acc 0.95\n","2019-04-04T22:11:05.158091: step 24800, loss 3.0934, acc 1\n","\n","Evaluation:\n","2019-04-04T22:11:15.168577: step 24800, loss 5.74315, acc 0.792085\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.9%, Best = 83.96%\n","\n","2019-04-04T22:11:17.521367: step 24810, loss 3.08716, acc 1\n","2019-04-04T22:11:20.069779: step 24820, loss 3.08909, acc 1\n","2019-04-04T22:11:22.321637: step 24830, loss 3.32217, acc 0.9\n","2019-04-04T22:11:24.642727: step 24840, loss 3.13944, acc 0.95\n","2019-04-04T22:11:27.086112: step 24850, loss 3.08974, acc 1\n","2019-04-04T22:11:29.278630: step 24860, loss 3.08639, acc 1\n","2019-04-04T22:11:31.523680: step 24870, loss 3.08408, acc 1\n","2019-04-04T22:11:33.980113: step 24880, loss 3.15062, acc 0.95\n","2019-04-04T22:11:36.382727: step 24890, loss 3.10232, acc 1\n","2019-04-04T22:11:38.836032: step 24900, loss 3.08278, acc 1\n","\n","Evaluation:\n","2019-04-04T22:11:48.815903: step 24900, loss 5.72405, acc 0.789144\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.65%, Best = 83.96%\n","\n","2019-04-04T22:11:51.500223: step 24910, loss 3.09212, acc 1\n","2019-04-04T22:11:53.850024: step 24920, loss 3.0803, acc 1\n","2019-04-04T22:11:56.361036: step 24930, loss 3.08851, acc 1\n","2019-04-04T22:11:58.735060: step 24940, loss 3.07924, acc 1\n","2019-04-04T22:12:01.027900: step 24950, loss 3.08422, acc 1\n","2019-04-04T22:12:03.489414: step 24960, loss 3.10248, acc 1\n","2019-04-04T22:12:05.727572: step 24970, loss 3.08224, acc 1\n","2019-04-04T22:12:08.066987: step 24980, loss 3.08421, acc 1\n","2019-04-04T22:12:10.417863: step 24990, loss 3.07716, acc 1\n","2019-04-04T22:12:12.592573: step 25000, loss 3.09072, acc 1\n","\n","Evaluation:\n","2019-04-04T22:12:22.652457: step 25000, loss 5.74193, acc 0.790247\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.58%, Best = 83.96%\n","\n","2019-04-04T22:12:24.967037: step 25010, loss 3.09385, acc 1\n","2019-04-04T22:12:27.447119: step 25020, loss 3.07587, acc 1\n","2019-04-04T22:12:29.871238: step 25030, loss 3.08517, acc 1\n","2019-04-04T22:12:32.212200: step 25040, loss 3.08722, acc 1\n","2019-04-04T22:12:34.611474: step 25050, loss 3.08005, acc 1\n","2019-04-04T22:12:36.973245: step 25060, loss 3.1328, acc 0.95\n","2019-04-04T22:12:39.358007: step 25070, loss 3.09102, acc 1\n","2019-04-04T22:12:41.633576: step 25080, loss 3.07287, acc 1\n","2019-04-04T22:12:43.891295: step 25090, loss 3.10105, acc 1\n","2019-04-04T22:12:46.418533: step 25100, loss 3.06995, acc 1\n","\n","Evaluation:\n","2019-04-04T22:12:56.394629: step 25100, loss 5.65, acc 0.792085\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.9%, Best = 83.96%\n","\n","2019-04-04T22:12:58.837405: step 25110, loss 3.14793, acc 0.95\n","2019-04-04T22:13:01.161723: step 25120, loss 3.06885, acc 1\n","2019-04-04T22:13:03.518729: step 25130, loss 3.0689, acc 1\n","2019-04-04T22:13:05.853694: step 25140, loss 3.10428, acc 0.95\n","2019-04-04T22:13:08.065772: step 25150, loss 3.91745, acc 0.9\n","2019-04-04T22:13:10.325299: step 25160, loss 3.06688, acc 1\n","2019-04-04T22:13:12.697226: step 25170, loss 3.06839, acc 1\n","2019-04-04T22:13:15.011071: step 25180, loss 3.06525, acc 1\n","2019-04-04T22:13:17.329183: step 25190, loss 3.06448, acc 1\n","2019-04-04T22:13:19.637781: step 25200, loss 3.06848, acc 1\n","\n","Evaluation:\n","2019-04-04T22:13:29.634498: step 25200, loss 5.57608, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.59%, Best = 83.96%\n","\n","2019-04-04T22:13:31.981878: step 25210, loss 3.18281, acc 0.95\n","2019-04-04T22:13:34.422105: step 25220, loss 3.06657, acc 1\n","2019-04-04T22:13:36.810962: step 25230, loss 3.07338, acc 1\n","2019-04-04T22:13:39.205746: step 25240, loss 3.06196, acc 1\n","2019-04-04T22:13:41.822241: step 25250, loss 3.0626, acc 1\n","2019-04-04T22:13:44.204508: step 25260, loss 3.06119, acc 1\n","2019-04-04T22:13:46.659023: step 25270, loss 3.05956, acc 1\n","2019-04-04T22:13:48.915300: step 25280, loss 3.21339, acc 0.95\n","2019-04-04T22:13:51.217379: step 25290, loss 3.05872, acc 1\n","2019-04-04T22:13:53.617221: step 25300, loss 3.05932, acc 1\n","\n","Evaluation:\n","2019-04-04T22:14:03.612069: step 25300, loss 5.59859, acc 0.785835\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.4%, Best = 83.96%\n","\n","2019-04-04T22:14:06.098603: step 25310, loss 3.28642, acc 0.95\n","2019-04-04T22:14:08.390509: step 25320, loss 3.06773, acc 1\n","2019-04-04T22:14:10.783349: step 25330, loss 3.11331, acc 0.95\n","2019-04-04T22:14:13.199546: step 25340, loss 3.05551, acc 1\n","2019-04-04T22:14:15.558588: step 25350, loss 3.0881, acc 1\n","2019-04-04T22:14:17.942042: step 25360, loss 3.0584, acc 1\n","2019-04-04T22:14:20.100642: step 25370, loss 3.05431, acc 1\n","2019-04-04T22:14:22.512075: step 25380, loss 3.05612, acc 1\n","2019-04-04T22:14:24.925175: step 25390, loss 3.20911, acc 0.95\n","2019-04-04T22:14:27.551531: step 25400, loss 3.05203, acc 1\n","\n","Evaluation:\n","2019-04-04T22:14:37.543513: step 25400, loss 5.50964, acc 0.787608\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.69%, Best = 83.96%\n","\n","2019-04-04T22:14:40.260060: step 25410, loss 3.05237, acc 1\n","2019-04-04T22:14:42.691800: step 25420, loss 3.08302, acc 1\n","2019-04-04T22:14:44.917918: step 25430, loss 3.05742, acc 1\n","2019-04-04T22:14:47.285515: step 25440, loss 3.1028, acc 0.95\n","2019-04-04T22:14:49.530231: step 25450, loss 3.44614, acc 0.95\n","2019-04-04T22:14:51.719028: step 25460, loss 3.05091, acc 1\n","2019-04-04T22:14:54.298009: step 25470, loss 3.10377, acc 0.95\n","2019-04-04T22:14:56.639650: step 25480, loss 3.05243, acc 1\n","2019-04-04T22:14:59.228267: step 25490, loss 3.04765, acc 1\n","2019-04-04T22:15:01.528400: step 25500, loss 3.13054, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:15:11.520692: step 25500, loss 5.63229, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.93%, Best = 83.96%\n","\n","2019-04-04T22:15:14.025585: step 25510, loss 3.04607, acc 1\n","2019-04-04T22:15:16.339903: step 25520, loss 3.08179, acc 1\n","2019-04-04T22:15:18.685004: step 25530, loss 3.04486, acc 1\n","2019-04-04T22:15:21.081246: step 25540, loss 3.05184, acc 1\n","2019-04-04T22:15:23.376253: step 25550, loss 3.09722, acc 0.95\n","2019-04-04T22:15:25.721420: step 25560, loss 3.18024, acc 0.95\n","2019-04-04T22:15:27.940256: step 25570, loss 3.04285, acc 1\n","2019-04-04T22:15:30.396452: step 25580, loss 3.04147, acc 1\n","2019-04-04T22:15:32.642659: step 25590, loss 3.06275, acc 1\n","2019-04-04T22:15:34.938595: step 25600, loss 3.07715, acc 1\n","\n","Evaluation:\n","2019-04-04T22:15:44.980180: step 25600, loss 5.50285, acc 0.782158\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.17%, Best = 83.96%\n","\n","2019-04-04T22:15:47.408963: step 25610, loss 3.11053, acc 0.95\n","2019-04-04T22:15:49.690873: step 25620, loss 3.04465, acc 1\n","2019-04-04T22:15:52.209513: step 25630, loss 3.04029, acc 1\n","2019-04-04T22:15:54.657122: step 25640, loss 3.2177, acc 0.95\n","2019-04-04T22:15:57.315906: step 25650, loss 3.03776, acc 1\n","2019-04-04T22:15:59.598365: step 25660, loss 3.04124, acc 1\n","2019-04-04T22:16:01.794271: step 25670, loss 3.03768, acc 1\n","2019-04-04T22:16:04.226968: step 25680, loss 3.05133, acc 1\n","2019-04-04T22:16:06.676013: step 25690, loss 3.03519, acc 1\n","2019-04-04T22:16:09.295389: step 25700, loss 3.03429, acc 1\n","\n","Evaluation:\n","2019-04-04T22:16:19.271005: step 25700, loss 5.41714, acc 0.793188\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.8%, Best = 83.96%\n","\n","2019-04-04T22:16:21.721089: step 25710, loss 3.03693, acc 1\n","2019-04-04T22:16:24.139826: step 25720, loss 3.03896, acc 1\n","2019-04-04T22:16:26.426701: step 25730, loss 3.0326, acc 1\n","2019-04-04T22:16:28.662694: step 25740, loss 3.03206, acc 1\n","2019-04-04T22:16:30.926710: step 25750, loss 3.03331, acc 1\n","2019-04-04T22:16:33.340563: step 25760, loss 3.03353, acc 1\n","2019-04-04T22:16:35.661269: step 25770, loss 3.03162, acc 1\n","2019-04-04T22:16:37.888512: step 25780, loss 3.02961, acc 1\n","2019-04-04T22:16:40.345647: step 25790, loss 3.04393, acc 1\n","2019-04-04T22:16:42.731513: step 25800, loss 3.02825, acc 1\n","\n","Evaluation:\n","2019-04-04T22:16:52.744356: step 25800, loss 5.19883, acc 0.78577\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.52%, Best = 83.96%\n","\n","2019-04-04T22:16:55.209028: step 25810, loss 3.02796, acc 1\n","2019-04-04T22:16:57.697477: step 25820, loss 3.02734, acc 1\n","2019-04-04T22:16:59.911542: step 25830, loss 3.0523, acc 1\n","2019-04-04T22:17:02.126280: step 25840, loss 3.03804, acc 1\n","2019-04-04T22:17:04.637323: step 25850, loss 3.02677, acc 1\n","2019-04-04T22:17:07.069102: step 25860, loss 3.02713, acc 1\n","2019-04-04T22:17:09.345029: step 25870, loss 3.03105, acc 1\n","2019-04-04T22:17:11.653602: step 25880, loss 3.07328, acc 0.95\n","2019-04-04T22:17:13.916052: step 25890, loss 3.05173, acc 1\n","2019-04-04T22:17:16.250409: step 25900, loss 3.02527, acc 1\n","\n","Evaluation:\n","2019-04-04T22:17:26.278644: step 25900, loss 5.06063, acc 0.789879\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T22:17:28.605846: step 25910, loss 3.2111, acc 0.95\n","2019-04-04T22:17:30.989990: step 25920, loss 3.03151, acc 1\n","2019-04-04T22:17:33.283760: step 25930, loss 3.02347, acc 1\n","2019-04-04T22:17:35.543335: step 25940, loss 3.03796, acc 1\n","2019-04-04T22:17:37.822919: step 25950, loss 3.01979, acc 1\n","2019-04-04T22:17:39.983638: step 25960, loss 3.02205, acc 1\n","2019-04-04T22:17:42.215163: step 25970, loss 3.02179, acc 1\n","2019-04-04T22:17:44.725497: step 25980, loss 3.01807, acc 1\n","2019-04-04T22:17:47.018522: step 25990, loss 3.03838, acc 1\n","2019-04-04T22:17:49.630696: step 26000, loss 3.03077, acc 1\n","\n","Evaluation:\n","2019-04-04T22:17:59.784896: step 26000, loss 5.04546, acc 0.790549\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.93%, Best = 83.96%\n","\n","2019-04-04T22:18:02.044461: step 26010, loss 3.02626, acc 1\n","2019-04-04T22:18:04.500094: step 26020, loss 3.01542, acc 1\n","2019-04-04T22:18:06.902901: step 26030, loss 3.01607, acc 1\n","2019-04-04T22:18:09.261868: step 26040, loss 3.01957, acc 1\n","2019-04-04T22:18:11.634532: step 26050, loss 3.01368, acc 1\n","2019-04-04T22:18:14.125303: step 26060, loss 3.01842, acc 1\n","2019-04-04T22:18:16.444058: step 26070, loss 3.02256, acc 1\n","2019-04-04T22:18:18.815496: step 26080, loss 3.68367, acc 0.9\n","2019-04-04T22:18:21.168499: step 26090, loss 3.0129, acc 1\n","2019-04-04T22:18:23.624831: step 26100, loss 3.01093, acc 1\n","\n","Evaluation:\n","2019-04-04T22:18:33.807254: step 26100, loss 5.46739, acc 0.790982\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.81%, Best = 83.96%\n","\n","2019-04-04T22:18:36.312867: step 26110, loss 3.02559, acc 1\n","2019-04-04T22:18:38.732821: step 26120, loss 3.02896, acc 1\n","2019-04-04T22:18:41.127446: step 26130, loss 3.03664, acc 1\n","2019-04-04T22:18:43.531851: step 26140, loss 3.09073, acc 0.95\n","2019-04-04T22:18:45.851381: step 26150, loss 3.01129, acc 1\n","2019-04-04T22:18:48.166657: step 26160, loss 3.00804, acc 1\n","2019-04-04T22:18:50.294496: step 26170, loss 3.00889, acc 1\n","2019-04-04T22:18:52.837814: step 26180, loss 3.01863, acc 1\n","2019-04-04T22:18:55.274008: step 26190, loss 3.0132, acc 1\n","2019-04-04T22:18:57.488921: step 26200, loss 3.00534, acc 1\n","\n","Evaluation:\n","2019-04-04T22:19:07.503712: step 26200, loss 5.33777, acc 0.793923\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.99%, Best = 83.96%\n","\n","2019-04-04T22:19:10.051574: step 26210, loss 3.00489, acc 1\n","2019-04-04T22:19:12.556142: step 26220, loss 3.00403, acc 1\n","2019-04-04T22:19:14.844972: step 26230, loss 3.06805, acc 0.95\n","2019-04-04T22:19:17.308372: step 26240, loss 3.31063, acc 0.9\n","2019-04-04T22:19:19.636690: step 26250, loss 3.0353, acc 1\n","2019-04-04T22:19:21.880582: step 26260, loss 3.00151, acc 1\n","2019-04-04T22:19:24.111718: step 26270, loss 3.01198, acc 1\n","2019-04-04T22:19:26.375547: step 26280, loss 3.00146, acc 1\n","2019-04-04T22:19:28.731370: step 26290, loss 3.00002, acc 1\n","2019-04-04T22:19:31.184488: step 26300, loss 3.00181, acc 1\n","\n","Evaluation:\n","2019-04-04T22:19:41.247792: step 26300, loss 5.46346, acc 0.795696\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.35%, Best = 83.96%\n","\n","2019-04-04T22:19:43.810320: step 26310, loss 2.99885, acc 1\n","2019-04-04T22:19:46.065728: step 26320, loss 3.0008, acc 1\n","2019-04-04T22:19:48.266107: step 26330, loss 3.00095, acc 1\n","2019-04-04T22:19:50.570024: step 26340, loss 2.99677, acc 1\n","2019-04-04T22:19:53.055916: step 26350, loss 2.99658, acc 1\n","2019-04-04T22:19:55.347002: step 26360, loss 3.02287, acc 1\n","2019-04-04T22:19:57.558270: step 26370, loss 3.00595, acc 1\n","2019-04-04T22:19:59.939275: step 26380, loss 2.99487, acc 1\n","2019-04-04T22:20:02.527449: step 26390, loss 2.99392, acc 1\n","2019-04-04T22:20:04.740760: step 26400, loss 2.99417, acc 1\n","\n","Evaluation:\n","2019-04-04T22:20:14.702323: step 26400, loss 5.5593, acc 0.794961\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T22:20:17.049273: step 26410, loss 3.02224, acc 1\n","2019-04-04T22:20:19.331317: step 26420, loss 2.99414, acc 1\n","2019-04-04T22:20:21.708530: step 26430, loss 2.99276, acc 1\n","2019-04-04T22:20:24.156445: step 26440, loss 2.99981, acc 1\n","2019-04-04T22:20:26.479307: step 26450, loss 3.15174, acc 0.95\n","2019-04-04T22:20:28.819187: step 26460, loss 2.9899, acc 1\n","2019-04-04T22:20:31.041251: step 26470, loss 3.19944, acc 0.95\n","2019-04-04T22:20:33.216538: step 26480, loss 2.99515, acc 1\n","2019-04-04T22:20:35.543613: step 26490, loss 2.98802, acc 1\n","2019-04-04T22:20:37.975513: step 26500, loss 3.06579, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:20:47.962886: step 26500, loss 5.28669, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.67%, Best = 83.96%\n","\n","2019-04-04T22:20:50.389914: step 26510, loss 3.12944, acc 0.95\n","2019-04-04T22:20:52.969668: step 26520, loss 2.99922, acc 1\n","2019-04-04T22:20:55.408989: step 26530, loss 2.98559, acc 1\n","2019-04-04T22:20:57.680069: step 26540, loss 2.98558, acc 1\n","2019-04-04T22:21:00.164940: step 26550, loss 2.9846, acc 1\n","2019-04-04T22:21:02.638755: step 26560, loss 2.98457, acc 1\n","2019-04-04T22:21:04.926518: step 26570, loss 2.98418, acc 1\n","2019-04-04T22:21:07.383942: step 26580, loss 2.98346, acc 1\n","2019-04-04T22:21:09.560622: step 26590, loss 3.01766, acc 1\n","2019-04-04T22:21:11.750465: step 26600, loss 2.9936, acc 1\n","\n","Evaluation:\n","2019-04-04T22:21:21.707138: step 26600, loss 5.62206, acc 0.794161\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.27%, Best = 83.96%\n","\n","2019-04-04T22:21:24.392734: step 26610, loss 2.98195, acc 1\n","2019-04-04T22:21:26.716766: step 26620, loss 2.98027, acc 1\n","2019-04-04T22:21:29.138530: step 26630, loss 2.99772, acc 1\n","2019-04-04T22:21:31.286168: step 26640, loss 2.98287, acc 1\n","2019-04-04T22:21:33.795096: step 26650, loss 3.11292, acc 0.95\n","2019-04-04T22:21:36.165453: step 26660, loss 2.9967, acc 1\n","2019-04-04T22:21:38.696752: step 26670, loss 2.97732, acc 1\n","2019-04-04T22:21:41.286090: step 26680, loss 3.0206, acc 0.95\n","2019-04-04T22:21:43.522391: step 26690, loss 2.97848, acc 1\n","2019-04-04T22:21:45.783599: step 26700, loss 2.97795, acc 1\n","\n","Evaluation:\n","2019-04-04T22:21:55.816130: step 26700, loss 5.55908, acc 0.794961\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.35%, Best = 83.96%\n","\n","2019-04-04T22:21:58.158734: step 26710, loss 2.97997, acc 1\n","2019-04-04T22:22:00.435321: step 26720, loss 2.97876, acc 1\n","2019-04-04T22:22:02.695676: step 26730, loss 2.97407, acc 1\n","2019-04-04T22:22:05.119229: step 26740, loss 2.97605, acc 1\n","2019-04-04T22:22:07.444358: step 26750, loss 2.97449, acc 1\n","2019-04-04T22:22:09.780961: step 26760, loss 2.98238, acc 1\n","2019-04-04T22:22:12.115275: step 26770, loss 2.9933, acc 1\n","2019-04-04T22:22:14.479963: step 26780, loss 2.97125, acc 1\n","2019-04-04T22:22:16.800185: step 26790, loss 2.98133, acc 1\n","2019-04-04T22:22:19.481250: step 26800, loss 2.97402, acc 1\n","\n","Evaluation:\n","2019-04-04T22:22:29.456339: step 26800, loss 5.53207, acc 0.794226\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.11%, Best = 83.96%\n","\n","2019-04-04T22:22:32.108660: step 26810, loss 2.97328, acc 1\n","2019-04-04T22:22:34.504541: step 26820, loss 2.9688, acc 1\n","2019-04-04T22:22:36.760925: step 26830, loss 2.97113, acc 1\n","2019-04-04T22:22:39.047894: step 26840, loss 3.14712, acc 0.9\n","2019-04-04T22:22:41.361984: step 26850, loss 2.96733, acc 1\n","2019-04-04T22:22:43.744558: step 26860, loss 2.97426, acc 1\n","2019-04-04T22:22:45.968002: step 26870, loss 2.98648, acc 1\n","2019-04-04T22:22:48.242978: step 26880, loss 2.96533, acc 1\n","2019-04-04T22:22:50.676295: step 26890, loss 2.98691, acc 1\n","2019-04-04T22:22:53.036008: step 26900, loss 2.96453, acc 1\n","\n","Evaluation:\n","2019-04-04T22:23:03.017691: step 26900, loss 5.57379, acc 0.790549\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.71%, Best = 83.96%\n","\n","2019-04-04T22:23:05.589990: step 26910, loss 3.17492, acc 0.9\n","2019-04-04T22:23:07.985660: step 26920, loss 2.96386, acc 1\n","2019-04-04T22:23:10.335143: step 26930, loss 2.96274, acc 1\n","2019-04-04T22:23:12.777557: step 26940, loss 2.98919, acc 1\n","2019-04-04T22:23:15.026637: step 26950, loss 3.16118, acc 0.95\n","2019-04-04T22:23:17.330145: step 26960, loss 2.96621, acc 1\n","2019-04-04T22:23:19.651712: step 26970, loss 2.96027, acc 1\n","2019-04-04T22:23:22.057447: step 26980, loss 2.96155, acc 1\n","2019-04-04T22:23:24.406632: step 26990, loss 2.95996, acc 1\n","2019-04-04T22:23:26.710208: step 27000, loss 2.95844, acc 1\n","\n","Evaluation:\n","2019-04-04T22:23:36.688265: step 27000, loss 5.70561, acc 0.796129\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.27%, Best = 83.96%\n","\n","2019-04-04T22:23:39.157400: step 27010, loss 2.98096, acc 1\n","2019-04-04T22:23:41.515125: step 27020, loss 2.95722, acc 1\n","2019-04-04T22:23:44.055134: step 27030, loss 2.95817, acc 1\n","2019-04-04T22:23:46.594060: step 27040, loss 3.27246, acc 0.95\n","2019-04-04T22:23:48.987173: step 27050, loss 2.96427, acc 1\n","2019-04-04T22:23:51.375757: step 27060, loss 2.95823, acc 1\n","2019-04-04T22:23:53.667703: step 27070, loss 3.01896, acc 0.95\n","2019-04-04T22:23:56.297567: step 27080, loss 2.97151, acc 1\n","2019-04-04T22:23:58.574921: step 27090, loss 2.97197, acc 1\n","2019-04-04T22:24:00.815417: step 27100, loss 3.02869, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:24:10.761980: step 27100, loss 5.75483, acc 0.792388\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.08%, Best = 83.96%\n","\n","2019-04-04T22:24:13.109672: step 27110, loss 2.95927, acc 1\n","2019-04-04T22:24:15.204097: step 27120, loss 2.95215, acc 1\n","2019-04-04T22:24:17.605826: step 27130, loss 2.95226, acc 1\n","2019-04-04T22:24:20.178765: step 27140, loss 2.97253, acc 1\n","2019-04-04T22:24:22.751819: step 27150, loss 2.99193, acc 1\n","2019-04-04T22:24:25.037557: step 27160, loss 2.99716, acc 0.95\n","2019-04-04T22:24:27.381818: step 27170, loss 3.01641, acc 0.95\n","2019-04-04T22:24:29.740620: step 27180, loss 2.95127, acc 1\n","2019-04-04T22:24:32.079647: step 27190, loss 2.99894, acc 0.95\n","2019-04-04T22:24:34.440434: step 27200, loss 2.94681, acc 1\n","\n","Evaluation:\n","2019-04-04T22:24:44.388365: step 27200, loss 5.85111, acc 0.791285\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.78%, Best = 83.96%\n","\n","2019-04-04T22:24:46.723587: step 27210, loss 2.9483, acc 1\n","2019-04-04T22:24:49.103446: step 27220, loss 2.94609, acc 1\n","2019-04-04T22:24:51.408875: step 27230, loss 2.9451, acc 1\n","2019-04-04T22:24:53.882914: step 27240, loss 3.29962, acc 0.95\n","2019-04-04T22:24:56.036521: step 27250, loss 2.94776, acc 1\n","2019-04-04T22:24:58.460041: step 27260, loss 2.94526, acc 1\n","2019-04-04T22:25:00.678969: step 27270, loss 2.95584, acc 1\n","2019-04-04T22:25:03.160046: step 27280, loss 3.04607, acc 0.95\n","2019-04-04T22:25:05.682824: step 27290, loss 2.94187, acc 1\n","2019-04-04T22:25:08.080877: step 27300, loss 3.20028, acc 0.9\n","\n","Evaluation:\n","2019-04-04T22:25:18.208066: step 27300, loss 6.04342, acc 0.788343\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.8%, Best = 83.96%\n","\n","2019-04-04T22:25:20.550966: step 27310, loss 3.05609, acc 0.95\n","2019-04-04T22:25:22.970864: step 27320, loss 2.96948, acc 1\n","2019-04-04T22:25:25.204023: step 27330, loss 3.05374, acc 0.95\n","2019-04-04T22:25:27.773774: step 27340, loss 2.94088, acc 1\n","2019-04-04T22:25:30.340764: step 27350, loss 2.93947, acc 1\n","2019-04-04T22:25:32.614225: step 27360, loss 2.93812, acc 1\n","2019-04-04T22:25:35.106652: step 27370, loss 2.93987, acc 1\n","2019-04-04T22:25:37.480548: step 27380, loss 2.94032, acc 1\n","2019-04-04T22:25:39.695858: step 27390, loss 3.14632, acc 0.95\n","2019-04-04T22:25:42.065505: step 27400, loss 2.93756, acc 1\n","\n","Evaluation:\n","2019-04-04T22:25:52.189575: step 27400, loss 6.00847, acc 0.790182\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.88%, Best = 83.96%\n","\n","2019-04-04T22:25:54.832773: step 27410, loss 2.93882, acc 1\n","2019-04-04T22:25:57.510935: step 27420, loss 2.93537, acc 1\n","2019-04-04T22:25:59.923139: step 27430, loss 2.95956, acc 1\n","2019-04-04T22:26:02.281721: step 27440, loss 2.93784, acc 1\n","2019-04-04T22:26:04.534257: step 27450, loss 2.96387, acc 1\n","2019-04-04T22:26:06.826800: step 27460, loss 2.93291, acc 1\n","2019-04-04T22:26:09.064451: step 27470, loss 2.93461, acc 1\n","2019-04-04T22:26:11.253410: step 27480, loss 2.95194, acc 1\n","2019-04-04T22:26:13.637012: step 27490, loss 2.93037, acc 1\n","2019-04-04T22:26:15.949998: step 27500, loss 2.94383, acc 1\n","\n","Evaluation:\n","2019-04-04T22:26:25.931491: step 27500, loss 5.73247, acc 0.789079\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.69%, Best = 83.96%\n","\n","2019-04-04T22:26:28.422054: step 27510, loss 2.92922, acc 1\n","2019-04-04T22:26:30.836885: step 27520, loss 2.93497, acc 1\n","2019-04-04T22:26:33.043780: step 27530, loss 2.93122, acc 1\n","2019-04-04T22:26:35.456340: step 27540, loss 2.93405, acc 1\n","2019-04-04T22:26:37.692313: step 27550, loss 2.92897, acc 1\n","2019-04-04T22:26:40.172163: step 27560, loss 2.93088, acc 1\n","2019-04-04T22:26:42.580602: step 27570, loss 2.92682, acc 1\n","2019-04-04T22:26:44.863538: step 27580, loss 2.92917, acc 1\n","2019-04-04T22:26:47.010333: step 27590, loss 2.94296, acc 1\n","2019-04-04T22:26:49.285219: step 27600, loss 3.01767, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:26:59.236760: step 27600, loss 5.83446, acc 0.789014\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.63%, Best = 83.96%\n","\n","2019-04-04T22:27:01.561807: step 27610, loss 2.97499, acc 0.95\n","2019-04-04T22:27:04.082354: step 27620, loss 2.92294, acc 1\n","2019-04-04T22:27:06.376736: step 27630, loss 2.92487, acc 1\n","2019-04-04T22:27:08.711861: step 27640, loss 2.92433, acc 1\n","2019-04-04T22:27:11.045471: step 27650, loss 2.98266, acc 0.95\n","2019-04-04T22:27:13.535943: step 27660, loss 2.92548, acc 1\n","2019-04-04T22:27:15.908909: step 27670, loss 2.923, acc 1\n","2019-04-04T22:27:18.440670: step 27680, loss 2.91973, acc 1\n","2019-04-04T22:27:20.709327: step 27690, loss 2.9206, acc 1\n","2019-04-04T22:27:23.200024: step 27700, loss 2.93106, acc 1\n","\n","Evaluation:\n","2019-04-04T22:27:33.156919: step 27700, loss 5.74615, acc 0.793123\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.04%, Best = 83.96%\n","\n","2019-04-04T22:27:35.702596: step 27710, loss 2.92456, acc 1\n","2019-04-04T22:27:37.929008: step 27720, loss 2.92252, acc 1\n","2019-04-04T22:27:40.329959: step 27730, loss 2.91788, acc 1\n","2019-04-04T22:27:42.669856: step 27740, loss 2.91639, acc 1\n","2019-04-04T22:27:44.986028: step 27750, loss 2.93777, acc 1\n","2019-04-04T22:27:47.329870: step 27760, loss 2.9807, acc 0.95\n","2019-04-04T22:27:49.587830: step 27770, loss 2.92247, acc 1\n","2019-04-04T22:27:52.076785: step 27780, loss 2.94116, acc 1\n","2019-04-04T22:27:54.427219: step 27790, loss 2.91587, acc 1\n","2019-04-04T22:27:56.650480: step 27800, loss 2.92245, acc 1\n","\n","Evaluation:\n","2019-04-04T22:28:06.589834: step 27800, loss 6.03443, acc 0.789014\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.76%, Best = 83.96%\n","\n","2019-04-04T22:28:08.954004: step 27810, loss 2.91338, acc 1\n","2019-04-04T22:28:11.394080: step 27820, loss 2.91592, acc 1\n","2019-04-04T22:28:13.723054: step 27830, loss 2.91119, acc 1\n","2019-04-04T22:28:16.230819: step 27840, loss 2.91547, acc 1\n","2019-04-04T22:28:18.632936: step 27850, loss 2.914, acc 1\n","2019-04-04T22:28:21.011445: step 27860, loss 2.92883, acc 1\n","2019-04-04T22:28:23.353111: step 27870, loss 2.90875, acc 1\n","2019-04-04T22:28:25.676070: step 27880, loss 2.91956, acc 1\n","2019-04-04T22:28:27.806181: step 27890, loss 3.22177, acc 0.95\n","2019-04-04T22:28:30.275136: step 27900, loss 2.91597, acc 1\n","\n","Evaluation:\n","2019-04-04T22:28:40.248502: step 27900, loss 5.98652, acc 0.789014\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.57%, Best = 83.96%\n","\n","2019-04-04T22:28:42.669017: step 27910, loss 2.90692, acc 1\n","2019-04-04T22:28:44.976557: step 27920, loss 2.91521, acc 1\n","2019-04-04T22:28:47.396053: step 27930, loss 2.92655, acc 1\n","2019-04-04T22:28:50.044945: step 27940, loss 2.90508, acc 1\n","2019-04-04T22:28:52.222427: step 27950, loss 2.91952, acc 1\n","2019-04-04T22:28:54.707034: step 27960, loss 3.30992, acc 0.95\n","2019-04-04T22:28:57.149222: step 27970, loss 2.90512, acc 1\n","2019-04-04T22:28:59.558455: step 27980, loss 2.90246, acc 1\n","2019-04-04T22:29:01.865233: step 27990, loss 2.903, acc 1\n","2019-04-04T22:29:04.151475: step 28000, loss 2.9155, acc 1\n","\n","Evaluation:\n","2019-04-04T22:29:14.129771: step 28000, loss 6.16767, acc 0.787911\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.58%, Best = 83.96%\n","\n","2019-04-04T22:29:16.444286: step 28010, loss 2.90923, acc 1\n","2019-04-04T22:29:18.791379: step 28020, loss 2.90064, acc 1\n","2019-04-04T22:29:21.329870: step 28030, loss 2.91665, acc 1\n","2019-04-04T22:29:23.601654: step 28040, loss 2.90038, acc 1\n","2019-04-04T22:29:26.103684: step 28050, loss 2.91433, acc 1\n","2019-04-04T22:29:28.425770: step 28060, loss 3.00544, acc 0.95\n","2019-04-04T22:29:31.018219: step 28070, loss 2.96017, acc 1\n","2019-04-04T22:29:33.392815: step 28080, loss 2.99038, acc 0.95\n","2019-04-04T22:29:35.657594: step 28090, loss 2.9144, acc 1\n","2019-04-04T22:29:38.247663: step 28100, loss 2.9137, acc 1\n","\n","Evaluation:\n","2019-04-04T22:29:48.245865: step 28100, loss 5.81649, acc 0.789446\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.91%, Best = 83.96%\n","\n","2019-04-04T22:29:50.651292: step 28110, loss 2.90463, acc 1\n","2019-04-04T22:29:53.186540: step 28120, loss 2.89455, acc 1\n","2019-04-04T22:29:55.433974: step 28130, loss 2.89405, acc 1\n","2019-04-04T22:29:57.877657: step 28140, loss 2.92047, acc 1\n","2019-04-04T22:30:00.207186: step 28150, loss 2.90174, acc 1\n","2019-04-04T22:30:02.687182: step 28160, loss 2.89246, acc 1\n","2019-04-04T22:30:04.975355: step 28170, loss 2.932, acc 0.95\n","2019-04-04T22:30:07.267511: step 28180, loss 2.89113, acc 1\n","2019-04-04T22:30:09.810658: step 28190, loss 2.89173, acc 1\n","2019-04-04T22:30:12.079404: step 28200, loss 2.8927, acc 1\n","\n","Evaluation:\n","2019-04-04T22:30:22.064861: step 28200, loss 5.64781, acc 0.789144\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.77%, Best = 83.96%\n","\n","2019-04-04T22:30:24.319736: step 28210, loss 2.89923, acc 1\n","2019-04-04T22:30:26.547387: step 28220, loss 2.89125, acc 1\n","2019-04-04T22:30:28.898197: step 28230, loss 2.90971, acc 1\n","2019-04-04T22:30:31.342396: step 28240, loss 2.88985, acc 1\n","2019-04-04T22:30:33.574841: step 28250, loss 2.93431, acc 1\n","2019-04-04T22:30:35.891249: step 28260, loss 2.88688, acc 1\n","2019-04-04T22:30:38.171858: step 28270, loss 2.8909, acc 1\n","2019-04-04T22:30:40.758907: step 28280, loss 2.88585, acc 1\n","2019-04-04T22:30:42.983104: step 28290, loss 2.88678, acc 1\n","2019-04-04T22:30:45.314809: step 28300, loss 2.90012, acc 1\n","\n","Evaluation:\n","2019-04-04T22:30:55.345544: step 28300, loss 5.76775, acc 0.79349\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T22:30:57.824653: step 28310, loss 2.88499, acc 1\n","2019-04-04T22:31:00.070397: step 28320, loss 2.88376, acc 1\n","2019-04-04T22:31:02.585745: step 28330, loss 2.88755, acc 1\n","2019-04-04T22:31:05.032935: step 28340, loss 2.88264, acc 1\n","2019-04-04T22:31:07.359817: step 28350, loss 2.88955, acc 1\n","2019-04-04T22:31:09.592849: step 28360, loss 2.94839, acc 0.95\n","2019-04-04T22:31:12.008176: step 28370, loss 2.90865, acc 1\n","2019-04-04T22:31:14.539760: step 28380, loss 2.92831, acc 0.95\n","2019-04-04T22:31:16.956884: step 28390, loss 2.88042, acc 1\n","2019-04-04T22:31:19.356061: step 28400, loss 2.88044, acc 1\n","\n","Evaluation:\n","2019-04-04T22:31:29.323924: step 28400, loss 5.81456, acc 0.795329\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.15%, Best = 83.96%\n","\n","2019-04-04T22:31:31.673654: step 28410, loss 2.96229, acc 0.95\n","2019-04-04T22:31:33.905321: step 28420, loss 3.29099, acc 0.95\n","2019-04-04T22:31:36.391380: step 28430, loss 2.92767, acc 1\n","2019-04-04T22:31:38.740853: step 28440, loss 2.88905, acc 1\n","2019-04-04T22:31:41.118286: step 28450, loss 2.87594, acc 1\n","2019-04-04T22:31:43.354694: step 28460, loss 2.87559, acc 1\n","2019-04-04T22:31:45.816249: step 28470, loss 2.89615, acc 1\n","2019-04-04T22:31:47.986539: step 28480, loss 2.87558, acc 1\n","2019-04-04T22:31:50.265921: step 28490, loss 2.90438, acc 1\n","2019-04-04T22:31:52.736850: step 28500, loss 2.87315, acc 1\n","\n","Evaluation:\n","2019-04-04T22:32:02.780919: step 28500, loss 5.65901, acc 0.789814\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.48%, Best = 83.96%\n","\n","2019-04-04T22:32:05.356536: step 28510, loss 2.87473, acc 1\n","2019-04-04T22:32:07.766890: step 28520, loss 2.87298, acc 1\n","2019-04-04T22:32:10.226947: step 28530, loss 2.87589, acc 1\n","2019-04-04T22:32:12.579124: step 28540, loss 2.87163, acc 1\n","2019-04-04T22:32:15.025037: step 28550, loss 2.87269, acc 1\n","2019-04-04T22:32:17.372591: step 28560, loss 2.88611, acc 1\n","2019-04-04T22:32:19.801355: step 28570, loss 2.88375, acc 1\n","2019-04-04T22:32:22.055715: step 28580, loss 2.99901, acc 0.95\n","2019-04-04T22:32:24.465468: step 28590, loss 2.8708, acc 1\n","2019-04-04T22:32:26.831202: step 28600, loss 2.91839, acc 1\n","\n","Evaluation:\n","2019-04-04T22:32:36.785478: step 28600, loss 5.40091, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.73%, Best = 83.96%\n","\n","2019-04-04T22:32:39.105017: step 28610, loss 2.89191, acc 1\n","2019-04-04T22:32:41.650194: step 28620, loss 2.86691, acc 1\n","2019-04-04T22:32:43.947740: step 28630, loss 2.86594, acc 1\n","2019-04-04T22:32:46.332405: step 28640, loss 2.86612, acc 1\n","2019-04-04T22:32:48.592325: step 28650, loss 2.86658, acc 1\n","2019-04-04T22:32:50.971738: step 28660, loss 2.87005, acc 1\n","2019-04-04T22:32:53.377941: step 28670, loss 2.87072, acc 1\n","2019-04-04T22:32:55.715234: step 28680, loss 2.87461, acc 1\n","2019-04-04T22:32:58.040047: step 28690, loss 2.94651, acc 0.9\n","2019-04-04T22:33:00.536566: step 28700, loss 2.86341, acc 1\n","\n","Evaluation:\n","2019-04-04T22:33:10.544475: step 28700, loss 5.59071, acc 0.785099\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.31%, Best = 83.96%\n","\n","2019-04-04T22:33:12.898438: step 28710, loss 2.86312, acc 1\n","2019-04-04T22:33:15.409916: step 28720, loss 2.86967, acc 1\n","2019-04-04T22:33:17.749886: step 28730, loss 2.86058, acc 1\n","2019-04-04T22:33:20.152721: step 28740, loss 2.87781, acc 1\n","2019-04-04T22:33:22.521071: step 28750, loss 2.86115, acc 1\n","2019-04-04T22:33:24.978997: step 28760, loss 2.88244, acc 1\n","2019-04-04T22:33:27.260268: step 28770, loss 2.90001, acc 0.95\n","2019-04-04T22:33:29.694920: step 28780, loss 2.87426, acc 1\n","2019-04-04T22:33:31.957760: step 28790, loss 2.86813, acc 1\n","2019-04-04T22:33:34.226219: step 28800, loss 2.85778, acc 1\n","\n","Evaluation:\n","2019-04-04T22:33:44.314279: step 28800, loss 5.56412, acc 0.785467\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.44%, Best = 83.96%\n","\n","2019-04-04T22:33:46.792495: step 28810, loss 2.86539, acc 1\n","2019-04-04T22:33:49.269595: step 28820, loss 2.85923, acc 1\n","2019-04-04T22:33:51.371625: step 28830, loss 2.86482, acc 1\n","2019-04-04T22:33:53.654744: step 28840, loss 2.85794, acc 1\n","2019-04-04T22:33:55.980616: step 28850, loss 2.85699, acc 1\n","2019-04-04T22:33:58.363227: step 28860, loss 2.85367, acc 1\n","2019-04-04T22:34:00.698828: step 28870, loss 2.85313, acc 1\n","2019-04-04T22:34:03.087804: step 28880, loss 2.85235, acc 1\n","2019-04-04T22:34:05.384145: step 28890, loss 2.85185, acc 1\n","2019-04-04T22:34:07.514965: step 28900, loss 2.86113, acc 1\n","\n","Evaluation:\n","2019-04-04T22:34:17.515668: step 28900, loss 5.44688, acc 0.78657\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.48%, Best = 83.96%\n","\n","2019-04-04T22:34:19.954564: step 28910, loss 2.85092, acc 1\n","2019-04-04T22:34:22.356522: step 28920, loss 2.85382, acc 1\n","2019-04-04T22:34:24.798556: step 28930, loss 2.84927, acc 1\n","2019-04-04T22:34:27.094671: step 28940, loss 2.85076, acc 1\n","2019-04-04T22:34:29.377351: step 28950, loss 2.84865, acc 1\n","2019-04-04T22:34:31.754945: step 28960, loss 2.8479, acc 1\n","2019-04-04T22:34:34.176873: step 28970, loss 2.85244, acc 1\n","2019-04-04T22:34:36.680682: step 28980, loss 2.84696, acc 1\n","2019-04-04T22:34:39.006464: step 28990, loss 2.84632, acc 1\n","2019-04-04T22:34:41.395367: step 29000, loss 2.84823, acc 1\n","\n","Evaluation:\n","2019-04-04T22:34:51.509475: step 29000, loss 5.35691, acc 0.785099\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.33%, Best = 83.96%\n","\n","2019-04-04T22:34:53.906675: step 29010, loss 2.87279, acc 1\n","2019-04-04T22:34:56.499673: step 29020, loss 2.85096, acc 1\n","2019-04-04T22:34:58.747679: step 29030, loss 2.844, acc 1\n","2019-04-04T22:35:01.062598: step 29040, loss 2.84336, acc 1\n","2019-04-04T22:35:03.470077: step 29050, loss 2.84282, acc 1\n","2019-04-04T22:35:05.877900: step 29060, loss 2.85491, acc 1\n","2019-04-04T22:35:08.117432: step 29070, loss 2.8415, acc 1\n","2019-04-04T22:35:10.341234: step 29080, loss 2.84189, acc 1\n","2019-04-04T22:35:12.700323: step 29090, loss 2.84065, acc 1\n","2019-04-04T22:35:14.988656: step 29100, loss 2.87595, acc 1\n","\n","Evaluation:\n","2019-04-04T22:35:25.069908: step 29100, loss 5.61202, acc 0.785402\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.47%, Best = 83.96%\n","\n","2019-04-04T22:35:27.627437: step 29110, loss 2.83956, acc 1\n","2019-04-04T22:35:29.952949: step 29120, loss 2.84043, acc 1\n","2019-04-04T22:35:32.295107: step 29130, loss 2.85471, acc 1\n","2019-04-04T22:35:34.713994: step 29140, loss 2.8884, acc 0.95\n","2019-04-04T22:35:37.026899: step 29150, loss 2.83739, acc 1\n","2019-04-04T22:35:39.507088: step 29160, loss 2.84, acc 1\n","2019-04-04T22:35:41.864115: step 29170, loss 2.84815, acc 1\n","2019-04-04T22:35:44.322383: step 29180, loss 2.94722, acc 0.95\n","2019-04-04T22:35:46.728580: step 29190, loss 2.91395, acc 0.95\n","2019-04-04T22:35:48.969389: step 29200, loss 2.88941, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:35:59.031364: step 29200, loss 5.36617, acc 0.789879\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.9%, Best = 83.96%\n","\n","2019-04-04T22:36:01.312848: step 29210, loss 2.87135, acc 0.95\n","2019-04-04T22:36:03.638232: step 29220, loss 2.84005, acc 1\n","2019-04-04T22:36:06.138036: step 29230, loss 2.83288, acc 1\n","2019-04-04T22:36:08.561163: step 29240, loss 2.99904, acc 0.95\n","2019-04-04T22:36:10.904616: step 29250, loss 2.85119, acc 1\n","2019-04-04T22:36:13.249933: step 29260, loss 3.00158, acc 0.95\n","2019-04-04T22:36:15.694679: step 29270, loss 2.83142, acc 1\n","2019-04-04T22:36:18.056661: step 29280, loss 2.96671, acc 0.95\n","2019-04-04T22:36:20.550798: step 29290, loss 2.84223, acc 1\n","2019-04-04T22:36:22.926889: step 29300, loss 2.82892, acc 1\n","\n","Evaluation:\n","2019-04-04T22:36:33.018577: step 29300, loss 5.31707, acc 0.78657\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.6%, Best = 83.96%\n","\n","2019-04-04T22:36:35.373134: step 29310, loss 2.82844, acc 1\n","2019-04-04T22:36:37.684284: step 29320, loss 2.82829, acc 1\n","2019-04-04T22:36:39.913285: step 29330, loss 2.83581, acc 1\n","2019-04-04T22:36:42.134603: step 29340, loss 2.82794, acc 1\n","2019-04-04T22:36:44.424052: step 29350, loss 2.82702, acc 1\n","2019-04-04T22:36:46.755878: step 29360, loss 2.82844, acc 1\n","2019-04-04T22:36:49.256511: step 29370, loss 2.82765, acc 1\n","2019-04-04T22:36:51.628107: step 29380, loss 2.82864, acc 1\n","2019-04-04T22:36:54.072332: step 29390, loss 2.82444, acc 1\n","2019-04-04T22:36:56.305985: step 29400, loss 2.87305, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:37:06.369260: step 29400, loss 5.23674, acc 0.79282\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.98%, Best = 83.96%\n","\n","2019-04-04T22:37:08.899615: step 29410, loss 2.85101, acc 1\n","2019-04-04T22:37:11.169720: step 29420, loss 2.83498, acc 1\n","2019-04-04T22:37:13.627773: step 29430, loss 2.82369, acc 1\n","2019-04-04T22:37:16.030484: step 29440, loss 2.8282, acc 1\n","2019-04-04T22:37:18.512942: step 29450, loss 2.8212, acc 1\n","2019-04-04T22:37:21.084846: step 29460, loss 2.82027, acc 1\n","2019-04-04T22:37:23.449766: step 29470, loss 2.8228, acc 1\n","2019-04-04T22:37:25.923347: step 29480, loss 2.82136, acc 1\n","2019-04-04T22:37:28.358554: step 29490, loss 2.82109, acc 1\n","2019-04-04T22:37:30.767656: step 29500, loss 2.81809, acc 1\n","\n","Evaluation:\n","2019-04-04T22:37:40.860538: step 29500, loss 5.0835, acc 0.787305\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.55%, Best = 83.96%\n","\n","2019-04-04T22:37:43.277953: step 29510, loss 2.81856, acc 1\n","2019-04-04T22:37:45.510063: step 29520, loss 2.82355, acc 1\n","2019-04-04T22:37:47.825215: step 29530, loss 2.82001, acc 1\n","2019-04-04T22:37:50.245855: step 29540, loss 2.81648, acc 1\n","2019-04-04T22:37:52.510000: step 29550, loss 2.82099, acc 1\n","2019-04-04T22:37:54.926979: step 29560, loss 2.82843, acc 1\n","2019-04-04T22:37:57.322525: step 29570, loss 2.82315, acc 1\n","2019-04-04T22:37:59.675703: step 29580, loss 2.8139, acc 1\n","2019-04-04T22:38:02.096481: step 29590, loss 2.81332, acc 1\n","2019-04-04T22:38:04.378245: step 29600, loss 2.82219, acc 1\n","\n","Evaluation:\n","2019-04-04T22:38:14.450058: step 29600, loss 5.27314, acc 0.79282\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.03%, Best = 83.96%\n","\n","2019-04-04T22:38:17.183612: step 29610, loss 2.81552, acc 1\n","2019-04-04T22:38:19.508628: step 29620, loss 2.81259, acc 1\n","2019-04-04T22:38:21.944681: step 29630, loss 2.81262, acc 1\n","2019-04-04T22:38:24.405661: step 29640, loss 2.85276, acc 1\n","2019-04-04T22:38:26.684445: step 29650, loss 2.82405, acc 1\n","2019-04-04T22:38:29.116240: step 29660, loss 2.81662, acc 1\n","2019-04-04T22:38:31.272443: step 29670, loss 2.81464, acc 1\n","2019-04-04T22:38:33.585166: step 29680, loss 2.81443, acc 1\n","2019-04-04T22:38:35.968973: step 29690, loss 2.80767, acc 1\n","2019-04-04T22:38:38.303408: step 29700, loss 2.81067, acc 1\n","\n","Evaluation:\n","2019-04-04T22:38:48.347539: step 29700, loss 5.08994, acc 0.788408\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.51%, Best = 83.96%\n","\n","2019-04-04T22:38:51.022033: step 29710, loss 2.81062, acc 1\n","2019-04-04T22:38:53.505881: step 29720, loss 2.81214, acc 1\n","2019-04-04T22:38:55.884356: step 29730, loss 2.80692, acc 1\n","2019-04-04T22:38:58.183843: step 29740, loss 2.80643, acc 1\n","2019-04-04T22:39:00.612701: step 29750, loss 2.80609, acc 1\n","2019-04-04T22:39:02.912755: step 29760, loss 2.80743, acc 1\n","2019-04-04T22:39:05.235419: step 29770, loss 2.83034, acc 1\n","2019-04-04T22:39:07.736635: step 29780, loss 2.8026, acc 1\n","2019-04-04T22:39:10.032830: step 29790, loss 2.80329, acc 1\n","2019-04-04T22:39:12.594303: step 29800, loss 2.8082, acc 1\n","\n","Evaluation:\n","2019-04-04T22:39:22.656663: step 29800, loss 5.25093, acc 0.792085\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.01%, Best = 83.96%\n","\n","2019-04-04T22:39:25.079230: step 29810, loss 2.8035, acc 1\n","2019-04-04T22:39:27.393396: step 29820, loss 2.80047, acc 1\n","2019-04-04T22:39:29.808935: step 29830, loss 2.80055, acc 1\n","2019-04-04T22:39:32.160544: step 29840, loss 2.80096, acc 1\n","2019-04-04T22:39:34.478725: step 29850, loss 2.79954, acc 1\n","2019-04-04T22:39:36.804394: step 29860, loss 2.79887, acc 1\n","2019-04-04T22:39:39.209619: step 29870, loss 2.80106, acc 1\n","2019-04-04T22:39:41.439461: step 29880, loss 2.79946, acc 1\n","2019-04-04T22:39:43.815223: step 29890, loss 2.79727, acc 1\n","2019-04-04T22:39:46.112341: step 29900, loss 2.82875, acc 1\n","\n","Evaluation:\n","2019-04-04T22:39:56.194825: step 29900, loss 5.38769, acc 0.786873\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.61%, Best = 83.96%\n","\n","2019-04-04T22:39:58.630360: step 29910, loss 2.79615, acc 1\n","2019-04-04T22:40:01.100205: step 29920, loss 2.80638, acc 1\n","2019-04-04T22:40:03.429580: step 29930, loss 2.82607, acc 1\n","2019-04-04T22:40:05.638227: step 29940, loss 2.79471, acc 1\n","2019-04-04T22:40:07.895713: step 29950, loss 2.92154, acc 0.95\n","2019-04-04T22:40:10.341276: step 29960, loss 2.79288, acc 1\n","2019-04-04T22:40:12.792793: step 29970, loss 2.80414, acc 1\n","2019-04-04T22:40:15.170221: step 29980, loss 2.79372, acc 1\n","2019-04-04T22:40:17.419113: step 29990, loss 2.79246, acc 1\n","2019-04-04T22:40:19.754499: step 30000, loss 2.79096, acc 1\n","\n","Evaluation:\n","2019-04-04T22:40:29.834292: step 30000, loss 5.48307, acc 0.789511\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.62%, Best = 83.96%\n","\n","2019-04-04T22:40:32.208137: step 30010, loss 2.79058, acc 1\n","2019-04-04T22:40:34.684597: step 30020, loss 2.79797, acc 1\n","2019-04-04T22:40:36.875248: step 30030, loss 2.78941, acc 1\n","2019-04-04T22:40:39.230763: step 30040, loss 2.81932, acc 1\n","2019-04-04T22:40:41.856298: step 30050, loss 2.78927, acc 1\n","2019-04-04T22:40:44.133734: step 30060, loss 2.78811, acc 1\n","2019-04-04T22:40:46.567946: step 30070, loss 2.78726, acc 1\n","2019-04-04T22:40:48.788912: step 30080, loss 2.78693, acc 1\n","2019-04-04T22:40:50.949752: step 30090, loss 2.78769, acc 1\n","2019-04-04T22:40:53.244762: step 30100, loss 2.78908, acc 1\n","\n","Evaluation:\n","2019-04-04T22:41:03.325514: step 30100, loss 5.53458, acc 0.788776\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.57%, Best = 83.96%\n","\n","2019-04-04T22:41:05.898401: step 30110, loss 2.84001, acc 0.95\n","2019-04-04T22:41:08.242979: step 30120, loss 2.81299, acc 1\n","2019-04-04T22:41:10.517386: step 30130, loss 2.7859, acc 1\n","2019-04-04T22:41:12.849025: step 30140, loss 2.7838, acc 1\n","2019-04-04T22:41:15.121916: step 30150, loss 2.78976, acc 1\n","2019-04-04T22:41:17.594693: step 30160, loss 2.78518, acc 1\n","2019-04-04T22:41:19.896723: step 30170, loss 3.17931, acc 0.95\n","2019-04-04T22:41:22.221897: step 30180, loss 2.78286, acc 1\n","2019-04-04T22:41:24.621086: step 30190, loss 2.98467, acc 0.95\n","2019-04-04T22:41:26.962270: step 30200, loss 2.78883, acc 1\n","\n","Evaluation:\n","2019-04-04T22:41:37.035145: step 30200, loss 5.54805, acc 0.786938\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.22%, Best = 83.96%\n","\n","2019-04-04T22:41:39.371460: step 30210, loss 2.78132, acc 1\n","2019-04-04T22:41:41.763744: step 30220, loss 2.78113, acc 1\n","2019-04-04T22:41:44.316941: step 30230, loss 2.80634, acc 1\n","2019-04-04T22:41:46.570818: step 30240, loss 2.85857, acc 0.95\n","2019-04-04T22:41:49.038138: step 30250, loss 2.77721, acc 1\n","2019-04-04T22:41:51.253934: step 30260, loss 2.77665, acc 1\n","2019-04-04T22:41:53.788509: step 30270, loss 2.78182, acc 1\n","2019-04-04T22:41:56.197236: step 30280, loss 2.78, acc 1\n","2019-04-04T22:41:58.514796: step 30290, loss 2.78779, acc 1\n","2019-04-04T22:42:00.856254: step 30300, loss 2.80253, acc 1\n","\n","Evaluation:\n","2019-04-04T22:42:10.969780: step 30300, loss 5.43134, acc 0.787305\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.3%, Best = 83.96%\n","\n","2019-04-04T22:42:13.485637: step 30310, loss 2.77772, acc 1\n","2019-04-04T22:42:15.770410: step 30320, loss 2.77417, acc 1\n","2019-04-04T22:42:18.389828: step 30330, loss 2.77292, acc 1\n","2019-04-04T22:42:20.923135: step 30340, loss 2.77291, acc 1\n","2019-04-04T22:42:23.283985: step 30350, loss 2.77405, acc 1\n","2019-04-04T22:42:25.812231: step 30360, loss 2.77645, acc 1\n","2019-04-04T22:42:28.246764: step 30370, loss 2.77208, acc 1\n","2019-04-04T22:42:30.533120: step 30380, loss 2.77031, acc 1\n","2019-04-04T22:42:32.866764: step 30390, loss 2.78203, acc 1\n","2019-04-04T22:42:35.219574: step 30400, loss 2.80205, acc 1\n","\n","Evaluation:\n","2019-04-04T22:42:45.307441: step 30400, loss 5.56439, acc 0.790917\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.72%, Best = 83.96%\n","\n","2019-04-04T22:42:47.649622: step 30410, loss 2.77098, acc 1\n","2019-04-04T22:42:50.048759: step 30420, loss 2.87667, acc 0.95\n","2019-04-04T22:42:52.268336: step 30430, loss 2.77096, acc 1\n","2019-04-04T22:42:54.581481: step 30440, loss 2.76853, acc 1\n","2019-04-04T22:42:57.046900: step 30450, loss 2.77162, acc 1\n","2019-04-04T22:42:59.405675: step 30460, loss 2.76895, acc 1\n","2019-04-04T22:43:01.739436: step 30470, loss 2.77026, acc 1\n","2019-04-04T22:43:04.123249: step 30480, loss 2.7662, acc 1\n","2019-04-04T22:43:06.346302: step 30490, loss 2.76431, acc 1\n","2019-04-04T22:43:08.737254: step 30500, loss 2.76623, acc 1\n","\n","Evaluation:\n","2019-04-04T22:43:18.806880: step 30500, loss 5.51958, acc 0.787608\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.38%, Best = 83.96%\n","\n","2019-04-04T22:43:21.234926: step 30510, loss 2.76868, acc 1\n","2019-04-04T22:43:23.738658: step 30520, loss 2.77021, acc 1\n","2019-04-04T22:43:25.916488: step 30530, loss 2.77631, acc 1\n","2019-04-04T22:43:28.274403: step 30540, loss 2.76441, acc 1\n","2019-04-04T22:43:30.547722: step 30550, loss 2.76416, acc 1\n","2019-04-04T22:43:33.046978: step 30560, loss 2.76047, acc 1\n","2019-04-04T22:43:35.580725: step 30570, loss 2.76073, acc 1\n","2019-04-04T22:43:38.018942: step 30580, loss 2.78168, acc 1\n","2019-04-04T22:43:40.318108: step 30590, loss 2.76231, acc 1\n","2019-04-04T22:43:42.834455: step 30600, loss 2.78513, acc 1\n","\n","Evaluation:\n","2019-04-04T22:43:52.928997: step 30600, loss 5.87359, acc 0.787543\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.5%, Best = 83.96%\n","\n","2019-04-04T22:43:55.548982: step 30610, loss 2.77432, acc 1\n","2019-04-04T22:43:57.806834: step 30620, loss 2.75957, acc 1\n","2019-04-04T22:44:00.317670: step 30630, loss 2.77674, acc 1\n","2019-04-04T22:44:02.941565: step 30640, loss 2.75947, acc 1\n","2019-04-04T22:44:05.422441: step 30650, loss 2.75652, acc 1\n","2019-04-04T22:44:07.761346: step 30660, loss 2.79381, acc 0.95\n","2019-04-04T22:44:10.007479: step 30670, loss 2.75896, acc 1\n","2019-04-04T22:44:12.324202: step 30680, loss 2.7951, acc 0.95\n","2019-04-04T22:44:14.622024: step 30690, loss 2.75795, acc 1\n","2019-04-04T22:44:16.986101: step 30700, loss 2.75392, acc 1\n","\n","Evaluation:\n","2019-04-04T22:44:27.073317: step 30700, loss 5.51097, acc 0.783867\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.19%, Best = 83.96%\n","\n","2019-04-04T22:44:29.502454: step 30710, loss 2.7525, acc 1\n","2019-04-04T22:44:31.820192: step 30720, loss 2.75382, acc 1\n","2019-04-04T22:44:34.285419: step 30730, loss 2.75367, acc 1\n","2019-04-04T22:44:36.699941: step 30740, loss 2.86861, acc 0.95\n","2019-04-04T22:44:38.952426: step 30750, loss 2.75993, acc 1\n","2019-04-04T22:44:41.249586: step 30760, loss 2.93834, acc 0.95\n","2019-04-04T22:44:43.729311: step 30770, loss 2.74979, acc 1\n","2019-04-04T22:44:45.949691: step 30780, loss 2.74897, acc 1\n","2019-04-04T22:44:48.179043: step 30790, loss 2.7495, acc 1\n","2019-04-04T22:44:50.553774: step 30800, loss 2.74852, acc 1\n","\n","Evaluation:\n","2019-04-04T22:45:00.642877: step 30800, loss 5.52241, acc 0.788711\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.69%, Best = 83.96%\n","\n","2019-04-04T22:45:03.094041: step 30810, loss 2.75476, acc 1\n","2019-04-04T22:45:05.464221: step 30820, loss 2.75223, acc 1\n","2019-04-04T22:45:08.041711: step 30830, loss 2.74647, acc 1\n","2019-04-04T22:45:10.342448: step 30840, loss 2.74924, acc 1\n","2019-04-04T22:45:12.651373: step 30850, loss 2.75104, acc 1\n","2019-04-04T22:45:15.251060: step 30860, loss 2.7448, acc 1\n","2019-04-04T22:45:17.643524: step 30870, loss 2.74476, acc 1\n","2019-04-04T22:45:20.266309: step 30880, loss 2.74805, acc 1\n","2019-04-04T22:45:22.584665: step 30890, loss 2.74661, acc 1\n","2019-04-04T22:45:24.819989: step 30900, loss 2.74345, acc 1\n","\n","Evaluation:\n","2019-04-04T22:45:34.821746: step 30900, loss 5.377, acc 0.796432\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.16%, Best = 83.96%\n","\n","2019-04-04T22:45:37.107442: step 30910, loss 2.7431, acc 1\n","2019-04-04T22:45:39.639842: step 30920, loss 2.75013, acc 1\n","2019-04-04T22:45:42.158308: step 30930, loss 2.74173, acc 1\n","2019-04-04T22:45:44.800923: step 30940, loss 2.92949, acc 0.95\n","2019-04-04T22:45:47.243047: step 30950, loss 2.74333, acc 1\n","2019-04-04T22:45:49.586352: step 30960, loss 2.73946, acc 1\n","2019-04-04T22:45:52.031966: step 30970, loss 2.74198, acc 1\n","2019-04-04T22:45:54.325556: step 30980, loss 2.7508, acc 1\n","2019-04-04T22:45:56.629595: step 30990, loss 2.73975, acc 1\n","2019-04-04T22:45:58.842443: step 31000, loss 2.73749, acc 1\n","\n","Evaluation:\n","2019-04-04T22:46:08.935872: step 31000, loss 5.58804, acc 0.793858\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.13%, Best = 83.96%\n","\n","2019-04-04T22:46:11.232627: step 31010, loss 2.78905, acc 0.95\n","2019-04-04T22:46:13.541369: step 31020, loss 2.73611, acc 1\n","2019-04-04T22:46:15.985966: step 31030, loss 2.96241, acc 0.95\n","2019-04-04T22:46:18.560324: step 31040, loss 2.81592, acc 0.95\n","2019-04-04T22:46:21.193928: step 31050, loss 2.73765, acc 1\n","2019-04-04T22:46:23.559619: step 31060, loss 2.73974, acc 1\n","2019-04-04T22:46:25.806952: step 31070, loss 2.7616, acc 1\n","2019-04-04T22:46:28.171527: step 31080, loss 2.739, acc 1\n","2019-04-04T22:46:30.495724: step 31090, loss 2.75532, acc 1\n","2019-04-04T22:46:32.859441: step 31100, loss 2.98566, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:46:42.957897: step 31100, loss 5.50723, acc 0.784234\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.15%, Best = 83.96%\n","\n","2019-04-04T22:46:45.283738: step 31110, loss 2.73278, acc 1\n","2019-04-04T22:46:47.595348: step 31120, loss 2.73075, acc 1\n","2019-04-04T22:46:49.965109: step 31130, loss 2.73028, acc 1\n","2019-04-04T22:46:52.337412: step 31140, loss 2.79282, acc 0.95\n","2019-04-04T22:46:54.809472: step 31150, loss 2.72914, acc 1\n","2019-04-04T22:46:57.045036: step 31160, loss 2.72888, acc 1\n","2019-04-04T22:46:59.379145: step 31170, loss 2.74045, acc 1\n","2019-04-04T22:47:01.548922: step 31180, loss 2.72754, acc 1\n","2019-04-04T22:47:03.961117: step 31190, loss 2.72843, acc 1\n","2019-04-04T22:47:06.320630: step 31200, loss 2.81511, acc 0.95\n","\n","Evaluation:\n","2019-04-04T22:47:16.470128: step 31200, loss 5.54129, acc 0.786505\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.43%, Best = 83.96%\n","\n","2019-04-04T22:47:19.111799: step 31210, loss 2.75233, acc 1\n","2019-04-04T22:47:21.634792: step 31220, loss 2.72875, acc 1\n","2019-04-04T22:47:23.985753: step 31230, loss 2.72482, acc 1\n","2019-04-04T22:47:26.308356: step 31240, loss 2.72497, acc 1\n","2019-04-04T22:47:28.767331: step 31250, loss 2.78991, acc 0.95\n","2019-04-04T22:47:31.205551: step 31260, loss 2.78847, acc 0.95\n","2019-04-04T22:47:33.574598: step 31270, loss 2.72881, acc 1\n","2019-04-04T22:47:36.041228: step 31280, loss 2.72321, acc 1\n","2019-04-04T22:47:38.454483: step 31290, loss 2.72384, acc 1\n","2019-04-04T22:47:40.923901: step 31300, loss 2.74221, acc 1\n","\n","Evaluation:\n","2019-04-04T22:47:50.994030: step 31300, loss 5.66539, acc 0.789381\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.58%, Best = 83.96%\n","\n","2019-04-04T22:47:53.273926: step 31310, loss 2.82431, acc 0.95\n","2019-04-04T22:47:55.500105: step 31320, loss 2.72077, acc 1\n","2019-04-04T22:47:57.734242: step 31330, loss 2.72477, acc 1\n","2019-04-04T22:47:59.973652: step 31340, loss 2.7195, acc 1\n","2019-04-04T22:48:02.311980: step 31350, loss 2.72856, acc 1\n","2019-04-04T22:48:04.539260: step 31360, loss 2.71843, acc 1\n","2019-04-04T22:48:06.992445: step 31370, loss 2.71764, acc 1\n","2019-04-04T22:48:09.387386: step 31380, loss 2.7224, acc 1\n","2019-04-04T22:48:11.726460: step 31390, loss 2.73342, acc 1\n","2019-04-04T22:48:14.221385: step 31400, loss 2.72223, acc 1\n","\n","Evaluation:\n","2019-04-04T22:48:24.264451: step 31400, loss 5.47983, acc 0.787543\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 82.6%, Best = 83.96%\n","\n","2019-04-04T22:48:26.668401: step 31410, loss 2.71589, acc 1\n","2019-04-04T22:48:29.038363: step 31420, loss 2.75329, acc 1\n","2019-04-04T22:48:31.400353: step 31430, loss 2.72116, acc 1\n","2019-04-04T22:48:33.788957: step 31440, loss 2.71429, acc 1\n","2019-04-04T22:48:36.153902: step 31450, loss 2.73814, acc 1\n","2019-04-04T22:48:38.507116: step 31460, loss 2.71851, acc 1\n","2019-04-04T22:48:40.959964: step 31470, loss 2.71218, acc 1\n","2019-04-04T22:48:43.257799: step 31480, loss 2.71416, acc 1\n","2019-04-04T22:48:45.684662: step 31490, loss 2.7117, acc 1\n","2019-04-04T22:48:48.146698: step 31500, loss 2.7107, acc 1\n","\n","Evaluation:\n","2019-04-04T22:48:58.192466: step 31500, loss 5.23648, acc 0.797967\n","<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:\n","macro-averaged F1-score = 83.43%, Best = 83.96%\n","\n","2019-04-04T22:49:00.508429: step 31510, loss 2.71017, acc 1\n","2019-04-04T22:49:02.843230: step 31520, loss 2.71892, acc 1\n","2019-04-04T22:49:05.098749: step 31530, loss 2.71176, acc 1\n","2019-04-04T22:49:07.445477: step 31540, loss 2.71061, acc 1\n","2019-04-04T22:49:09.757188: step 31550, loss 2.71691, acc 1\n","2019-04-04T22:49:12.022182: step 31560, loss 2.70761, acc 1\n","2019-04-04T22:49:14.389358: step 31570, loss 2.70755, acc 1\n","2019-04-04T22:49:16.741018: step 31580, loss 2.71115, acc 1\n","2019-04-04T22:49:18.960054: step 31590, loss 2.70955, acc 1\n"],"name":"stdout"}]},{"metadata":{"id":"6cWbVQ-OnGt-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}