{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextCNN_Relational_Extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xchen35/Experienment_on_Relation_Extration/blob/master/TextCNN_Relational_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZAfoJ9zxx6t5",
        "colab_type": "code",
        "outputId": "85510199-bb8b-40b7-8062-51e9346b5a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZK2hC8O4Nov",
        "colab_type": "code",
        "outputId": "c9b78a46-41cd-4f05-efdf-3c0979d4aff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import subprocess\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "NHGRYhugBb5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQEC9JZp4bh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class2label = {'Other': 0,\n",
        "               'Message-Topic(e1,e2)': 1, 'Message-Topic(e2,e1)': 2,\n",
        "               'Product-Producer(e1,e2)': 3, 'Product-Producer(e2,e1)': 4,\n",
        "               'Instrument-Agency(e1,e2)': 5, 'Instrument-Agency(e2,e1)': 6,\n",
        "               'Entity-Destination(e1,e2)': 7, 'Entity-Destination(e2,e1)': 8,\n",
        "               'Cause-Effect(e1,e2)': 9, 'Cause-Effect(e2,e1)': 10,\n",
        "               'Component-Whole(e1,e2)': 11, 'Component-Whole(e2,e1)': 12,\n",
        "               'Entity-Origin(e1,e2)': 13, 'Entity-Origin(e2,e1)': 14,\n",
        "               'Member-Collection(e1,e2)': 15, 'Member-Collection(e2,e1)': 16,\n",
        "               'Content-Container(e1,e2)': 17, 'Content-Container(e2,e1)': 18}\n",
        "\n",
        "label2class = {0: 'Other',\n",
        "               1: 'Message-Topic(e1,e2)', 2: 'Message-Topic(e2,e1)',\n",
        "               3: 'Product-Producer(e1,e2)', 4: 'Product-Producer(e2,e1)',\n",
        "               5: 'Instrument-Agency(e1,e2)', 6: 'Instrument-Agency(e2,e1)',\n",
        "               7: 'Entity-Desatination(e1,e2)', 8: 'Entity-Destination(e2,e1)',\n",
        "               9: 'Cause-Effect(e1,e2)', 10: 'Cause-Effect(e2,e1)',\n",
        "               11: 'Component-Whole(e1,e2)', 12: 'Component-Whole(e2,e1)',\n",
        "               13: 'Entity-Origin(e1,e2)', 14: 'Entity-Origin(e2,e1)',\n",
        "               15: 'Member-Collection(e1,e2)', 16: 'Member-Collection(e2,e1)',\n",
        "               17: 'Content-Container(e1,e2)', 18: 'Content-Container(e2,e1)'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZUhLLNfh4hfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_word2vec(embedding_path, embedding_dim, vocab):\n",
        "    # initial matrix with random uniform\n",
        "    initW = np.random.randn(len(vocab.vocabulary_), embedding_dim).astype(np.float32) / np.sqrt(len(vocab.vocabulary_))\n",
        "    # load any vectors from the word2vec\n",
        "    print(\"Load word2vec file {0}\".format(embedding_path))\n",
        "    with open(embedding_path, \"rb\") as f:\n",
        "        header = f.readline()\n",
        "        vocab_size, layer_size = map(int, header.split())\n",
        "        binary_len = np.dtype('float32').itemsize * layer_size\n",
        "        for line in range(vocab_size):\n",
        "            word = []\n",
        "            while True:\n",
        "                ch = f.read(1).decode('latin-1')\n",
        "                if ch == ' ':\n",
        "                    word = ''.join(word)\n",
        "                    break\n",
        "                if ch != '\\n':\n",
        "                    word.append(ch)\n",
        "            idx = vocab.vocabulary_.get(word)\n",
        "            if idx != 0:\n",
        "                initW[idx] = np.fromstring(f.read(binary_len), dtype='float32')\n",
        "            else:\n",
        "                f.read(binary_len)\n",
        "    return initW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OtJm6jC34xKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_str(text):\n",
        "    text = text.lower()\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"that's\", \"that is \", text)\n",
        "    text = re.sub(r\"there's\", \"there is \", text)\n",
        "    text = re.sub(r\"it's\", \"it is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    return text.strip()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJfpmJME4z5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data_and_labels(path):\n",
        "    data = []\n",
        "    lines = [line.strip() for line in open(path)]\n",
        "    max_sentence_length = 0\n",
        "    for idx in range(0, len(lines), 4):\n",
        "        id = lines[idx].split(\"\\t\")[0]\n",
        "        relation = lines[idx + 1]\n",
        "\n",
        "        sentence = lines[idx].split(\"\\t\")[1][1:-1]\n",
        "        sentence = sentence.replace('<e1>', ' _e11_ ')\n",
        "        sentence = sentence.replace('</e1>', ' _e12_ ')\n",
        "        sentence = sentence.replace('<e2>', ' _e21_ ')\n",
        "        sentence = sentence.replace('</e2>', ' _e22_ ')\n",
        "\n",
        "        sentence = clean_str(sentence)\n",
        "        tokens = nltk.word_tokenize(sentence)\n",
        "        if max_sentence_length < len(tokens):\n",
        "            max_sentence_length = len(tokens)\n",
        "        e1 = tokens.index(\"e12\") - 1\n",
        "        e2 = tokens.index(\"e22\") - 1\n",
        "        sentence = \" \".join(tokens)\n",
        "\n",
        "        data.append([id, sentence, e1, e2, relation])\n",
        "\n",
        "    print(path)\n",
        "    print(\"max sentence length = {}\\n\".format(max_sentence_length))\n",
        "\n",
        "    df = pd.DataFrame(data=data, columns=[\"id\", \"sentence\", \"e1\", \"e2\", \"relation\"])\n",
        "\n",
        "    pos1, pos2 = get_relative_position(df, 90)\n",
        "\n",
        "    df['label'] = [class2label[r] for r in df['relation']]\n",
        "\n",
        "    # Text Data\n",
        "    x_text = df['sentence'].tolist()\n",
        "\n",
        "    # Label Data\n",
        "    y = df['label']\n",
        "    labels_flat = y.values.ravel()\n",
        "    labels_count = np.unique(labels_flat).shape[0]\n",
        "\n",
        "    # convert class labels from scalars to one-hot vectors\n",
        "    # 0  => [1 0 0 0 0 ... 0 0 0 0 0]\n",
        "    # 1  => [0 1 0 0 0 ... 0 0 0 0 0]\n",
        "    # ...\n",
        "    # 18 => [0 0 0 0 0 ... 0 0 0 0 1]\n",
        "    def dense_to_one_hot(labels_dense, num_classes):\n",
        "        num_labels = labels_dense.shape[0]\n",
        "        index_offset = np.arange(num_labels) * num_classes\n",
        "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
        "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
        "        return labels_one_hot\n",
        "\n",
        "    labels = dense_to_one_hot(labels_flat, labels_count)\n",
        "    labels = labels.astype(np.uint8)\n",
        "\n",
        "    return x_text, labels, pos1, pos2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lD7vJMuD42Bp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_relative_position(df, max_sentence_length):\n",
        "    # Position data\n",
        "    pos1 = []\n",
        "    pos2 = []\n",
        "    for df_idx in range(len(df)):\n",
        "        sentence = df.iloc[df_idx]['sentence']\n",
        "        tokens = nltk.word_tokenize(sentence)\n",
        "        e1 = df.iloc[df_idx]['e1']\n",
        "        e2 = df.iloc[df_idx]['e2']\n",
        "\n",
        "        p1 = \"\"\n",
        "        p2 = \"\"\n",
        "        for word_idx in range(len(tokens)):\n",
        "            p1 += str((max_sentence_length - 1) + word_idx - e1) + \" \"\n",
        "            p2 += str((max_sentence_length - 1) + word_idx - e2) + \" \"\n",
        "        pos1.append(p1)\n",
        "        pos2.append(p2)\n",
        "\n",
        "    return pos1, pos2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nn1tGWVz4k1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
        "    \"\"\"\n",
        "    Generates a batch iterator for a dataset.\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    data_size = len(data)\n",
        "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
        "    for epoch in range(num_epochs):\n",
        "        # Shuffle the data at each epoch\n",
        "        if shuffle:\n",
        "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "            shuffled_data = data[shuffle_indices]\n",
        "        else:\n",
        "            shuffled_data = data\n",
        "        for batch_num in range(num_batches_per_epoch):\n",
        "            start_index = batch_num * batch_size\n",
        "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
        "            yield shuffled_data[start_index:end_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1j-56VY4sIx",
        "colab_type": "code",
        "outputId": "784d0086-3dd3-4431-b090-f101bda26d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "trainFile = '/content/drive/My Drive/SemEval2010_task8_all_data/SemEval2010_task8_training/TRAIN_FILE.TXT'\n",
        "testFile = '/content/drive/My Drive/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT'\n",
        "\n",
        "x_text, y, pos1, pos2 = load_data_and_labels(testFile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/SemEval2010_task8_all_data/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT\n",
            "max sentence length = 68\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-2CxSZUZIu5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Develop TextCNN model**"
      ]
    },
    {
      "metadata": {
        "id": "nMwk4eoh5c2L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TextCNN:\n",
        "    def __init__(self, sequence_length, num_classes,\n",
        "                 text_vocab_size, text_embedding_size, pos_vocab_size, pos_embedding_size,\n",
        "                 filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
        "\n",
        "        # Placeholders for input, output and dropout\n",
        "        self.input_text = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_text')\n",
        "        self.input_p1 = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_p1')\n",
        "        self.input_p2 = tf.placeholder(tf.int32, shape=[None, sequence_length], name='input_p2')\n",
        "        self.input_y = tf.placeholder(tf.float32, shape=[None, num_classes], name='input_y')\n",
        "        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n",
        "\n",
        "        initializer = tf.keras.initializers.glorot_normal\n",
        "\n",
        "        # Embedding layer\n",
        "        with tf.variable_scope(\"text-embedding\"):\n",
        "            self.W_text = tf.Variable(tf.random_uniform([text_vocab_size, text_embedding_size], -0.25, 0.25), name=\"W_text\")\n",
        "            self.text_embedded_chars = tf.nn.embedding_lookup(self.W_text, self.input_text)\n",
        "            self.text_embedded_chars_expanded = tf.expand_dims(self.text_embedded_chars, -1)\n",
        "\n",
        "        with tf.variable_scope(\"position-embedding\"):\n",
        "            self.W_pos = tf.get_variable(\"W_pos\", [pos_vocab_size, pos_embedding_size], initializer=initializer())\n",
        "            self.p1_embedded_chars = tf.nn.embedding_lookup(self.W_pos, self.input_p1)\n",
        "            self.p2_embedded_chars = tf.nn.embedding_lookup(self.W_pos, self.input_p2)\n",
        "            self.p1_embedded_chars_expanded = tf.expand_dims(self.p1_embedded_chars, -1)\n",
        "            self.p2_embedded_chars_expanded = tf.expand_dims(self.p2_embedded_chars, -1)\n",
        "\n",
        "        self.embedded_chars_expanded = tf.concat([self.text_embedded_chars_expanded,\n",
        "                                                  self.p1_embedded_chars_expanded,\n",
        "                                                  self.p2_embedded_chars_expanded], 2)\n",
        "        _embedding_size = text_embedding_size + 2*pos_embedding_size\n",
        "\n",
        "        # Create a convolution + maxpool layer for each filter size\n",
        "        pooled_outputs = []\n",
        "        for i, filter_size in enumerate(filter_sizes):\n",
        "            with tf.variable_scope(\"conv-maxpool-%s\" % filter_size):\n",
        "                # Convolution Layer\n",
        "                conv = tf.layers.conv2d(self.embedded_chars_expanded, num_filters, [filter_size, _embedding_size],\n",
        "                                        kernel_initializer=initializer(), activation=tf.nn.relu, name=\"conv\")\n",
        "                # Maxpooling over the outputs\n",
        "                pooled = tf.nn.max_pool(conv, ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
        "                                        strides=[1, 1, 1, 1], padding='VALID', name=\"pool\")\n",
        "                pooled_outputs.append(pooled)\n",
        "\n",
        "        # Combine all the pooled features\n",
        "        num_filters_total = num_filters * len(filter_sizes)\n",
        "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
        "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
        "\n",
        "        # Add dropout\n",
        "        with tf.variable_scope(\"dropout\"):\n",
        "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
        "\n",
        "        # Final scores and predictions\n",
        "        with tf.variable_scope(\"output\"):\n",
        "            self.logits = tf.layers.dense(self.h_drop, num_classes, kernel_initializer=initializer())\n",
        "            self.predictions = tf.argmax(self.logits, 1, name=\"predictions\")\n",
        "\n",
        "        # Calculate mean cross-entropy loss\n",
        "        with tf.variable_scope(\"loss\"):\n",
        "            losses = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.input_y)\n",
        "            self.l2 = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
        "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * self.l2\n",
        "\n",
        "        # Accuracy\n",
        "        with tf.name_scope(\"accuracy\"):\n",
        "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
        "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B93yJufE6xdb",
        "colab_type": "code",
        "outputId": "1b05f56a-210f-4a57-aa40-baf5ab7ddeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        " # Build vocabulary\n",
        "text_vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(90)\n",
        "x = np.array(list(text_vocab_processor.fit_transform(x_text)))\n",
        "print(\"Text Vocabulary Size: {:d}\".format(len(text_vocab_processor.vocabulary_)))\n",
        "print(\"x = {0}\".format(x.shape))\n",
        "print(\"y = {0}\".format(y.shape))\n",
        "print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Vocabulary Size: 10470\n",
            "x = (2717, 90)\n",
            "y = (2717, 19)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UjPMrsHz-52u",
        "colab_type": "code",
        "outputId": "18d9bf24-6fac-4832-d8be-2f34b9d77d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        " # Build vocabulary\n",
        "pos_vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(90)\n",
        "pos_vocab_processor.fit(pos1 + pos2)\n",
        "p1 = np.array(list(pos_vocab_processor.transform(pos1)))\n",
        "p2 = np.array(list(pos_vocab_processor.transform(pos2)))\n",
        "print(\"Position Vocabulary Size: {:d}\".format(len(pos_vocab_processor.vocabulary_)))\n",
        "print(\"position_1 = {0}\".format(p1.shape))\n",
        "print(\"position_2 = {0}\".format(p2.shape))\n",
        "print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Position Vocabulary Size: 121\n",
            "position_1 = (2717, 90)\n",
            "position_2 = (2717, 90)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GPqY5h8E-9sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Randomly shuffle data to split into train and test(dev)\n",
        "np.random.seed(10)\n",
        "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
        "x_shuffled = x[shuffle_indices]\n",
        "p1_shuffled = p1[shuffle_indices]\n",
        "p2_shuffled = p2[shuffle_indices]\n",
        "y_shuffled = y[shuffle_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPKF0nkI_D8H",
        "colab_type": "code",
        "outputId": "afd78b7f-fa47-42f0-9aaa-bc8fa9b3bda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Split train/test set\n",
        "dev_sample_index = -1 * int(0.1 * float(len(y)))\n",
        "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
        "p1_train, p1_dev = p1_shuffled[:dev_sample_index], p1_shuffled[dev_sample_index:]\n",
        "p2_train, p2_dev = p2_shuffled[:dev_sample_index], p2_shuffled[dev_sample_index:]\n",
        "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
        "print(\"Train/Dev split: {:d}/{:d}\\n\".format(len(y_train), len(y_dev)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train/Dev split: 2446/271\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXmUXmCBJF6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build Model**"
      ]
    },
    {
      "metadata": {
        "id": "glJEElmt_Ria",
        "colab_type": "code",
        "outputId": "713629c5-062c-49cb-c6df-c3428c7f1ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32014
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Graph().as_default():\n",
        "    session_conf = tf.ConfigProto(\n",
        "        allow_soft_placement=True,\n",
        "        log_device_placement=False)\n",
        "    session_conf.gpu_options.allow_growth = True\n",
        "    sess = tf.Session(config=session_conf)\n",
        "    with sess.as_default():\n",
        "        cnn = TextCNN(\n",
        "            sequence_length=x_train.shape[1],\n",
        "            num_classes=y_train.shape[1],\n",
        "            text_vocab_size=len(text_vocab_processor.vocabulary_),\n",
        "            text_embedding_size=300,\n",
        "            pos_vocab_size=len(pos_vocab_processor.vocabulary_),\n",
        "            pos_embedding_size=50,\n",
        "            filter_sizes=list(map(int, \"2,3,4,5\".split(\",\"))),\n",
        "            num_filters=128,\n",
        "            l2_reg_lambda=1e-5)\n",
        "\n",
        "        # Define Training procedure\n",
        "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
        "        optimizer = tf.train.AdadeltaOptimizer(1.0, 0.9, 1e-6)\n",
        "        gvs = optimizer.compute_gradients(cnn.loss)\n",
        "        capped_gvs = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in gvs]\n",
        "        train_op = optimizer.apply_gradients(capped_gvs, global_step=global_step)\n",
        "\n",
        "        # Output directory for models and summaries\n",
        "        timestamp = str(int(time.time()))\n",
        "        out_dir = os.path.abspath(os.path.join(\"drive/My Drive\", \"runs\", timestamp))\n",
        "        print(\"Writing to {}\\n\".format(out_dir))\n",
        "\n",
        "        # Summaries for loss and accuracy\n",
        "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
        "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
        "\n",
        "        # Train Summaries\n",
        "        train_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
        "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
        "\n",
        "        # Dev summaries\n",
        "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
        "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
        "\n",
        "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
        "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
        "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
        "\n",
        "        # Write vocabulary\n",
        "        text_vocab_processor.save(os.path.join(out_dir, \"text_vocab\"))\n",
        "        pos_vocab_processor.save(os.path.join(out_dir, \"pos_vocab\"))\n",
        "\n",
        "        # Initialize all variables\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Pre-trained word2vec\n",
        "        if None:\n",
        "            pretrain_W = utils.load_word2vec(None, 300, text_vocab_processor)\n",
        "            sess.run(cnn.W_text.assign(pretrain_W))\n",
        "            print(\"Success to load pre-trained word2vec model!\\n\")\n",
        "\n",
        "        # Generate batches\n",
        "        batches = batch_iter(list(zip(x_train, p1_train, p2_train, y_train)),\n",
        "                                          20, 100)\n",
        "        # Training loop. For each batch...\n",
        "        best_f1 = 0.0  # For save checkpoint(model)\n",
        "        for batch in batches:\n",
        "            x_batch, p1_batch, p2_batch, y_batch = zip(*batch)\n",
        "            # Train\n",
        "            feed_dict = {\n",
        "                cnn.input_text: x_batch,\n",
        "                cnn.input_p1: p1_batch,\n",
        "                cnn.input_p2: p2_batch,\n",
        "                cnn.input_y: y_batch,\n",
        "                cnn.dropout_keep_prob: 0.5\n",
        "            }\n",
        "            _, step, summaries, loss, accuracy = sess.run(\n",
        "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy], feed_dict)\n",
        "            train_summary_writer.add_summary(summaries, step)\n",
        "\n",
        "            # Training log display\n",
        "            if step % 10 == 0:\n",
        "                time_str = datetime.datetime.now().isoformat()\n",
        "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
        "\n",
        "            # Evaluation\n",
        "            if step % 100 == 0:\n",
        "                print(\"\\nEvaluation:\")\n",
        "                feed_dict = {\n",
        "                    cnn.input_text: x_dev,\n",
        "                    cnn.input_p1: p1_dev,\n",
        "                    cnn.input_p2: p2_dev,\n",
        "                    cnn.input_y: y_dev,\n",
        "                    cnn.dropout_keep_prob: 1.0\n",
        "                }\n",
        "                summaries, loss, accuracy, predictions = sess.run(\n",
        "                    [dev_summary_op, cnn.loss, cnn.accuracy, cnn.predictions], feed_dict)\n",
        "                dev_summary_writer.add_summary(summaries, step)\n",
        "\n",
        "                time_str = datetime.datetime.now().isoformat()\n",
        "                f1 = f1_score(np.argmax(y_dev, axis=1), predictions, labels=np.array(range(1, 19)), average=\"macro\")\n",
        "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
        "                print(\"[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): {:g}\\n\".format(f1))\n",
        "\n",
        "                # Model checkpoint\n",
        "                if best_f1 < f1:\n",
        "                    best_f1 = f1\n",
        "                    path = saver.save(sess, checkpoint_prefix + \"-{:.3g}\".format(best_f1), global_step=step)\n",
        "                    print(\"Saved model checkpoint to {}\\n\".format(path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to /content/drive/My Drive/runs/1554407997\n",
            "\n",
            "2019-04-04T19:59:58.513649: step 10, loss 3.03723, acc 0.25\n",
            "2019-04-04T19:59:58.736299: step 20, loss 2.506, acc 0.4\n",
            "2019-04-04T19:59:58.934491: step 30, loss 1.90786, acc 0.6\n",
            "2019-04-04T19:59:59.125092: step 40, loss 2.3436, acc 0.45\n",
            "2019-04-04T19:59:59.309128: step 50, loss 2.18892, acc 0.4\n",
            "2019-04-04T19:59:59.498203: step 60, loss 3.07166, acc 0.25\n",
            "2019-04-04T19:59:59.683537: step 70, loss 2.12132, acc 0.3\n",
            "2019-04-04T19:59:59.872661: step 80, loss 2.45624, acc 0.25\n",
            "2019-04-04T20:00:00.062702: step 90, loss 2.08163, acc 0.45\n",
            "2019-04-04T20:00:00.244896: step 100, loss 2.17, acc 0.45\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:00.325883: step 100, loss 2.00576, acc 0.527675\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.404361\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.404-100\n",
            "\n",
            "2019-04-04T20:00:00.766424: step 110, loss 2.10452, acc 0.45\n",
            "2019-04-04T20:00:00.950391: step 120, loss 1.44472, acc 0.6\n",
            "2019-04-04T20:00:01.130336: step 130, loss 1.68129, acc 0.6\n",
            "2019-04-04T20:00:01.318766: step 140, loss 1.91809, acc 0.5\n",
            "2019-04-04T20:00:01.503113: step 150, loss 1.74221, acc 0.55\n",
            "2019-04-04T20:00:01.692868: step 160, loss 1.71685, acc 0.65\n",
            "2019-04-04T20:00:01.883766: step 170, loss 1.99708, acc 0.25\n",
            "2019-04-04T20:00:02.071765: step 180, loss 1.63917, acc 0.55\n",
            "2019-04-04T20:00:02.258363: step 190, loss 1.67851, acc 0.55\n",
            "2019-04-04T20:00:02.448223: step 200, loss 1.41328, acc 0.6\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:02.479971: step 200, loss 1.7244, acc 0.560886\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.438528\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.439-200\n",
            "\n",
            "2019-04-04T20:00:02.943339: step 210, loss 1.20927, acc 0.75\n",
            "2019-04-04T20:00:03.129069: step 220, loss 1.54993, acc 0.6\n",
            "2019-04-04T20:00:03.314994: step 230, loss 1.58974, acc 0.6\n",
            "2019-04-04T20:00:03.502866: step 240, loss 2.05703, acc 0.55\n",
            "2019-04-04T20:00:03.682528: step 250, loss 1.45682, acc 0.65\n",
            "2019-04-04T20:00:03.874490: step 260, loss 1.12955, acc 0.75\n",
            "2019-04-04T20:00:04.059822: step 270, loss 1.27132, acc 0.6\n",
            "2019-04-04T20:00:04.247076: step 280, loss 1.18634, acc 0.75\n",
            "2019-04-04T20:00:04.432924: step 290, loss 1.38371, acc 0.7\n",
            "2019-04-04T20:00:04.625372: step 300, loss 1.23454, acc 0.75\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:04.656971: step 300, loss 1.65495, acc 0.594096\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.44736\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.447-300\n",
            "\n",
            "2019-04-04T20:00:05.064211: step 310, loss 1.42853, acc 0.7\n",
            "2019-04-04T20:00:05.256602: step 320, loss 1.66813, acc 0.45\n",
            "2019-04-04T20:00:05.442340: step 330, loss 1.36118, acc 0.6\n",
            "2019-04-04T20:00:05.629582: step 340, loss 1.31461, acc 0.65\n",
            "2019-04-04T20:00:05.814254: step 350, loss 1.9065, acc 0.65\n",
            "2019-04-04T20:00:06.007741: step 360, loss 0.874152, acc 0.75\n",
            "2019-04-04T20:00:06.186884: step 370, loss 0.668395, acc 0.85\n",
            "2019-04-04T20:00:06.374488: step 380, loss 0.886824, acc 0.85\n",
            "2019-04-04T20:00:06.559186: step 390, loss 0.674018, acc 0.95\n",
            "2019-04-04T20:00:06.748143: step 400, loss 1.00559, acc 0.75\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:06.779938: step 400, loss 1.57928, acc 0.634686\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.540651\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.541-400\n",
            "\n",
            "2019-04-04T20:00:07.191492: step 410, loss 0.677513, acc 0.95\n",
            "2019-04-04T20:00:07.381273: step 420, loss 1.09961, acc 0.8\n",
            "2019-04-04T20:00:07.570544: step 430, loss 1.06359, acc 0.7\n",
            "2019-04-04T20:00:07.766614: step 440, loss 0.747019, acc 0.9\n",
            "2019-04-04T20:00:07.971761: step 450, loss 0.876899, acc 0.8\n",
            "2019-04-04T20:00:08.230058: step 460, loss 1.17986, acc 0.75\n",
            "2019-04-04T20:00:08.431841: step 470, loss 0.824697, acc 0.8\n",
            "2019-04-04T20:00:08.625421: step 480, loss 1.02514, acc 0.75\n",
            "2019-04-04T20:00:08.814121: step 490, loss 1.0205, acc 0.8\n",
            "2019-04-04T20:00:08.997817: step 500, loss 0.602281, acc 0.95\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:09.029713: step 500, loss 1.56905, acc 0.627306\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.501316\n",
            "\n",
            "2019-04-04T20:00:09.218986: step 510, loss 0.708909, acc 0.8\n",
            "2019-04-04T20:00:09.406614: step 520, loss 0.645194, acc 0.9\n",
            "2019-04-04T20:00:09.596659: step 530, loss 0.449044, acc 1\n",
            "2019-04-04T20:00:09.782290: step 540, loss 0.665141, acc 0.85\n",
            "2019-04-04T20:00:09.976998: step 550, loss 1.41241, acc 0.75\n",
            "2019-04-04T20:00:10.173910: step 560, loss 0.715876, acc 0.9\n",
            "2019-04-04T20:00:10.361231: step 570, loss 0.622436, acc 0.85\n",
            "2019-04-04T20:00:10.546537: step 580, loss 0.710501, acc 0.9\n",
            "2019-04-04T20:00:10.745305: step 590, loss 0.540692, acc 0.95\n",
            "2019-04-04T20:00:10.932704: step 600, loss 0.445868, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:10.963889: step 600, loss 1.55318, acc 0.638376\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.52956\n",
            "\n",
            "2019-04-04T20:00:11.149226: step 610, loss 0.508803, acc 1\n",
            "2019-04-04T20:00:11.337798: step 620, loss 0.405971, acc 1\n",
            "2019-04-04T20:00:11.522735: step 630, loss 0.394721, acc 1\n",
            "2019-04-04T20:00:11.721442: step 640, loss 0.580571, acc 0.85\n",
            "2019-04-04T20:00:11.908337: step 650, loss 0.576876, acc 1\n",
            "2019-04-04T20:00:12.101211: step 660, loss 0.549124, acc 0.95\n",
            "2019-04-04T20:00:12.285774: step 670, loss 0.422578, acc 1\n",
            "2019-04-04T20:00:12.475143: step 680, loss 0.538377, acc 0.95\n",
            "2019-04-04T20:00:12.661081: step 690, loss 0.469837, acc 1\n",
            "2019-04-04T20:00:12.853487: step 700, loss 0.408269, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:12.885080: step 700, loss 1.54868, acc 0.642066\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.531663\n",
            "\n",
            "2019-04-04T20:00:13.084404: step 710, loss 0.489853, acc 1\n",
            "2019-04-04T20:00:13.289918: step 720, loss 0.415793, acc 1\n",
            "2019-04-04T20:00:13.482891: step 730, loss 0.413279, acc 1\n",
            "2019-04-04T20:00:13.663768: step 740, loss 0.441158, acc 0.95\n",
            "2019-04-04T20:00:13.848322: step 750, loss 0.394634, acc 1\n",
            "2019-04-04T20:00:14.036598: step 760, loss 0.405133, acc 1\n",
            "2019-04-04T20:00:14.224736: step 770, loss 0.456183, acc 0.95\n",
            "2019-04-04T20:00:14.410911: step 780, loss 0.402044, acc 1\n",
            "2019-04-04T20:00:14.595879: step 790, loss 0.35211, acc 1\n",
            "2019-04-04T20:00:14.784234: step 800, loss 0.452376, acc 0.95\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:14.816049: step 800, loss 1.58889, acc 0.645756\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.537594\n",
            "\n",
            "2019-04-04T20:00:15.004462: step 810, loss 0.43553, acc 1\n",
            "2019-04-04T20:00:15.192727: step 820, loss 0.475853, acc 0.95\n",
            "2019-04-04T20:00:15.379161: step 830, loss 0.389593, acc 1\n",
            "2019-04-04T20:00:15.562321: step 840, loss 0.414843, acc 1\n",
            "2019-04-04T20:00:15.750532: step 850, loss 0.455049, acc 1\n",
            "2019-04-04T20:00:15.935298: step 860, loss 0.61406, acc 0.9\n",
            "2019-04-04T20:00:16.117246: step 870, loss 0.358149, acc 1\n",
            "2019-04-04T20:00:16.305148: step 880, loss 0.463057, acc 0.95\n",
            "2019-04-04T20:00:16.490234: step 890, loss 0.366938, acc 1\n",
            "2019-04-04T20:00:16.676077: step 900, loss 0.455096, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:16.707875: step 900, loss 1.66214, acc 0.627306\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.514055\n",
            "\n",
            "2019-04-04T20:00:16.898136: step 910, loss 0.384912, acc 1\n",
            "2019-04-04T20:00:17.083198: step 920, loss 0.399413, acc 0.95\n",
            "2019-04-04T20:00:17.270051: step 930, loss 0.349351, acc 1\n",
            "2019-04-04T20:00:17.455804: step 940, loss 0.352708, acc 1\n",
            "2019-04-04T20:00:17.640377: step 950, loss 0.383342, acc 1\n",
            "2019-04-04T20:00:17.834708: step 960, loss 0.373423, acc 1\n",
            "2019-04-04T20:00:18.020599: step 970, loss 0.36557, acc 1\n",
            "2019-04-04T20:00:18.211461: step 980, loss 0.362995, acc 1\n",
            "2019-04-04T20:00:18.391852: step 990, loss 0.377804, acc 1\n",
            "2019-04-04T20:00:18.578068: step 1000, loss 0.369395, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:18.609218: step 1000, loss 1.65802, acc 0.656827\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.532581\n",
            "\n",
            "2019-04-04T20:00:18.798632: step 1010, loss 0.343945, acc 1\n",
            "2019-04-04T20:00:18.985206: step 1020, loss 0.355648, acc 1\n",
            "2019-04-04T20:00:19.174783: step 1030, loss 0.365248, acc 1\n",
            "2019-04-04T20:00:19.359357: step 1040, loss 0.356172, acc 1\n",
            "2019-04-04T20:00:19.548558: step 1050, loss 0.388227, acc 1\n",
            "2019-04-04T20:00:19.733200: step 1060, loss 0.360932, acc 1\n",
            "2019-04-04T20:00:19.923633: step 1070, loss 0.363284, acc 1\n",
            "2019-04-04T20:00:20.114587: step 1080, loss 0.37925, acc 1\n",
            "2019-04-04T20:00:20.301063: step 1090, loss 0.351428, acc 1\n",
            "2019-04-04T20:00:20.484169: step 1100, loss 0.381029, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:20.525095: step 1100, loss 1.63191, acc 0.664207\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.543854\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.544-1100\n",
            "\n",
            "2019-04-04T20:00:20.930096: step 1110, loss 0.372108, acc 1\n",
            "2019-04-04T20:00:21.117276: step 1120, loss 0.332615, acc 1\n",
            "2019-04-04T20:00:21.305726: step 1130, loss 0.346398, acc 1\n",
            "2019-04-04T20:00:21.490412: step 1140, loss 0.348045, acc 1\n",
            "2019-04-04T20:00:21.677472: step 1150, loss 0.340463, acc 1\n",
            "2019-04-04T20:00:21.864208: step 1160, loss 0.335564, acc 1\n",
            "2019-04-04T20:00:22.048826: step 1170, loss 0.348101, acc 1\n",
            "2019-04-04T20:00:22.237800: step 1180, loss 0.348992, acc 1\n",
            "2019-04-04T20:00:22.426245: step 1190, loss 0.340484, acc 1\n",
            "2019-04-04T20:00:22.613902: step 1200, loss 0.367991, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:22.645566: step 1200, loss 1.62177, acc 0.667897\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.543669\n",
            "\n",
            "2019-04-04T20:00:22.836913: step 1210, loss 0.339462, acc 1\n",
            "2019-04-04T20:00:23.022893: step 1220, loss 0.401023, acc 0.95\n",
            "2019-04-04T20:00:23.204959: step 1230, loss 0.35714, acc 1\n",
            "2019-04-04T20:00:23.395423: step 1240, loss 0.343277, acc 1\n",
            "2019-04-04T20:00:23.580318: step 1250, loss 0.334272, acc 1\n",
            "2019-04-04T20:00:23.767083: step 1260, loss 0.342343, acc 1\n",
            "2019-04-04T20:00:23.953821: step 1270, loss 0.339537, acc 1\n",
            "2019-04-04T20:00:24.137610: step 1280, loss 0.407069, acc 0.95\n",
            "2019-04-04T20:00:24.325799: step 1290, loss 0.336147, acc 1\n",
            "2019-04-04T20:00:24.515901: step 1300, loss 0.347316, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:24.547230: step 1300, loss 1.66679, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.571151\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.571-1300\n",
            "\n",
            "2019-04-04T20:00:24.972830: step 1310, loss 0.335361, acc 1\n",
            "2019-04-04T20:00:25.160977: step 1320, loss 0.347104, acc 1\n",
            "2019-04-04T20:00:25.346701: step 1330, loss 0.333167, acc 1\n",
            "2019-04-04T20:00:25.536932: step 1340, loss 0.351993, acc 1\n",
            "2019-04-04T20:00:25.722535: step 1350, loss 0.349867, acc 1\n",
            "2019-04-04T20:00:25.906595: step 1360, loss 0.348386, acc 1\n",
            "2019-04-04T20:00:26.090588: step 1370, loss 0.340933, acc 1\n",
            "2019-04-04T20:00:26.281652: step 1380, loss 0.355809, acc 1\n",
            "2019-04-04T20:00:26.471830: step 1390, loss 0.331662, acc 1\n",
            "2019-04-04T20:00:26.656302: step 1400, loss 0.345695, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:26.688371: step 1400, loss 1.71181, acc 0.664207\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.572409\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.572-1400\n",
            "\n",
            "2019-04-04T20:00:27.159822: step 1410, loss 0.33933, acc 1\n",
            "2019-04-04T20:00:27.344179: step 1420, loss 0.333413, acc 1\n",
            "2019-04-04T20:00:27.528207: step 1430, loss 0.350522, acc 1\n",
            "2019-04-04T20:00:27.716318: step 1440, loss 0.352354, acc 1\n",
            "2019-04-04T20:00:27.897142: step 1450, loss 0.336343, acc 1\n",
            "2019-04-04T20:00:28.080215: step 1460, loss 0.338181, acc 1\n",
            "2019-04-04T20:00:28.261127: step 1470, loss 0.362694, acc 1\n",
            "2019-04-04T20:00:28.440327: step 1480, loss 0.330894, acc 1\n",
            "2019-04-04T20:00:28.622778: step 1490, loss 0.332198, acc 1\n",
            "2019-04-04T20:00:28.817703: step 1500, loss 0.334464, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:28.850912: step 1500, loss 1.67451, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.548098\n",
            "\n",
            "2019-04-04T20:00:29.042041: step 1510, loss 0.332386, acc 1\n",
            "2019-04-04T20:00:29.229229: step 1520, loss 0.335838, acc 1\n",
            "2019-04-04T20:00:29.417124: step 1530, loss 0.33321, acc 1\n",
            "2019-04-04T20:00:29.607423: step 1540, loss 0.332043, acc 1\n",
            "2019-04-04T20:00:29.791391: step 1550, loss 0.360696, acc 1\n",
            "2019-04-04T20:00:29.975968: step 1560, loss 0.33161, acc 1\n",
            "2019-04-04T20:00:30.163668: step 1570, loss 0.337301, acc 1\n",
            "2019-04-04T20:00:30.351534: step 1580, loss 0.335813, acc 1\n",
            "2019-04-04T20:00:30.536844: step 1590, loss 0.342815, acc 1\n",
            "2019-04-04T20:00:30.719181: step 1600, loss 0.33279, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:30.750892: step 1600, loss 1.66591, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.57151\n",
            "\n",
            "2019-04-04T20:00:30.937168: step 1610, loss 0.3357, acc 1\n",
            "2019-04-04T20:00:31.124516: step 1620, loss 0.335156, acc 1\n",
            "2019-04-04T20:00:31.309013: step 1630, loss 0.386644, acc 1\n",
            "2019-04-04T20:00:31.497306: step 1640, loss 0.378808, acc 0.95\n",
            "2019-04-04T20:00:31.685971: step 1650, loss 0.33135, acc 1\n",
            "2019-04-04T20:00:31.873459: step 1660, loss 0.339908, acc 1\n",
            "2019-04-04T20:00:32.063751: step 1670, loss 0.334923, acc 1\n",
            "2019-04-04T20:00:32.252155: step 1680, loss 0.353857, acc 1\n",
            "2019-04-04T20:00:32.443905: step 1690, loss 0.334927, acc 1\n",
            "2019-04-04T20:00:32.638840: step 1700, loss 0.3424, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:32.670658: step 1700, loss 1.7196, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.573763\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.574-1700\n",
            "\n",
            "2019-04-04T20:00:33.134188: step 1710, loss 0.32873, acc 1\n",
            "2019-04-04T20:00:33.320334: step 1720, loss 0.332348, acc 1\n",
            "2019-04-04T20:00:33.499015: step 1730, loss 0.330581, acc 1\n",
            "2019-04-04T20:00:33.691154: step 1740, loss 0.337284, acc 1\n",
            "2019-04-04T20:00:33.883743: step 1750, loss 0.335344, acc 1\n",
            "2019-04-04T20:00:34.075541: step 1760, loss 0.33155, acc 1\n",
            "2019-04-04T20:00:34.260629: step 1770, loss 0.347926, acc 1\n",
            "2019-04-04T20:00:34.449247: step 1780, loss 0.33008, acc 1\n",
            "2019-04-04T20:00:34.637271: step 1790, loss 0.331997, acc 1\n",
            "2019-04-04T20:00:34.823913: step 1800, loss 0.33359, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:34.855506: step 1800, loss 1.68923, acc 0.667897\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.570954\n",
            "\n",
            "2019-04-04T20:00:35.038856: step 1810, loss 0.337636, acc 1\n",
            "2019-04-04T20:00:35.224373: step 1820, loss 0.360183, acc 1\n",
            "2019-04-04T20:00:35.408066: step 1830, loss 0.330267, acc 1\n",
            "2019-04-04T20:00:35.588036: step 1840, loss 0.330819, acc 1\n",
            "2019-04-04T20:00:35.773016: step 1850, loss 0.335862, acc 1\n",
            "2019-04-04T20:00:35.955016: step 1860, loss 0.350776, acc 1\n",
            "2019-04-04T20:00:36.143198: step 1870, loss 0.331084, acc 1\n",
            "2019-04-04T20:00:36.324437: step 1880, loss 0.33022, acc 1\n",
            "2019-04-04T20:00:36.507240: step 1890, loss 0.329418, acc 1\n",
            "2019-04-04T20:00:36.690382: step 1900, loss 0.33468, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:36.723161: step 1900, loss 1.71179, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.563145\n",
            "\n",
            "2019-04-04T20:00:36.909925: step 1910, loss 0.330689, acc 1\n",
            "2019-04-04T20:00:37.099093: step 1920, loss 0.331349, acc 1\n",
            "2019-04-04T20:00:37.299073: step 1930, loss 0.342769, acc 1\n",
            "2019-04-04T20:00:37.492336: step 1940, loss 0.342196, acc 1\n",
            "2019-04-04T20:00:37.676293: step 1950, loss 0.328374, acc 1\n",
            "2019-04-04T20:00:37.874721: step 1960, loss 0.341945, acc 1\n",
            "2019-04-04T20:00:38.050576: step 1970, loss 0.329222, acc 1\n",
            "2019-04-04T20:00:38.242841: step 1980, loss 0.333591, acc 1\n",
            "2019-04-04T20:00:38.427289: step 1990, loss 0.330278, acc 1\n",
            "2019-04-04T20:00:38.614716: step 2000, loss 0.33293, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:38.648086: step 2000, loss 1.67906, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.573908\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.574-2000\n",
            "\n",
            "2019-04-04T20:00:39.116015: step 2010, loss 0.329895, acc 1\n",
            "2019-04-04T20:00:39.303945: step 2020, loss 0.332008, acc 1\n",
            "2019-04-04T20:00:39.490330: step 2030, loss 0.330889, acc 1\n",
            "2019-04-04T20:00:39.677855: step 2040, loss 0.332693, acc 1\n",
            "2019-04-04T20:00:39.863419: step 2050, loss 0.329383, acc 1\n",
            "2019-04-04T20:00:40.046170: step 2060, loss 0.333423, acc 1\n",
            "2019-04-04T20:00:40.227112: step 2070, loss 0.336282, acc 1\n",
            "2019-04-04T20:00:40.409721: step 2080, loss 0.331405, acc 1\n",
            "2019-04-04T20:00:40.591255: step 2090, loss 0.325964, acc 1\n",
            "2019-04-04T20:00:40.765190: step 2100, loss 0.329209, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:40.798209: step 2100, loss 1.75589, acc 0.660517\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.575854\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.576-2100\n",
            "\n",
            "2019-04-04T20:00:41.227243: step 2110, loss 0.329045, acc 1\n",
            "2019-04-04T20:00:41.416652: step 2120, loss 0.331697, acc 1\n",
            "2019-04-04T20:00:41.601289: step 2130, loss 0.32779, acc 1\n",
            "2019-04-04T20:00:41.788338: step 2140, loss 0.331807, acc 1\n",
            "2019-04-04T20:00:41.983666: step 2150, loss 0.325788, acc 1\n",
            "2019-04-04T20:00:42.168462: step 2160, loss 0.326349, acc 1\n",
            "2019-04-04T20:00:42.353081: step 2170, loss 0.326716, acc 1\n",
            "2019-04-04T20:00:42.567068: step 2180, loss 0.329326, acc 1\n",
            "2019-04-04T20:00:42.753619: step 2190, loss 0.32722, acc 1\n",
            "2019-04-04T20:00:42.941790: step 2200, loss 0.328723, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:42.974053: step 2200, loss 1.74198, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.591337\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.591-2200\n",
            "\n",
            "2019-04-04T20:00:43.465391: step 2210, loss 0.32943, acc 1\n",
            "2019-04-04T20:00:43.643632: step 2220, loss 0.345793, acc 1\n",
            "2019-04-04T20:00:43.828691: step 2230, loss 0.325773, acc 1\n",
            "2019-04-04T20:00:44.022339: step 2240, loss 0.328412, acc 1\n",
            "2019-04-04T20:00:44.206250: step 2250, loss 0.327063, acc 1\n",
            "2019-04-04T20:00:44.393970: step 2260, loss 0.329937, acc 1\n",
            "2019-04-04T20:00:44.578626: step 2270, loss 0.330612, acc 1\n",
            "2019-04-04T20:00:44.766246: step 2280, loss 0.328464, acc 1\n",
            "2019-04-04T20:00:44.952261: step 2290, loss 0.324433, acc 1\n",
            "2019-04-04T20:00:45.139374: step 2300, loss 0.334055, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:45.171337: step 2300, loss 1.7516, acc 0.664207\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.543662\n",
            "\n",
            "2019-04-04T20:00:45.359803: step 2310, loss 0.331865, acc 1\n",
            "2019-04-04T20:00:45.544549: step 2320, loss 0.326027, acc 1\n",
            "2019-04-04T20:00:45.733314: step 2330, loss 0.326329, acc 1\n",
            "2019-04-04T20:00:45.914315: step 2340, loss 0.328015, acc 1\n",
            "2019-04-04T20:00:46.105623: step 2350, loss 0.327005, acc 1\n",
            "2019-04-04T20:00:46.292547: step 2360, loss 0.329961, acc 1\n",
            "2019-04-04T20:00:46.481143: step 2370, loss 0.325749, acc 1\n",
            "2019-04-04T20:00:46.665808: step 2380, loss 0.341241, acc 1\n",
            "2019-04-04T20:00:46.854322: step 2390, loss 0.325016, acc 1\n",
            "2019-04-04T20:00:47.041658: step 2400, loss 0.325385, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:47.073352: step 2400, loss 1.78007, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.593657\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.594-2400\n",
            "\n",
            "2019-04-04T20:00:47.503313: step 2410, loss 0.323203, acc 1\n",
            "2019-04-04T20:00:47.692634: step 2420, loss 0.323658, acc 1\n",
            "2019-04-04T20:00:47.879515: step 2430, loss 0.326084, acc 1\n",
            "2019-04-04T20:00:48.072992: step 2440, loss 0.479585, acc 0.95\n",
            "2019-04-04T20:00:48.269384: step 2450, loss 0.328167, acc 1\n",
            "2019-04-04T20:00:48.454119: step 2460, loss 0.328627, acc 1\n",
            "2019-04-04T20:00:48.661613: step 2470, loss 0.326594, acc 1\n",
            "2019-04-04T20:00:48.856719: step 2480, loss 0.325397, acc 1\n",
            "2019-04-04T20:00:49.050359: step 2490, loss 0.342107, acc 1\n",
            "2019-04-04T20:00:49.235141: step 2500, loss 0.323607, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:49.266801: step 2500, loss 1.73244, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.579477\n",
            "\n",
            "2019-04-04T20:00:49.449346: step 2510, loss 0.326933, acc 1\n",
            "2019-04-04T20:00:49.632655: step 2520, loss 0.323829, acc 1\n",
            "2019-04-04T20:00:49.822647: step 2530, loss 0.327914, acc 1\n",
            "2019-04-04T20:00:50.010069: step 2540, loss 0.330998, acc 1\n",
            "2019-04-04T20:00:50.191918: step 2550, loss 0.335496, acc 1\n",
            "2019-04-04T20:00:50.379160: step 2560, loss 0.325556, acc 1\n",
            "2019-04-04T20:00:50.565463: step 2570, loss 0.328192, acc 1\n",
            "2019-04-04T20:00:50.750620: step 2580, loss 0.323255, acc 1\n",
            "2019-04-04T20:00:50.931423: step 2590, loss 0.323214, acc 1\n",
            "2019-04-04T20:00:51.131435: step 2600, loss 0.325874, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:51.164101: step 2600, loss 1.75809, acc 0.664207\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.541903\n",
            "\n",
            "2019-04-04T20:00:51.359398: step 2610, loss 0.323953, acc 1\n",
            "2019-04-04T20:00:51.543876: step 2620, loss 0.323618, acc 1\n",
            "2019-04-04T20:00:51.730526: step 2630, loss 0.324649, acc 1\n",
            "2019-04-04T20:00:51.917891: step 2640, loss 0.322561, acc 1\n",
            "2019-04-04T20:00:52.106397: step 2650, loss 0.335069, acc 1\n",
            "2019-04-04T20:00:52.292538: step 2660, loss 0.324328, acc 1\n",
            "2019-04-04T20:00:52.482134: step 2670, loss 0.327714, acc 1\n",
            "2019-04-04T20:00:52.663510: step 2680, loss 0.323516, acc 1\n",
            "2019-04-04T20:00:52.851411: step 2690, loss 0.322575, acc 1\n",
            "2019-04-04T20:00:53.037963: step 2700, loss 0.323881, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:53.069199: step 2700, loss 1.7698, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.562657\n",
            "\n",
            "2019-04-04T20:00:53.252817: step 2710, loss 0.323618, acc 1\n",
            "2019-04-04T20:00:53.439660: step 2720, loss 0.324771, acc 1\n",
            "2019-04-04T20:00:53.623568: step 2730, loss 0.325226, acc 1\n",
            "2019-04-04T20:00:53.821395: step 2740, loss 0.32278, acc 1\n",
            "2019-04-04T20:00:54.002742: step 2750, loss 0.323928, acc 1\n",
            "2019-04-04T20:00:54.190217: step 2760, loss 0.322785, acc 1\n",
            "2019-04-04T20:00:54.369025: step 2770, loss 0.321874, acc 1\n",
            "2019-04-04T20:00:54.552281: step 2780, loss 0.321095, acc 1\n",
            "2019-04-04T20:00:54.734133: step 2790, loss 0.321464, acc 1\n",
            "2019-04-04T20:00:54.917720: step 2800, loss 0.332957, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:54.950513: step 2800, loss 1.76219, acc 0.660517\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.541238\n",
            "\n",
            "2019-04-04T20:00:55.139402: step 2810, loss 0.324183, acc 1\n",
            "2019-04-04T20:00:55.325659: step 2820, loss 0.324264, acc 1\n",
            "2019-04-04T20:00:55.506012: step 2830, loss 0.321155, acc 1\n",
            "2019-04-04T20:00:55.689191: step 2840, loss 0.321216, acc 1\n",
            "2019-04-04T20:00:55.877286: step 2850, loss 0.321342, acc 1\n",
            "2019-04-04T20:00:56.057534: step 2860, loss 0.323645, acc 1\n",
            "2019-04-04T20:00:56.243717: step 2870, loss 0.322405, acc 1\n",
            "2019-04-04T20:00:56.424357: step 2880, loss 0.32249, acc 1\n",
            "2019-04-04T20:00:56.612020: step 2890, loss 0.321638, acc 1\n",
            "2019-04-04T20:00:56.792529: step 2900, loss 0.321904, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:56.824451: step 2900, loss 1.80308, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.589816\n",
            "\n",
            "2019-04-04T20:00:57.012166: step 2910, loss 0.321321, acc 1\n",
            "2019-04-04T20:00:57.199128: step 2920, loss 0.322419, acc 1\n",
            "2019-04-04T20:00:57.385829: step 2930, loss 0.321248, acc 1\n",
            "2019-04-04T20:00:57.571449: step 2940, loss 0.324068, acc 1\n",
            "2019-04-04T20:00:57.755613: step 2950, loss 0.320333, acc 1\n",
            "2019-04-04T20:00:57.937315: step 2960, loss 0.320735, acc 1\n",
            "2019-04-04T20:00:58.122219: step 2970, loss 0.321301, acc 1\n",
            "2019-04-04T20:00:58.313210: step 2980, loss 0.333301, acc 1\n",
            "2019-04-04T20:00:58.497599: step 2990, loss 0.320424, acc 1\n",
            "2019-04-04T20:00:58.684324: step 3000, loss 0.325021, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:00:58.716580: step 3000, loss 1.77632, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.610315\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.61-3000\n",
            "\n",
            "2019-04-04T20:00:59.140469: step 3010, loss 0.321877, acc 1\n",
            "2019-04-04T20:00:59.328123: step 3020, loss 0.32059, acc 1\n",
            "2019-04-04T20:00:59.512706: step 3030, loss 0.323242, acc 1\n",
            "2019-04-04T20:00:59.702006: step 3040, loss 0.320928, acc 1\n",
            "2019-04-04T20:00:59.887262: step 3050, loss 0.322464, acc 1\n",
            "2019-04-04T20:01:00.075804: step 3060, loss 0.320065, acc 1\n",
            "2019-04-04T20:01:00.260866: step 3070, loss 0.320414, acc 1\n",
            "2019-04-04T20:01:00.448388: step 3080, loss 0.322055, acc 1\n",
            "2019-04-04T20:01:00.642567: step 3090, loss 0.32004, acc 1\n",
            "2019-04-04T20:01:00.827736: step 3100, loss 0.321424, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:00.859129: step 3100, loss 1.75674, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.579326\n",
            "\n",
            "2019-04-04T20:01:01.049507: step 3110, loss 0.320219, acc 1\n",
            "2019-04-04T20:01:01.234196: step 3120, loss 0.320394, acc 1\n",
            "2019-04-04T20:01:01.426284: step 3130, loss 0.319378, acc 1\n",
            "2019-04-04T20:01:01.610695: step 3140, loss 0.320769, acc 1\n",
            "2019-04-04T20:01:01.799514: step 3150, loss 0.322433, acc 1\n",
            "2019-04-04T20:01:01.984271: step 3160, loss 0.319386, acc 1\n",
            "2019-04-04T20:01:02.172907: step 3170, loss 0.319336, acc 1\n",
            "2019-04-04T20:01:02.360194: step 3180, loss 0.324815, acc 1\n",
            "2019-04-04T20:01:02.545304: step 3190, loss 0.319102, acc 1\n",
            "2019-04-04T20:01:02.722930: step 3200, loss 0.32021, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:02.755586: step 3200, loss 1.77482, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.574367\n",
            "\n",
            "2019-04-04T20:01:02.937625: step 3210, loss 0.318928, acc 1\n",
            "2019-04-04T20:01:03.123052: step 3220, loss 0.319169, acc 1\n",
            "2019-04-04T20:01:03.305141: step 3230, loss 0.318585, acc 1\n",
            "2019-04-04T20:01:03.491379: step 3240, loss 0.319464, acc 1\n",
            "2019-04-04T20:01:03.672413: step 3250, loss 0.340863, acc 1\n",
            "2019-04-04T20:01:03.860303: step 3260, loss 0.318881, acc 1\n",
            "2019-04-04T20:01:04.054953: step 3270, loss 0.319111, acc 1\n",
            "2019-04-04T20:01:04.249814: step 3280, loss 0.31931, acc 1\n",
            "2019-04-04T20:01:04.436439: step 3290, loss 0.322299, acc 1\n",
            "2019-04-04T20:01:04.623284: step 3300, loss 0.328641, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:04.655542: step 3300, loss 1.82911, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596684\n",
            "\n",
            "2019-04-04T20:01:04.842198: step 3310, loss 0.318071, acc 1\n",
            "2019-04-04T20:01:05.026126: step 3320, loss 0.317911, acc 1\n",
            "2019-04-04T20:01:05.207451: step 3330, loss 0.318338, acc 1\n",
            "2019-04-04T20:01:05.390713: step 3340, loss 0.317924, acc 1\n",
            "2019-04-04T20:01:05.577969: step 3350, loss 0.319076, acc 1\n",
            "2019-04-04T20:01:05.762648: step 3360, loss 0.321392, acc 1\n",
            "2019-04-04T20:01:05.950950: step 3370, loss 0.319511, acc 1\n",
            "2019-04-04T20:01:06.135928: step 3380, loss 0.31986, acc 1\n",
            "2019-04-04T20:01:06.324767: step 3390, loss 0.317896, acc 1\n",
            "2019-04-04T20:01:06.509278: step 3400, loss 0.318986, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:06.541267: step 3400, loss 1.80592, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.604112\n",
            "\n",
            "2019-04-04T20:01:06.725415: step 3410, loss 0.321754, acc 1\n",
            "2019-04-04T20:01:06.915054: step 3420, loss 0.322807, acc 1\n",
            "2019-04-04T20:01:07.100550: step 3430, loss 0.317209, acc 1\n",
            "2019-04-04T20:01:07.289064: step 3440, loss 0.317793, acc 1\n",
            "2019-04-04T20:01:07.468476: step 3450, loss 0.329008, acc 1\n",
            "2019-04-04T20:01:07.657507: step 3460, loss 0.31845, acc 1\n",
            "2019-04-04T20:01:07.843614: step 3470, loss 0.317353, acc 1\n",
            "2019-04-04T20:01:08.042712: step 3480, loss 0.319248, acc 1\n",
            "2019-04-04T20:01:08.228667: step 3490, loss 0.320522, acc 1\n",
            "2019-04-04T20:01:08.425480: step 3500, loss 0.320146, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:08.459436: step 3500, loss 1.82905, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.598636\n",
            "\n",
            "2019-04-04T20:01:08.666331: step 3510, loss 0.320527, acc 1\n",
            "2019-04-04T20:01:08.858735: step 3520, loss 0.317039, acc 1\n",
            "2019-04-04T20:01:09.046305: step 3530, loss 0.3186, acc 1\n",
            "2019-04-04T20:01:09.231334: step 3540, loss 0.317149, acc 1\n",
            "2019-04-04T20:01:09.424101: step 3550, loss 0.320189, acc 1\n",
            "2019-04-04T20:01:09.618538: step 3560, loss 0.316734, acc 1\n",
            "2019-04-04T20:01:09.800051: step 3570, loss 0.316852, acc 1\n",
            "2019-04-04T20:01:09.985436: step 3580, loss 0.320401, acc 1\n",
            "2019-04-04T20:01:10.173823: step 3590, loss 0.316748, acc 1\n",
            "2019-04-04T20:01:10.362095: step 3600, loss 0.316624, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:10.393607: step 3600, loss 1.81461, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.570175\n",
            "\n",
            "2019-04-04T20:01:10.580927: step 3610, loss 0.320219, acc 1\n",
            "2019-04-04T20:01:10.762870: step 3620, loss 0.317891, acc 1\n",
            "2019-04-04T20:01:10.956597: step 3630, loss 0.316834, acc 1\n",
            "2019-04-04T20:01:11.138711: step 3640, loss 0.316164, acc 1\n",
            "2019-04-04T20:01:11.318788: step 3650, loss 0.316373, acc 1\n",
            "2019-04-04T20:01:11.506609: step 3660, loss 0.317, acc 1\n",
            "2019-04-04T20:01:11.693465: step 3670, loss 0.316198, acc 1\n",
            "2019-04-04T20:01:11.880130: step 3680, loss 0.315864, acc 1\n",
            "2019-04-04T20:01:12.057570: step 3690, loss 0.316515, acc 1\n",
            "2019-04-04T20:01:12.247534: step 3700, loss 0.315804, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:12.278741: step 3700, loss 1.81543, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.598938\n",
            "\n",
            "2019-04-04T20:01:12.461333: step 3710, loss 0.316313, acc 1\n",
            "2019-04-04T20:01:12.643990: step 3720, loss 0.318084, acc 1\n",
            "2019-04-04T20:01:12.830105: step 3730, loss 0.316206, acc 1\n",
            "2019-04-04T20:01:13.012201: step 3740, loss 0.3162, acc 1\n",
            "2019-04-04T20:01:13.199246: step 3750, loss 0.31564, acc 1\n",
            "2019-04-04T20:01:13.379762: step 3760, loss 0.316401, acc 1\n",
            "2019-04-04T20:01:13.567182: step 3770, loss 0.318964, acc 1\n",
            "2019-04-04T20:01:13.750430: step 3780, loss 0.33129, acc 1\n",
            "2019-04-04T20:01:13.933181: step 3790, loss 0.315042, acc 1\n",
            "2019-04-04T20:01:14.114136: step 3800, loss 0.318703, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:14.146141: step 3800, loss 1.79882, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.5833\n",
            "\n",
            "2019-04-04T20:01:14.330869: step 3810, loss 0.316533, acc 1\n",
            "2019-04-04T20:01:14.514616: step 3820, loss 0.31689, acc 1\n",
            "2019-04-04T20:01:14.702946: step 3830, loss 0.315409, acc 1\n",
            "2019-04-04T20:01:14.890119: step 3840, loss 0.319495, acc 1\n",
            "2019-04-04T20:01:15.070473: step 3850, loss 0.316695, acc 1\n",
            "2019-04-04T20:01:15.251844: step 3860, loss 0.314796, acc 1\n",
            "2019-04-04T20:01:15.435552: step 3870, loss 0.315703, acc 1\n",
            "2019-04-04T20:01:15.627621: step 3880, loss 0.337579, acc 1\n",
            "2019-04-04T20:01:15.815525: step 3890, loss 0.315407, acc 1\n",
            "2019-04-04T20:01:16.006603: step 3900, loss 0.316126, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:16.038402: step 3900, loss 1.77584, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.574571\n",
            "\n",
            "2019-04-04T20:01:16.226974: step 3910, loss 0.314988, acc 1\n",
            "2019-04-04T20:01:16.407318: step 3920, loss 0.314558, acc 1\n",
            "2019-04-04T20:01:16.588571: step 3930, loss 0.314103, acc 1\n",
            "2019-04-04T20:01:16.772286: step 3940, loss 0.314336, acc 1\n",
            "2019-04-04T20:01:16.957832: step 3950, loss 0.314043, acc 1\n",
            "2019-04-04T20:01:17.137285: step 3960, loss 0.314137, acc 1\n",
            "2019-04-04T20:01:17.320434: step 3970, loss 0.316762, acc 1\n",
            "2019-04-04T20:01:17.503544: step 3980, loss 0.313946, acc 1\n",
            "2019-04-04T20:01:17.692112: step 3990, loss 0.314362, acc 1\n",
            "2019-04-04T20:01:17.873187: step 4000, loss 0.314048, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:17.904892: step 4000, loss 1.80327, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.561257\n",
            "\n",
            "2019-04-04T20:01:18.092693: step 4010, loss 0.313589, acc 1\n",
            "2019-04-04T20:01:18.280143: step 4020, loss 0.314958, acc 1\n",
            "2019-04-04T20:01:18.464561: step 4030, loss 0.318846, acc 1\n",
            "2019-04-04T20:01:18.655656: step 4040, loss 0.314767, acc 1\n",
            "2019-04-04T20:01:18.840894: step 4050, loss 0.315653, acc 1\n",
            "2019-04-04T20:01:19.025316: step 4060, loss 0.324647, acc 1\n",
            "2019-04-04T20:01:19.209088: step 4070, loss 0.316188, acc 1\n",
            "2019-04-04T20:01:19.397022: step 4080, loss 0.315009, acc 1\n",
            "2019-04-04T20:01:19.581615: step 4090, loss 0.313447, acc 1\n",
            "2019-04-04T20:01:19.774084: step 4100, loss 0.314583, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:19.806313: step 4100, loss 1.78699, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.574171\n",
            "\n",
            "2019-04-04T20:01:19.993125: step 4110, loss 0.314563, acc 1\n",
            "2019-04-04T20:01:20.181926: step 4120, loss 0.314973, acc 1\n",
            "2019-04-04T20:01:20.366299: step 4130, loss 0.312923, acc 1\n",
            "2019-04-04T20:01:20.551275: step 4140, loss 0.314325, acc 1\n",
            "2019-04-04T20:01:20.740014: step 4150, loss 0.313673, acc 1\n",
            "2019-04-04T20:01:20.926832: step 4160, loss 0.314904, acc 1\n",
            "2019-04-04T20:01:21.114728: step 4170, loss 0.314988, acc 1\n",
            "2019-04-04T20:01:21.298732: step 4180, loss 0.31437, acc 1\n",
            "2019-04-04T20:01:21.484691: step 4190, loss 0.3136, acc 1\n",
            "2019-04-04T20:01:21.667993: step 4200, loss 0.313274, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:21.699701: step 4200, loss 1.77525, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.582345\n",
            "\n",
            "2019-04-04T20:01:21.888553: step 4210, loss 0.313613, acc 1\n",
            "2019-04-04T20:01:22.073359: step 4220, loss 0.313945, acc 1\n",
            "2019-04-04T20:01:22.258840: step 4230, loss 0.312439, acc 1\n",
            "2019-04-04T20:01:22.446974: step 4240, loss 0.312488, acc 1\n",
            "2019-04-04T20:01:22.631536: step 4250, loss 0.313859, acc 1\n",
            "2019-04-04T20:01:22.821885: step 4260, loss 0.311999, acc 1\n",
            "2019-04-04T20:01:23.007771: step 4270, loss 0.313295, acc 1\n",
            "2019-04-04T20:01:23.198263: step 4280, loss 0.31376, acc 1\n",
            "2019-04-04T20:01:23.382872: step 4290, loss 0.312327, acc 1\n",
            "2019-04-04T20:01:23.572147: step 4300, loss 0.312352, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:23.603812: step 4300, loss 1.83121, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.582071\n",
            "\n",
            "2019-04-04T20:01:23.778925: step 4310, loss 0.312467, acc 1\n",
            "2019-04-04T20:01:23.965633: step 4320, loss 0.316015, acc 1\n",
            "2019-04-04T20:01:24.149636: step 4330, loss 0.324212, acc 1\n",
            "2019-04-04T20:01:24.330528: step 4340, loss 0.314501, acc 1\n",
            "2019-04-04T20:01:24.515601: step 4350, loss 0.312921, acc 1\n",
            "2019-04-04T20:01:24.694774: step 4360, loss 0.314466, acc 1\n",
            "2019-04-04T20:01:24.877521: step 4370, loss 0.312382, acc 1\n",
            "2019-04-04T20:01:25.062312: step 4380, loss 0.311825, acc 1\n",
            "2019-04-04T20:01:25.247558: step 4390, loss 0.312231, acc 1\n",
            "2019-04-04T20:01:25.428605: step 4400, loss 0.313284, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:25.460696: step 4400, loss 1.81556, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.605426\n",
            "\n",
            "2019-04-04T20:01:25.647968: step 4410, loss 0.314245, acc 1\n",
            "2019-04-04T20:01:25.835850: step 4420, loss 0.314005, acc 1\n",
            "2019-04-04T20:01:26.016252: step 4430, loss 0.312151, acc 1\n",
            "2019-04-04T20:01:26.201172: step 4440, loss 0.312197, acc 1\n",
            "2019-04-04T20:01:26.386981: step 4450, loss 0.312184, acc 1\n",
            "2019-04-04T20:01:26.576873: step 4460, loss 0.312323, acc 1\n",
            "2019-04-04T20:01:26.763263: step 4470, loss 0.311632, acc 1\n",
            "2019-04-04T20:01:26.951421: step 4480, loss 0.311794, acc 1\n",
            "2019-04-04T20:01:27.136179: step 4490, loss 0.311784, acc 1\n",
            "2019-04-04T20:01:27.325202: step 4500, loss 0.313064, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:27.357202: step 4500, loss 1.84689, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.606326\n",
            "\n",
            "2019-04-04T20:01:27.544125: step 4510, loss 0.31204, acc 1\n",
            "2019-04-04T20:01:27.727560: step 4520, loss 0.312092, acc 1\n",
            "2019-04-04T20:01:27.918369: step 4530, loss 0.313169, acc 1\n",
            "2019-04-04T20:01:28.105510: step 4540, loss 0.311408, acc 1\n",
            "2019-04-04T20:01:28.292311: step 4550, loss 0.310423, acc 1\n",
            "2019-04-04T20:01:28.472439: step 4560, loss 0.313016, acc 1\n",
            "2019-04-04T20:01:28.659445: step 4570, loss 0.310451, acc 1\n",
            "2019-04-04T20:01:28.844221: step 4580, loss 0.310883, acc 1\n",
            "2019-04-04T20:01:29.032612: step 4590, loss 0.311891, acc 1\n",
            "2019-04-04T20:01:29.219568: step 4600, loss 0.31102, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:29.250980: step 4600, loss 1.80765, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.597237\n",
            "\n",
            "2019-04-04T20:01:29.436700: step 4610, loss 0.310382, acc 1\n",
            "2019-04-04T20:01:29.630456: step 4620, loss 0.309812, acc 1\n",
            "2019-04-04T20:01:29.815122: step 4630, loss 0.311347, acc 1\n",
            "2019-04-04T20:01:30.003139: step 4640, loss 0.310642, acc 1\n",
            "2019-04-04T20:01:30.192948: step 4650, loss 0.312678, acc 1\n",
            "2019-04-04T20:01:30.379322: step 4660, loss 0.31034, acc 1\n",
            "2019-04-04T20:01:30.564764: step 4670, loss 0.310335, acc 1\n",
            "2019-04-04T20:01:30.750945: step 4680, loss 0.309902, acc 1\n",
            "2019-04-04T20:01:30.939971: step 4690, loss 0.309948, acc 1\n",
            "2019-04-04T20:01:31.130478: step 4700, loss 0.313152, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:31.162285: step 4700, loss 1.82968, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.606168\n",
            "\n",
            "2019-04-04T20:01:31.344294: step 4710, loss 0.309768, acc 1\n",
            "2019-04-04T20:01:31.528328: step 4720, loss 0.315012, acc 1\n",
            "2019-04-04T20:01:31.714709: step 4730, loss 0.313385, acc 1\n",
            "2019-04-04T20:01:31.895225: step 4740, loss 0.310387, acc 1\n",
            "2019-04-04T20:01:32.080337: step 4750, loss 0.310618, acc 1\n",
            "2019-04-04T20:01:32.268310: step 4760, loss 0.310245, acc 1\n",
            "2019-04-04T20:01:32.455024: step 4770, loss 0.310342, acc 1\n",
            "2019-04-04T20:01:32.639079: step 4780, loss 0.309973, acc 1\n",
            "2019-04-04T20:01:32.828643: step 4790, loss 0.313004, acc 1\n",
            "2019-04-04T20:01:33.008593: step 4800, loss 0.310117, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:33.040660: step 4800, loss 1.78854, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.603169\n",
            "\n",
            "2019-04-04T20:01:33.228139: step 4810, loss 0.327748, acc 1\n",
            "2019-04-04T20:01:33.410063: step 4820, loss 0.309157, acc 1\n",
            "2019-04-04T20:01:33.597446: step 4830, loss 0.309493, acc 1\n",
            "2019-04-04T20:01:33.783137: step 4840, loss 0.30949, acc 1\n",
            "2019-04-04T20:01:33.970743: step 4850, loss 0.30925, acc 1\n",
            "2019-04-04T20:01:34.156278: step 4860, loss 0.310637, acc 1\n",
            "2019-04-04T20:01:34.345651: step 4870, loss 0.309681, acc 1\n",
            "2019-04-04T20:01:34.529448: step 4880, loss 0.309795, acc 1\n",
            "2019-04-04T20:01:34.713563: step 4890, loss 0.309368, acc 1\n",
            "2019-04-04T20:01:34.904003: step 4900, loss 0.312229, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:34.935431: step 4900, loss 1.80595, acc 0.701107\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.615699\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.616-4900\n",
            "\n",
            "2019-04-04T20:01:35.357510: step 4910, loss 0.309704, acc 1\n",
            "2019-04-04T20:01:35.534991: step 4920, loss 0.307964, acc 1\n",
            "2019-04-04T20:01:35.719517: step 4930, loss 0.315113, acc 1\n",
            "2019-04-04T20:01:35.908580: step 4940, loss 0.309132, acc 1\n",
            "2019-04-04T20:01:36.093990: step 4950, loss 0.309916, acc 1\n",
            "2019-04-04T20:01:36.282275: step 4960, loss 0.308484, acc 1\n",
            "2019-04-04T20:01:36.466451: step 4970, loss 0.309328, acc 1\n",
            "2019-04-04T20:01:36.654649: step 4980, loss 0.308542, acc 1\n",
            "2019-04-04T20:01:36.839584: step 4990, loss 0.308742, acc 1\n",
            "2019-04-04T20:01:37.028864: step 5000, loss 0.307733, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:37.061311: step 5000, loss 1.80973, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.60906\n",
            "\n",
            "2019-04-04T20:01:37.251130: step 5010, loss 0.308462, acc 1\n",
            "2019-04-04T20:01:37.439380: step 5020, loss 0.308104, acc 1\n",
            "2019-04-04T20:01:37.623558: step 5030, loss 0.307808, acc 1\n",
            "2019-04-04T20:01:37.807855: step 5040, loss 0.308226, acc 1\n",
            "2019-04-04T20:01:37.991991: step 5050, loss 0.309828, acc 1\n",
            "2019-04-04T20:01:38.181047: step 5060, loss 0.30818, acc 1\n",
            "2019-04-04T20:01:38.368561: step 5070, loss 0.307767, acc 1\n",
            "2019-04-04T20:01:38.552771: step 5080, loss 0.307445, acc 1\n",
            "2019-04-04T20:01:38.744297: step 5090, loss 0.307491, acc 1\n",
            "2019-04-04T20:01:38.929202: step 5100, loss 0.307387, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:38.960897: step 5100, loss 1.85028, acc 0.697417\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.615124\n",
            "\n",
            "2019-04-04T20:01:39.144928: step 5110, loss 0.307195, acc 1\n",
            "2019-04-04T20:01:39.336299: step 5120, loss 0.307558, acc 1\n",
            "2019-04-04T20:01:39.523235: step 5130, loss 0.307904, acc 1\n",
            "2019-04-04T20:01:39.709654: step 5140, loss 0.31195, acc 1\n",
            "2019-04-04T20:01:39.895011: step 5150, loss 0.308504, acc 1\n",
            "2019-04-04T20:01:40.083346: step 5160, loss 0.306631, acc 1\n",
            "2019-04-04T20:01:40.262517: step 5170, loss 0.307613, acc 1\n",
            "2019-04-04T20:01:40.451474: step 5180, loss 0.308269, acc 1\n",
            "2019-04-04T20:01:40.636370: step 5190, loss 0.306937, acc 1\n",
            "2019-04-04T20:01:40.833024: step 5200, loss 0.307178, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:40.864705: step 5200, loss 1.79616, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596187\n",
            "\n",
            "2019-04-04T20:01:41.046931: step 5210, loss 0.306852, acc 1\n",
            "2019-04-04T20:01:41.227393: step 5220, loss 0.308216, acc 1\n",
            "2019-04-04T20:01:41.413302: step 5230, loss 0.310428, acc 1\n",
            "2019-04-04T20:01:41.593004: step 5240, loss 0.307618, acc 1\n",
            "2019-04-04T20:01:41.778310: step 5250, loss 0.308688, acc 1\n",
            "2019-04-04T20:01:41.958537: step 5260, loss 0.307716, acc 1\n",
            "2019-04-04T20:01:42.138287: step 5270, loss 0.307379, acc 1\n",
            "2019-04-04T20:01:42.318346: step 5280, loss 0.312226, acc 1\n",
            "2019-04-04T20:01:42.498266: step 5290, loss 0.306614, acc 1\n",
            "2019-04-04T20:01:42.677836: step 5300, loss 0.306595, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:42.710101: step 5300, loss 1.83399, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.604672\n",
            "\n",
            "2019-04-04T20:01:42.899081: step 5310, loss 0.306083, acc 1\n",
            "2019-04-04T20:01:43.094662: step 5320, loss 0.306777, acc 1\n",
            "2019-04-04T20:01:43.279990: step 5330, loss 0.305627, acc 1\n",
            "2019-04-04T20:01:43.479902: step 5340, loss 0.30631, acc 1\n",
            "2019-04-04T20:01:43.668554: step 5350, loss 0.306537, acc 1\n",
            "2019-04-04T20:01:43.860481: step 5360, loss 0.306026, acc 1\n",
            "2019-04-04T20:01:44.047362: step 5370, loss 0.306386, acc 1\n",
            "2019-04-04T20:01:44.235529: step 5380, loss 0.307009, acc 1\n",
            "2019-04-04T20:01:44.420076: step 5390, loss 0.306388, acc 1\n",
            "2019-04-04T20:01:44.612475: step 5400, loss 0.306024, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:44.644445: step 5400, loss 1.7643, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.606571\n",
            "\n",
            "2019-04-04T20:01:44.836944: step 5410, loss 0.307244, acc 1\n",
            "2019-04-04T20:01:45.019381: step 5420, loss 0.305717, acc 1\n",
            "2019-04-04T20:01:45.203509: step 5430, loss 0.305307, acc 1\n",
            "2019-04-04T20:01:45.388796: step 5440, loss 0.305501, acc 1\n",
            "2019-04-04T20:01:45.578004: step 5450, loss 0.305144, acc 1\n",
            "2019-04-04T20:01:45.762802: step 5460, loss 0.305814, acc 1\n",
            "2019-04-04T20:01:45.953928: step 5470, loss 0.305646, acc 1\n",
            "2019-04-04T20:01:46.140517: step 5480, loss 0.305798, acc 1\n",
            "2019-04-04T20:01:46.328126: step 5490, loss 0.30514, acc 1\n",
            "2019-04-04T20:01:46.514238: step 5500, loss 0.305376, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:46.545480: step 5500, loss 1.83234, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.592606\n",
            "\n",
            "2019-04-04T20:01:46.730817: step 5510, loss 0.30874, acc 1\n",
            "2019-04-04T20:01:46.918348: step 5520, loss 0.306307, acc 1\n",
            "2019-04-04T20:01:47.103193: step 5530, loss 0.306487, acc 1\n",
            "2019-04-04T20:01:47.285820: step 5540, loss 0.304537, acc 1\n",
            "2019-04-04T20:01:47.472905: step 5550, loss 0.305888, acc 1\n",
            "2019-04-04T20:01:47.661199: step 5560, loss 0.305045, acc 1\n",
            "2019-04-04T20:01:47.845861: step 5570, loss 0.304591, acc 1\n",
            "2019-04-04T20:01:48.036162: step 5580, loss 0.304573, acc 1\n",
            "2019-04-04T20:01:48.221121: step 5590, loss 0.304593, acc 1\n",
            "2019-04-04T20:01:48.412604: step 5600, loss 0.304639, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:48.444391: step 5600, loss 1.85204, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.586981\n",
            "\n",
            "2019-04-04T20:01:48.638055: step 5610, loss 0.30555, acc 1\n",
            "2019-04-04T20:01:48.818698: step 5620, loss 0.304245, acc 1\n",
            "2019-04-04T20:01:49.005154: step 5630, loss 0.304411, acc 1\n",
            "2019-04-04T20:01:49.185589: step 5640, loss 0.305383, acc 1\n",
            "2019-04-04T20:01:49.369264: step 5650, loss 0.304329, acc 1\n",
            "2019-04-04T20:01:49.543968: step 5660, loss 0.305217, acc 1\n",
            "2019-04-04T20:01:49.728415: step 5670, loss 0.304113, acc 1\n",
            "2019-04-04T20:01:49.909298: step 5680, loss 0.303979, acc 1\n",
            "2019-04-04T20:01:50.097001: step 5690, loss 0.305055, acc 1\n",
            "2019-04-04T20:01:50.277574: step 5700, loss 0.306149, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:50.309392: step 5700, loss 1.81673, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.598287\n",
            "\n",
            "2019-04-04T20:01:50.497294: step 5710, loss 0.304141, acc 1\n",
            "2019-04-04T20:01:50.685006: step 5720, loss 0.303418, acc 1\n",
            "2019-04-04T20:01:50.869127: step 5730, loss 0.304245, acc 1\n",
            "2019-04-04T20:01:51.060261: step 5740, loss 0.303353, acc 1\n",
            "2019-04-04T20:01:51.244269: step 5750, loss 0.305797, acc 1\n",
            "2019-04-04T20:01:51.435253: step 5760, loss 0.304488, acc 1\n",
            "2019-04-04T20:01:51.620188: step 5770, loss 0.303237, acc 1\n",
            "2019-04-04T20:01:51.815146: step 5780, loss 0.303458, acc 1\n",
            "2019-04-04T20:01:51.992633: step 5790, loss 0.302997, acc 1\n",
            "2019-04-04T20:01:52.179266: step 5800, loss 0.305233, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:52.211097: step 5800, loss 1.8163, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.605764\n",
            "\n",
            "2019-04-04T20:01:52.404736: step 5810, loss 0.304944, acc 1\n",
            "2019-04-04T20:01:52.590424: step 5820, loss 0.303342, acc 1\n",
            "2019-04-04T20:01:52.781048: step 5830, loss 0.303051, acc 1\n",
            "2019-04-04T20:01:52.966022: step 5840, loss 0.302871, acc 1\n",
            "2019-04-04T20:01:53.155283: step 5850, loss 0.303566, acc 1\n",
            "2019-04-04T20:01:53.341306: step 5860, loss 0.303607, acc 1\n",
            "2019-04-04T20:01:53.529716: step 5870, loss 0.303676, acc 1\n",
            "2019-04-04T20:01:53.714793: step 5880, loss 0.302572, acc 1\n",
            "2019-04-04T20:01:53.904585: step 5890, loss 0.303614, acc 1\n",
            "2019-04-04T20:01:54.090338: step 5900, loss 0.30244, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:54.122328: step 5900, loss 1.8464, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.613067\n",
            "\n",
            "2019-04-04T20:01:54.303010: step 5910, loss 0.304983, acc 1\n",
            "2019-04-04T20:01:54.488661: step 5920, loss 0.303766, acc 1\n",
            "2019-04-04T20:01:54.674003: step 5930, loss 0.303823, acc 1\n",
            "2019-04-04T20:01:54.867236: step 5940, loss 0.304701, acc 1\n",
            "2019-04-04T20:01:55.050532: step 5950, loss 0.302997, acc 1\n",
            "2019-04-04T20:01:55.239028: step 5960, loss 0.30315, acc 1\n",
            "2019-04-04T20:01:55.423516: step 5970, loss 0.302482, acc 1\n",
            "2019-04-04T20:01:55.611173: step 5980, loss 0.303086, acc 1\n",
            "2019-04-04T20:01:55.799208: step 5990, loss 0.301857, acc 1\n",
            "2019-04-04T20:01:55.987154: step 6000, loss 0.301883, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:56.018815: step 6000, loss 1.83858, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.570717\n",
            "\n",
            "2019-04-04T20:01:56.206834: step 6010, loss 0.301805, acc 1\n",
            "2019-04-04T20:01:56.390607: step 6020, loss 0.302195, acc 1\n",
            "2019-04-04T20:01:56.571953: step 6030, loss 0.302024, acc 1\n",
            "2019-04-04T20:01:56.756215: step 6040, loss 0.30719, acc 1\n",
            "2019-04-04T20:01:56.948843: step 6050, loss 0.302502, acc 1\n",
            "2019-04-04T20:01:57.133454: step 6060, loss 0.302277, acc 1\n",
            "2019-04-04T20:01:57.321095: step 6070, loss 0.30409, acc 1\n",
            "2019-04-04T20:01:57.505244: step 6080, loss 0.301273, acc 1\n",
            "2019-04-04T20:01:57.697717: step 6090, loss 0.301393, acc 1\n",
            "2019-04-04T20:01:57.887835: step 6100, loss 0.302306, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:57.919969: step 6100, loss 1.89258, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.581036\n",
            "\n",
            "2019-04-04T20:01:58.107054: step 6110, loss 0.301983, acc 1\n",
            "2019-04-04T20:01:58.296904: step 6120, loss 0.30132, acc 1\n",
            "2019-04-04T20:01:58.480010: step 6130, loss 0.301325, acc 1\n",
            "2019-04-04T20:01:58.665964: step 6140, loss 0.302337, acc 1\n",
            "2019-04-04T20:01:58.844482: step 6150, loss 0.301445, acc 1\n",
            "2019-04-04T20:01:59.037219: step 6160, loss 0.301933, acc 1\n",
            "2019-04-04T20:01:59.217839: step 6170, loss 0.301434, acc 1\n",
            "2019-04-04T20:01:59.399955: step 6180, loss 0.301256, acc 1\n",
            "2019-04-04T20:01:59.581162: step 6190, loss 0.301679, acc 1\n",
            "2019-04-04T20:01:59.762960: step 6200, loss 0.305342, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:01:59.795704: step 6200, loss 1.82666, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596593\n",
            "\n",
            "2019-04-04T20:01:59.983580: step 6210, loss 0.300833, acc 1\n",
            "2019-04-04T20:02:00.168217: step 6220, loss 0.301384, acc 1\n",
            "2019-04-04T20:02:00.352933: step 6230, loss 0.300621, acc 1\n",
            "2019-04-04T20:02:00.533112: step 6240, loss 0.300707, acc 1\n",
            "2019-04-04T20:02:00.716722: step 6250, loss 0.300861, acc 1\n",
            "2019-04-04T20:02:00.898363: step 6260, loss 0.300716, acc 1\n",
            "2019-04-04T20:02:01.088241: step 6270, loss 0.300269, acc 1\n",
            "2019-04-04T20:02:01.263426: step 6280, loss 0.300619, acc 1\n",
            "2019-04-04T20:02:01.445106: step 6290, loss 0.300629, acc 1\n",
            "2019-04-04T20:02:01.629166: step 6300, loss 0.301093, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:01.660824: step 6300, loss 1.83964, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.609416\n",
            "\n",
            "2019-04-04T20:02:01.846708: step 6310, loss 0.300932, acc 1\n",
            "2019-04-04T20:02:02.036394: step 6320, loss 0.301183, acc 1\n",
            "2019-04-04T20:02:02.219416: step 6330, loss 0.300034, acc 1\n",
            "2019-04-04T20:02:02.406113: step 6340, loss 0.300221, acc 1\n",
            "2019-04-04T20:02:02.590585: step 6350, loss 0.300343, acc 1\n",
            "2019-04-04T20:02:02.779007: step 6360, loss 0.304322, acc 1\n",
            "2019-04-04T20:02:02.964015: step 6370, loss 0.299736, acc 1\n",
            "2019-04-04T20:02:03.156356: step 6380, loss 0.299912, acc 1\n",
            "2019-04-04T20:02:03.344406: step 6390, loss 0.300989, acc 1\n",
            "2019-04-04T20:02:03.525344: step 6400, loss 0.300017, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:03.556918: step 6400, loss 1.8504, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.593656\n",
            "\n",
            "2019-04-04T20:02:03.738917: step 6410, loss 0.300085, acc 1\n",
            "2019-04-04T20:02:03.920989: step 6420, loss 0.303278, acc 1\n",
            "2019-04-04T20:02:04.108470: step 6430, loss 0.299435, acc 1\n",
            "2019-04-04T20:02:04.288378: step 6440, loss 0.299742, acc 1\n",
            "2019-04-04T20:02:04.472034: step 6450, loss 0.29931, acc 1\n",
            "2019-04-04T20:02:04.651950: step 6460, loss 0.299787, acc 1\n",
            "2019-04-04T20:02:04.833557: step 6470, loss 0.299951, acc 1\n",
            "2019-04-04T20:02:05.015608: step 6480, loss 0.301992, acc 1\n",
            "2019-04-04T20:02:05.203166: step 6490, loss 0.299101, acc 1\n",
            "2019-04-04T20:02:05.383806: step 6500, loss 0.301193, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:05.415599: step 6500, loss 1.85606, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.557376\n",
            "\n",
            "2019-04-04T20:02:05.601896: step 6510, loss 0.299451, acc 1\n",
            "2019-04-04T20:02:05.785511: step 6520, loss 0.299324, acc 1\n",
            "2019-04-04T20:02:05.971329: step 6530, loss 0.299617, acc 1\n",
            "2019-04-04T20:02:06.161927: step 6540, loss 0.298866, acc 1\n",
            "2019-04-04T20:02:06.342245: step 6550, loss 0.298917, acc 1\n",
            "2019-04-04T20:02:06.525008: step 6560, loss 0.299078, acc 1\n",
            "2019-04-04T20:02:06.704785: step 6570, loss 0.301175, acc 1\n",
            "2019-04-04T20:02:06.889516: step 6580, loss 0.300528, acc 1\n",
            "2019-04-04T20:02:07.070606: step 6590, loss 0.299058, acc 1\n",
            "2019-04-04T20:02:07.256175: step 6600, loss 0.298471, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:07.288428: step 6600, loss 1.85738, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.583672\n",
            "\n",
            "2019-04-04T20:02:07.475704: step 6610, loss 0.299877, acc 1\n",
            "2019-04-04T20:02:07.659550: step 6620, loss 0.298384, acc 1\n",
            "2019-04-04T20:02:07.850764: step 6630, loss 0.298825, acc 1\n",
            "2019-04-04T20:02:08.034975: step 6640, loss 0.300043, acc 1\n",
            "2019-04-04T20:02:08.222144: step 6650, loss 0.298421, acc 1\n",
            "2019-04-04T20:02:08.410050: step 6660, loss 0.29925, acc 1\n",
            "2019-04-04T20:02:08.595412: step 6670, loss 0.297885, acc 1\n",
            "2019-04-04T20:02:08.779454: step 6680, loss 0.300654, acc 1\n",
            "2019-04-04T20:02:08.975540: step 6690, loss 0.297867, acc 1\n",
            "2019-04-04T20:02:09.164951: step 6700, loss 0.298006, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:09.196244: step 6700, loss 1.85596, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.589146\n",
            "\n",
            "2019-04-04T20:02:09.387870: step 6710, loss 0.299242, acc 1\n",
            "2019-04-04T20:02:09.573358: step 6720, loss 0.297941, acc 1\n",
            "2019-04-04T20:02:09.766164: step 6730, loss 0.311205, acc 1\n",
            "2019-04-04T20:02:09.950428: step 6740, loss 0.297503, acc 1\n",
            "2019-04-04T20:02:10.141917: step 6750, loss 0.299421, acc 1\n",
            "2019-04-04T20:02:10.335050: step 6760, loss 0.297644, acc 1\n",
            "2019-04-04T20:02:10.517427: step 6770, loss 0.298654, acc 1\n",
            "2019-04-04T20:02:10.707604: step 6780, loss 0.297761, acc 1\n",
            "2019-04-04T20:02:10.889143: step 6790, loss 0.297854, acc 1\n",
            "2019-04-04T20:02:11.074232: step 6800, loss 0.298297, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:11.106208: step 6800, loss 1.85426, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.591535\n",
            "\n",
            "2019-04-04T20:02:11.293020: step 6810, loss 0.298477, acc 1\n",
            "2019-04-04T20:02:11.475790: step 6820, loss 0.297924, acc 1\n",
            "2019-04-04T20:02:11.659321: step 6830, loss 0.299408, acc 1\n",
            "2019-04-04T20:02:11.842142: step 6840, loss 0.297845, acc 1\n",
            "2019-04-04T20:02:12.031196: step 6850, loss 0.297735, acc 1\n",
            "2019-04-04T20:02:12.216179: step 6860, loss 0.296871, acc 1\n",
            "2019-04-04T20:02:12.406279: step 6870, loss 0.29958, acc 1\n",
            "2019-04-04T20:02:12.590352: step 6880, loss 0.298159, acc 1\n",
            "2019-04-04T20:02:12.777009: step 6890, loss 0.297084, acc 1\n",
            "2019-04-04T20:02:12.962578: step 6900, loss 0.296998, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:12.994899: step 6900, loss 1.84151, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.590554\n",
            "\n",
            "2019-04-04T20:02:13.182065: step 6910, loss 0.2975, acc 1\n",
            "2019-04-04T20:02:13.378728: step 6920, loss 0.297325, acc 1\n",
            "2019-04-04T20:02:13.564130: step 6930, loss 0.296691, acc 1\n",
            "2019-04-04T20:02:13.761342: step 6940, loss 0.297543, acc 1\n",
            "2019-04-04T20:02:13.946031: step 6950, loss 0.297134, acc 1\n",
            "2019-04-04T20:02:14.132867: step 6960, loss 0.296195, acc 1\n",
            "2019-04-04T20:02:14.320181: step 6970, loss 0.298765, acc 1\n",
            "2019-04-04T20:02:14.505980: step 6980, loss 0.296174, acc 1\n",
            "2019-04-04T20:02:14.690449: step 6990, loss 0.297476, acc 1\n",
            "2019-04-04T20:02:14.881183: step 7000, loss 0.296452, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:14.913162: step 7000, loss 1.83145, acc 0.697417\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.626516\n",
            "\n",
            "Saved model checkpoint to /content/drive/My Drive/runs/1554407997/checkpoints/model-0.627-7000\n",
            "\n",
            "2019-04-04T20:02:15.343304: step 7010, loss 0.2983, acc 1\n",
            "2019-04-04T20:02:15.527582: step 7020, loss 0.296267, acc 1\n",
            "2019-04-04T20:02:15.711804: step 7030, loss 0.296348, acc 1\n",
            "2019-04-04T20:02:15.900516: step 7040, loss 0.296135, acc 1\n",
            "2019-04-04T20:02:16.083346: step 7050, loss 0.295847, acc 1\n",
            "2019-04-04T20:02:16.270339: step 7060, loss 0.303016, acc 1\n",
            "2019-04-04T20:02:16.456182: step 7070, loss 0.297861, acc 1\n",
            "2019-04-04T20:02:16.643536: step 7080, loss 0.295995, acc 1\n",
            "2019-04-04T20:02:16.825649: step 7090, loss 0.296559, acc 1\n",
            "2019-04-04T20:02:17.016279: step 7100, loss 0.297704, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:17.048115: step 7100, loss 1.79008, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.591874\n",
            "\n",
            "2019-04-04T20:02:17.236082: step 7110, loss 0.295782, acc 1\n",
            "2019-04-04T20:02:17.423176: step 7120, loss 0.296015, acc 1\n",
            "2019-04-04T20:02:17.608333: step 7130, loss 0.295474, acc 1\n",
            "2019-04-04T20:02:17.784237: step 7140, loss 0.295613, acc 1\n",
            "2019-04-04T20:02:17.970374: step 7150, loss 0.295262, acc 1\n",
            "2019-04-04T20:02:18.154278: step 7160, loss 0.295293, acc 1\n",
            "2019-04-04T20:02:18.343279: step 7170, loss 0.295477, acc 1\n",
            "2019-04-04T20:02:18.530441: step 7180, loss 0.295282, acc 1\n",
            "2019-04-04T20:02:18.716503: step 7190, loss 0.295087, acc 1\n",
            "2019-04-04T20:02:18.901032: step 7200, loss 0.294963, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:18.934653: step 7200, loss 1.84455, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.617476\n",
            "\n",
            "2019-04-04T20:02:19.121336: step 7210, loss 0.295492, acc 1\n",
            "2019-04-04T20:02:19.307066: step 7220, loss 0.29491, acc 1\n",
            "2019-04-04T20:02:19.497418: step 7230, loss 0.29704, acc 1\n",
            "2019-04-04T20:02:19.681996: step 7240, loss 0.296408, acc 1\n",
            "2019-04-04T20:02:19.865334: step 7250, loss 0.295101, acc 1\n",
            "2019-04-04T20:02:20.049143: step 7260, loss 0.294618, acc 1\n",
            "2019-04-04T20:02:20.233759: step 7270, loss 0.294834, acc 1\n",
            "2019-04-04T20:02:20.421964: step 7280, loss 0.294645, acc 1\n",
            "2019-04-04T20:02:20.605654: step 7290, loss 0.294695, acc 1\n",
            "2019-04-04T20:02:20.805822: step 7300, loss 0.294835, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:20.837352: step 7300, loss 1.86008, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.594766\n",
            "\n",
            "2019-04-04T20:02:21.017042: step 7310, loss 0.294493, acc 1\n",
            "2019-04-04T20:02:21.199083: step 7320, loss 0.294343, acc 1\n",
            "2019-04-04T20:02:21.384314: step 7330, loss 0.294966, acc 1\n",
            "2019-04-04T20:02:21.571238: step 7340, loss 0.296824, acc 1\n",
            "2019-04-04T20:02:21.754112: step 7350, loss 0.294984, acc 1\n",
            "2019-04-04T20:02:21.936791: step 7360, loss 0.295495, acc 1\n",
            "2019-04-04T20:02:22.119960: step 7370, loss 0.294626, acc 1\n",
            "2019-04-04T20:02:22.295427: step 7380, loss 0.294862, acc 1\n",
            "2019-04-04T20:02:22.475539: step 7390, loss 0.298683, acc 1\n",
            "2019-04-04T20:02:22.658023: step 7400, loss 0.295328, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:22.689557: step 7400, loss 1.8147, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.61436\n",
            "\n",
            "2019-04-04T20:02:22.877268: step 7410, loss 0.294294, acc 1\n",
            "2019-04-04T20:02:23.067389: step 7420, loss 0.293979, acc 1\n",
            "2019-04-04T20:02:23.252894: step 7430, loss 0.294005, acc 1\n",
            "2019-04-04T20:02:23.444909: step 7440, loss 0.297197, acc 1\n",
            "2019-04-04T20:02:23.636780: step 7450, loss 0.294131, acc 1\n",
            "2019-04-04T20:02:23.831824: step 7460, loss 0.294299, acc 1\n",
            "2019-04-04T20:02:24.017275: step 7470, loss 0.294398, acc 1\n",
            "2019-04-04T20:02:24.206112: step 7480, loss 0.29599, acc 1\n",
            "2019-04-04T20:02:24.391634: step 7490, loss 0.293445, acc 1\n",
            "2019-04-04T20:02:24.584190: step 7500, loss 0.293156, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:24.615436: step 7500, loss 1.83719, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.59424\n",
            "\n",
            "2019-04-04T20:02:24.794629: step 7510, loss 0.293231, acc 1\n",
            "2019-04-04T20:02:24.979800: step 7520, loss 0.293812, acc 1\n",
            "2019-04-04T20:02:25.167139: step 7530, loss 0.294313, acc 1\n",
            "2019-04-04T20:02:25.351939: step 7540, loss 0.293962, acc 1\n",
            "2019-04-04T20:02:25.538058: step 7550, loss 0.299925, acc 1\n",
            "2019-04-04T20:02:25.723514: step 7560, loss 0.293061, acc 1\n",
            "2019-04-04T20:02:25.913254: step 7570, loss 0.293334, acc 1\n",
            "2019-04-04T20:02:26.096974: step 7580, loss 0.293389, acc 1\n",
            "2019-04-04T20:02:26.287638: step 7590, loss 0.292936, acc 1\n",
            "2019-04-04T20:02:26.472392: step 7600, loss 0.293224, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:26.503804: step 7600, loss 1.83349, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.610141\n",
            "\n",
            "2019-04-04T20:02:26.690878: step 7610, loss 0.293151, acc 1\n",
            "2019-04-04T20:02:26.882125: step 7620, loss 0.293823, acc 1\n",
            "2019-04-04T20:02:27.062465: step 7630, loss 0.292376, acc 1\n",
            "2019-04-04T20:02:27.256715: step 7640, loss 0.292563, acc 1\n",
            "2019-04-04T20:02:27.442654: step 7650, loss 0.292398, acc 1\n",
            "2019-04-04T20:02:27.632099: step 7660, loss 0.293095, acc 1\n",
            "2019-04-04T20:02:27.820261: step 7670, loss 0.292184, acc 1\n",
            "2019-04-04T20:02:28.006227: step 7680, loss 0.293645, acc 1\n",
            "2019-04-04T20:02:28.192297: step 7690, loss 0.292113, acc 1\n",
            "2019-04-04T20:02:28.380195: step 7700, loss 0.292307, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:28.412304: step 7700, loss 1.86564, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596077\n",
            "\n",
            "2019-04-04T20:02:28.600538: step 7710, loss 0.292238, acc 1\n",
            "2019-04-04T20:02:28.787589: step 7720, loss 0.292646, acc 1\n",
            "2019-04-04T20:02:28.973899: step 7730, loss 0.292777, acc 1\n",
            "2019-04-04T20:02:29.159630: step 7740, loss 0.291931, acc 1\n",
            "2019-04-04T20:02:29.341287: step 7750, loss 0.29317, acc 1\n",
            "2019-04-04T20:02:29.525397: step 7760, loss 0.292013, acc 1\n",
            "2019-04-04T20:02:29.715073: step 7770, loss 0.294303, acc 1\n",
            "2019-04-04T20:02:29.899348: step 7780, loss 0.29214, acc 1\n",
            "2019-04-04T20:02:30.091369: step 7790, loss 0.29164, acc 1\n",
            "2019-04-04T20:02:30.274659: step 7800, loss 0.292222, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:30.305936: step 7800, loss 1.8744, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.591405\n",
            "\n",
            "2019-04-04T20:02:30.487234: step 7810, loss 0.292513, acc 1\n",
            "2019-04-04T20:02:30.670137: step 7820, loss 0.2927, acc 1\n",
            "2019-04-04T20:02:30.858798: step 7830, loss 0.293109, acc 1\n",
            "2019-04-04T20:02:31.040546: step 7840, loss 0.291656, acc 1\n",
            "2019-04-04T20:02:31.220029: step 7850, loss 0.29248, acc 1\n",
            "2019-04-04T20:02:31.401919: step 7860, loss 0.291737, acc 1\n",
            "2019-04-04T20:02:31.584331: step 7870, loss 0.291411, acc 1\n",
            "2019-04-04T20:02:31.764449: step 7880, loss 0.291646, acc 1\n",
            "2019-04-04T20:02:31.947135: step 7890, loss 0.291428, acc 1\n",
            "2019-04-04T20:02:32.131864: step 7900, loss 0.291396, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:32.164232: step 7900, loss 1.83825, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.62103\n",
            "\n",
            "2019-04-04T20:02:32.350052: step 7910, loss 0.292363, acc 1\n",
            "2019-04-04T20:02:32.534964: step 7920, loss 0.290937, acc 1\n",
            "2019-04-04T20:02:32.722751: step 7930, loss 0.290927, acc 1\n",
            "2019-04-04T20:02:32.912639: step 7940, loss 0.291043, acc 1\n",
            "2019-04-04T20:02:33.096607: step 7950, loss 0.290961, acc 1\n",
            "2019-04-04T20:02:33.283602: step 7960, loss 0.290915, acc 1\n",
            "2019-04-04T20:02:33.467862: step 7970, loss 0.291902, acc 1\n",
            "2019-04-04T20:02:33.650885: step 7980, loss 0.29146, acc 1\n",
            "2019-04-04T20:02:33.846428: step 7990, loss 0.290401, acc 1\n",
            "2019-04-04T20:02:34.026900: step 8000, loss 0.290779, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:34.058584: step 8000, loss 1.85688, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596756\n",
            "\n",
            "2019-04-04T20:02:34.243115: step 8010, loss 0.292697, acc 1\n",
            "2019-04-04T20:02:34.431080: step 8020, loss 0.293201, acc 1\n",
            "2019-04-04T20:02:34.613751: step 8030, loss 0.291132, acc 1\n",
            "2019-04-04T20:02:34.801062: step 8040, loss 0.290856, acc 1\n",
            "2019-04-04T20:02:34.987888: step 8050, loss 0.290654, acc 1\n",
            "2019-04-04T20:02:35.174814: step 8060, loss 0.290806, acc 1\n",
            "2019-04-04T20:02:35.357756: step 8070, loss 0.292811, acc 1\n",
            "2019-04-04T20:02:35.542800: step 8080, loss 0.290199, acc 1\n",
            "2019-04-04T20:02:35.726327: step 8090, loss 0.290203, acc 1\n",
            "2019-04-04T20:02:35.916044: step 8100, loss 0.290241, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:35.947387: step 8100, loss 1.83384, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.595218\n",
            "\n",
            "2019-04-04T20:02:36.141057: step 8110, loss 0.291205, acc 1\n",
            "2019-04-04T20:02:36.321206: step 8120, loss 0.289924, acc 1\n",
            "2019-04-04T20:02:36.506986: step 8130, loss 0.290248, acc 1\n",
            "2019-04-04T20:02:36.691873: step 8140, loss 0.290239, acc 1\n",
            "2019-04-04T20:02:36.884962: step 8150, loss 0.289891, acc 1\n",
            "2019-04-04T20:02:37.071499: step 8160, loss 0.28949, acc 1\n",
            "2019-04-04T20:02:37.256795: step 8170, loss 0.290193, acc 1\n",
            "2019-04-04T20:02:37.440288: step 8180, loss 0.290761, acc 1\n",
            "2019-04-04T20:02:37.629991: step 8190, loss 0.295012, acc 1\n",
            "2019-04-04T20:02:37.814151: step 8200, loss 0.2896, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:37.846221: step 8200, loss 1.82991, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.621497\n",
            "\n",
            "2019-04-04T20:02:38.034298: step 8210, loss 0.289573, acc 1\n",
            "2019-04-04T20:02:38.221071: step 8220, loss 0.289695, acc 1\n",
            "2019-04-04T20:02:38.405976: step 8230, loss 0.289265, acc 1\n",
            "2019-04-04T20:02:38.597632: step 8240, loss 0.289686, acc 1\n",
            "2019-04-04T20:02:38.775721: step 8250, loss 0.289849, acc 1\n",
            "2019-04-04T20:02:38.971220: step 8260, loss 0.289255, acc 1\n",
            "2019-04-04T20:02:39.154871: step 8270, loss 0.289118, acc 1\n",
            "2019-04-04T20:02:39.342619: step 8280, loss 0.288747, acc 1\n",
            "2019-04-04T20:02:39.527737: step 8290, loss 0.292085, acc 1\n",
            "2019-04-04T20:02:39.718043: step 8300, loss 0.289633, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:39.749929: step 8300, loss 1.8249, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.600264\n",
            "\n",
            "2019-04-04T20:02:39.938808: step 8310, loss 0.288919, acc 1\n",
            "2019-04-04T20:02:40.127078: step 8320, loss 0.288515, acc 1\n",
            "2019-04-04T20:02:40.313492: step 8330, loss 0.289516, acc 1\n",
            "2019-04-04T20:02:40.497969: step 8340, loss 0.288952, acc 1\n",
            "2019-04-04T20:02:40.686502: step 8350, loss 0.289932, acc 1\n",
            "2019-04-04T20:02:40.870550: step 8360, loss 0.297264, acc 1\n",
            "2019-04-04T20:02:41.062441: step 8370, loss 0.28911, acc 1\n",
            "2019-04-04T20:02:41.263167: step 8380, loss 0.288411, acc 1\n",
            "2019-04-04T20:02:41.451190: step 8390, loss 0.289928, acc 1\n",
            "2019-04-04T20:02:41.635852: step 8400, loss 0.292496, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:41.667621: step 8400, loss 1.8511, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.602102\n",
            "\n",
            "2019-04-04T20:02:41.853195: step 8410, loss 0.289446, acc 1\n",
            "2019-04-04T20:02:42.050235: step 8420, loss 0.288217, acc 1\n",
            "2019-04-04T20:02:42.235597: step 8430, loss 0.288475, acc 1\n",
            "2019-04-04T20:02:42.423348: step 8440, loss 0.28827, acc 1\n",
            "2019-04-04T20:02:42.608073: step 8450, loss 0.287817, acc 1\n",
            "2019-04-04T20:02:42.800102: step 8460, loss 0.287938, acc 1\n",
            "2019-04-04T20:02:42.983866: step 8470, loss 0.288329, acc 1\n",
            "2019-04-04T20:02:43.176034: step 8480, loss 0.2883, acc 1\n",
            "2019-04-04T20:02:43.355110: step 8490, loss 0.290821, acc 1\n",
            "2019-04-04T20:02:43.541382: step 8500, loss 0.288589, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:43.573826: step 8500, loss 1.85743, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.594485\n",
            "\n",
            "2019-04-04T20:02:43.761924: step 8510, loss 0.287878, acc 1\n",
            "2019-04-04T20:02:43.946115: step 8520, loss 0.288525, acc 1\n",
            "2019-04-04T20:02:44.138644: step 8530, loss 0.288878, acc 1\n",
            "2019-04-04T20:02:44.322361: step 8540, loss 0.288092, acc 1\n",
            "2019-04-04T20:02:44.514160: step 8550, loss 0.287907, acc 1\n",
            "2019-04-04T20:02:44.698352: step 8560, loss 0.288081, acc 1\n",
            "2019-04-04T20:02:44.889354: step 8570, loss 0.287738, acc 1\n",
            "2019-04-04T20:02:45.073307: step 8580, loss 0.287291, acc 1\n",
            "2019-04-04T20:02:45.264820: step 8590, loss 0.287692, acc 1\n",
            "2019-04-04T20:02:45.447790: step 8600, loss 0.288357, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:45.480275: step 8600, loss 1.87485, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.591281\n",
            "\n",
            "2019-04-04T20:02:45.655929: step 8610, loss 0.288768, acc 1\n",
            "2019-04-04T20:02:45.837849: step 8620, loss 0.287958, acc 1\n",
            "2019-04-04T20:02:46.017890: step 8630, loss 0.287136, acc 1\n",
            "2019-04-04T20:02:46.204348: step 8640, loss 0.286946, acc 1\n",
            "2019-04-04T20:02:46.389788: step 8650, loss 0.28732, acc 1\n",
            "2019-04-04T20:02:46.574536: step 8660, loss 0.287111, acc 1\n",
            "2019-04-04T20:02:46.759231: step 8670, loss 0.28696, acc 1\n",
            "2019-04-04T20:02:46.950981: step 8680, loss 0.287775, acc 1\n",
            "2019-04-04T20:02:47.136921: step 8690, loss 0.286682, acc 1\n",
            "2019-04-04T20:02:47.327648: step 8700, loss 0.28711, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:47.361293: step 8700, loss 1.85038, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.608882\n",
            "\n",
            "2019-04-04T20:02:47.547370: step 8710, loss 0.287881, acc 1\n",
            "2019-04-04T20:02:47.726841: step 8720, loss 0.287124, acc 1\n",
            "2019-04-04T20:02:47.911238: step 8730, loss 0.28711, acc 1\n",
            "2019-04-04T20:02:48.086739: step 8740, loss 0.286151, acc 1\n",
            "2019-04-04T20:02:48.267693: step 8750, loss 0.286842, acc 1\n",
            "2019-04-04T20:02:48.450354: step 8760, loss 0.28739, acc 1\n",
            "2019-04-04T20:02:48.638156: step 8770, loss 0.286339, acc 1\n",
            "2019-04-04T20:02:48.823334: step 8780, loss 0.288983, acc 1\n",
            "2019-04-04T20:02:49.015189: step 8790, loss 0.286055, acc 1\n",
            "2019-04-04T20:02:49.199120: step 8800, loss 0.286724, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:49.240392: step 8800, loss 1.82832, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.616697\n",
            "\n",
            "2019-04-04T20:02:49.424039: step 8810, loss 0.286408, acc 1\n",
            "2019-04-04T20:02:49.610422: step 8820, loss 0.28672, acc 1\n",
            "2019-04-04T20:02:49.793053: step 8830, loss 0.285993, acc 1\n",
            "2019-04-04T20:02:49.979832: step 8840, loss 0.28607, acc 1\n",
            "2019-04-04T20:02:50.164973: step 8850, loss 0.285968, acc 1\n",
            "2019-04-04T20:02:50.351054: step 8860, loss 0.285843, acc 1\n",
            "2019-04-04T20:02:50.535181: step 8870, loss 0.28574, acc 1\n",
            "2019-04-04T20:02:50.723926: step 8880, loss 0.285567, acc 1\n",
            "2019-04-04T20:02:50.907863: step 8890, loss 0.286419, acc 1\n",
            "2019-04-04T20:02:51.093899: step 8900, loss 0.287195, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:51.126654: step 8900, loss 1.84906, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.616952\n",
            "\n",
            "2019-04-04T20:02:51.319280: step 8910, loss 0.285609, acc 1\n",
            "2019-04-04T20:02:51.500523: step 8920, loss 0.285308, acc 1\n",
            "2019-04-04T20:02:51.680770: step 8930, loss 0.285134, acc 1\n",
            "2019-04-04T20:02:51.859367: step 8940, loss 0.286022, acc 1\n",
            "2019-04-04T20:02:52.041579: step 8950, loss 0.285229, acc 1\n",
            "2019-04-04T20:02:52.219465: step 8960, loss 0.285104, acc 1\n",
            "2019-04-04T20:02:52.403218: step 8970, loss 0.285367, acc 1\n",
            "2019-04-04T20:02:52.578430: step 8980, loss 0.285554, acc 1\n",
            "2019-04-04T20:02:52.757643: step 8990, loss 0.285149, acc 1\n",
            "2019-04-04T20:02:52.941191: step 9000, loss 0.284839, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:52.972960: step 9000, loss 1.85349, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.599762\n",
            "\n",
            "2019-04-04T20:02:53.155002: step 9010, loss 0.285548, acc 1\n",
            "2019-04-04T20:02:53.343119: step 9020, loss 0.284631, acc 1\n",
            "2019-04-04T20:02:53.524976: step 9030, loss 0.284617, acc 1\n",
            "2019-04-04T20:02:53.708977: step 9040, loss 0.285515, acc 1\n",
            "2019-04-04T20:02:53.893046: step 9050, loss 0.284497, acc 1\n",
            "2019-04-04T20:02:54.081803: step 9060, loss 0.285166, acc 1\n",
            "2019-04-04T20:02:54.265556: step 9070, loss 0.28527, acc 1\n",
            "2019-04-04T20:02:54.456197: step 9080, loss 0.284771, acc 1\n",
            "2019-04-04T20:02:54.642792: step 9090, loss 0.285274, acc 1\n",
            "2019-04-04T20:02:54.830495: step 9100, loss 0.285171, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:54.862468: step 9100, loss 1.84889, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.598224\n",
            "\n",
            "2019-04-04T20:02:55.040105: step 9110, loss 0.284413, acc 1\n",
            "2019-04-04T20:02:55.220573: step 9120, loss 0.2842, acc 1\n",
            "2019-04-04T20:02:55.403170: step 9130, loss 0.286559, acc 1\n",
            "2019-04-04T20:02:55.586443: step 9140, loss 0.285985, acc 1\n",
            "2019-04-04T20:02:55.773156: step 9150, loss 0.284061, acc 1\n",
            "2019-04-04T20:02:55.957724: step 9160, loss 0.284383, acc 1\n",
            "2019-04-04T20:02:56.148776: step 9170, loss 0.283977, acc 1\n",
            "2019-04-04T20:02:56.332940: step 9180, loss 0.284232, acc 1\n",
            "2019-04-04T20:02:56.521778: step 9190, loss 0.285, acc 1\n",
            "2019-04-04T20:02:56.708170: step 9200, loss 0.284081, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:56.740049: step 9200, loss 1.87156, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.600172\n",
            "\n",
            "2019-04-04T20:02:56.926030: step 9210, loss 0.28563, acc 1\n",
            "2019-04-04T20:02:57.111908: step 9220, loss 0.284065, acc 1\n",
            "2019-04-04T20:02:57.290333: step 9230, loss 0.284248, acc 1\n",
            "2019-04-04T20:02:57.482272: step 9240, loss 0.284482, acc 1\n",
            "2019-04-04T20:02:57.666384: step 9250, loss 0.285689, acc 1\n",
            "2019-04-04T20:02:57.857375: step 9260, loss 0.284198, acc 1\n",
            "2019-04-04T20:02:58.040911: step 9270, loss 0.283757, acc 1\n",
            "2019-04-04T20:02:58.234214: step 9280, loss 0.284332, acc 1\n",
            "2019-04-04T20:02:58.419582: step 9290, loss 0.287808, acc 1\n",
            "2019-04-04T20:02:58.611663: step 9300, loss 0.283334, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:02:58.643895: step 9300, loss 1.87228, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.598361\n",
            "\n",
            "2019-04-04T20:02:58.835103: step 9310, loss 0.283498, acc 1\n",
            "2019-04-04T20:02:59.019195: step 9320, loss 0.283451, acc 1\n",
            "2019-04-04T20:02:59.206252: step 9330, loss 0.286094, acc 1\n",
            "2019-04-04T20:02:59.389658: step 9340, loss 0.28341, acc 1\n",
            "2019-04-04T20:02:59.575328: step 9350, loss 0.289347, acc 1\n",
            "2019-04-04T20:02:59.759118: step 9360, loss 0.283409, acc 1\n",
            "2019-04-04T20:02:59.951272: step 9370, loss 0.293899, acc 1\n",
            "2019-04-04T20:03:00.134748: step 9380, loss 0.283583, acc 1\n",
            "2019-04-04T20:03:00.324400: step 9390, loss 0.289201, acc 1\n",
            "2019-04-04T20:03:00.510984: step 9400, loss 0.284, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:00.546230: step 9400, loss 1.8556, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.586589\n",
            "\n",
            "2019-04-04T20:03:00.731272: step 9410, loss 0.282694, acc 1\n",
            "2019-04-04T20:03:00.921758: step 9420, loss 0.283584, acc 1\n",
            "2019-04-04T20:03:01.106098: step 9430, loss 0.283426, acc 1\n",
            "2019-04-04T20:03:01.293509: step 9440, loss 0.283095, acc 1\n",
            "2019-04-04T20:03:01.478526: step 9450, loss 0.282592, acc 1\n",
            "2019-04-04T20:03:01.671346: step 9460, loss 0.282433, acc 1\n",
            "2019-04-04T20:03:01.861337: step 9470, loss 0.282512, acc 1\n",
            "2019-04-04T20:03:02.044462: step 9480, loss 0.282349, acc 1\n",
            "2019-04-04T20:03:02.228885: step 9490, loss 0.283512, acc 1\n",
            "2019-04-04T20:03:02.416633: step 9500, loss 0.282236, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:02.448882: step 9500, loss 1.8561, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.584379\n",
            "\n",
            "2019-04-04T20:03:02.637468: step 9510, loss 0.282763, acc 1\n",
            "2019-04-04T20:03:02.824057: step 9520, loss 0.283434, acc 1\n",
            "2019-04-04T20:03:03.010372: step 9530, loss 0.282017, acc 1\n",
            "2019-04-04T20:03:03.195054: step 9540, loss 0.281846, acc 1\n",
            "2019-04-04T20:03:03.383080: step 9550, loss 0.283791, acc 1\n",
            "2019-04-04T20:03:03.566136: step 9560, loss 0.282201, acc 1\n",
            "2019-04-04T20:03:03.756839: step 9570, loss 0.282591, acc 1\n",
            "2019-04-04T20:03:03.936037: step 9580, loss 0.283087, acc 1\n",
            "2019-04-04T20:03:04.120132: step 9590, loss 0.281962, acc 1\n",
            "2019-04-04T20:03:04.297115: step 9600, loss 0.283906, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:04.332316: step 9600, loss 1.83037, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.61283\n",
            "\n",
            "2019-04-04T20:03:04.518583: step 9610, loss 0.281782, acc 1\n",
            "2019-04-04T20:03:04.710624: step 9620, loss 0.282499, acc 1\n",
            "2019-04-04T20:03:04.895113: step 9630, loss 0.281491, acc 1\n",
            "2019-04-04T20:03:05.081554: step 9640, loss 0.281809, acc 1\n",
            "2019-04-04T20:03:05.267408: step 9650, loss 0.282694, acc 1\n",
            "2019-04-04T20:03:05.456309: step 9660, loss 0.281918, acc 1\n",
            "2019-04-04T20:03:05.640149: step 9670, loss 0.281536, acc 1\n",
            "2019-04-04T20:03:05.831544: step 9680, loss 0.281475, acc 1\n",
            "2019-04-04T20:03:06.014573: step 9690, loss 0.283376, acc 1\n",
            "2019-04-04T20:03:06.200657: step 9700, loss 0.28163, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:06.232667: step 9700, loss 1.8766, acc 0.671587\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.589818\n",
            "\n",
            "2019-04-04T20:03:06.420031: step 9710, loss 0.281122, acc 1\n",
            "2019-04-04T20:03:06.598266: step 9720, loss 0.280907, acc 1\n",
            "2019-04-04T20:03:06.788335: step 9730, loss 0.280727, acc 1\n",
            "2019-04-04T20:03:06.971087: step 9740, loss 0.281071, acc 1\n",
            "2019-04-04T20:03:07.158778: step 9750, loss 0.281031, acc 1\n",
            "2019-04-04T20:03:07.342811: step 9760, loss 0.28078, acc 1\n",
            "2019-04-04T20:03:07.531922: step 9770, loss 0.280794, acc 1\n",
            "2019-04-04T20:03:07.717760: step 9780, loss 0.282571, acc 1\n",
            "2019-04-04T20:03:07.909014: step 9790, loss 0.280569, acc 1\n",
            "2019-04-04T20:03:08.096457: step 9800, loss 0.281802, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:08.131067: step 9800, loss 1.87004, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.592793\n",
            "\n",
            "2019-04-04T20:03:08.315941: step 9810, loss 0.280642, acc 1\n",
            "2019-04-04T20:03:08.503057: step 9820, loss 0.281248, acc 1\n",
            "2019-04-04T20:03:08.687436: step 9830, loss 0.280962, acc 1\n",
            "2019-04-04T20:03:08.873449: step 9840, loss 0.280484, acc 1\n",
            "2019-04-04T20:03:09.063162: step 9850, loss 0.28057, acc 1\n",
            "2019-04-04T20:03:09.248021: step 9860, loss 0.280527, acc 1\n",
            "2019-04-04T20:03:09.433788: step 9870, loss 0.280083, acc 1\n",
            "2019-04-04T20:03:09.621234: step 9880, loss 0.280206, acc 1\n",
            "2019-04-04T20:03:09.812032: step 9890, loss 0.280196, acc 1\n",
            "2019-04-04T20:03:10.001355: step 9900, loss 0.280778, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:10.033176: step 9900, loss 1.7959, acc 0.667897\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.556905\n",
            "\n",
            "2019-04-04T20:03:10.218889: step 9910, loss 0.28431, acc 1\n",
            "2019-04-04T20:03:10.410723: step 9920, loss 0.279834, acc 1\n",
            "2019-04-04T20:03:10.598935: step 9930, loss 0.280345, acc 1\n",
            "2019-04-04T20:03:10.786233: step 9940, loss 0.281745, acc 1\n",
            "2019-04-04T20:03:10.977591: step 9950, loss 0.280048, acc 1\n",
            "2019-04-04T20:03:11.161069: step 9960, loss 0.28077, acc 1\n",
            "2019-04-04T20:03:11.347639: step 9970, loss 0.279668, acc 1\n",
            "2019-04-04T20:03:11.531754: step 9980, loss 0.279505, acc 1\n",
            "2019-04-04T20:03:11.721619: step 9990, loss 0.279686, acc 1\n",
            "2019-04-04T20:03:11.911694: step 10000, loss 0.279961, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:11.943501: step 10000, loss 1.84918, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.597963\n",
            "\n",
            "2019-04-04T20:03:12.130301: step 10010, loss 0.279867, acc 1\n",
            "2019-04-04T20:03:12.316966: step 10020, loss 0.27957, acc 1\n",
            "2019-04-04T20:03:12.505992: step 10030, loss 0.282819, acc 1\n",
            "2019-04-04T20:03:12.693522: step 10040, loss 0.279594, acc 1\n",
            "2019-04-04T20:03:12.880982: step 10050, loss 0.279675, acc 1\n",
            "2019-04-04T20:03:13.067871: step 10060, loss 0.27937, acc 1\n",
            "2019-04-04T20:03:13.255051: step 10070, loss 0.279119, acc 1\n",
            "2019-04-04T20:03:13.441448: step 10080, loss 0.279676, acc 1\n",
            "2019-04-04T20:03:13.618074: step 10090, loss 0.278989, acc 1\n",
            "2019-04-04T20:03:13.803694: step 10100, loss 0.279492, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:13.835061: step 10100, loss 1.85883, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.594911\n",
            "\n",
            "2019-04-04T20:03:14.026930: step 10110, loss 0.278963, acc 1\n",
            "2019-04-04T20:03:14.212373: step 10120, loss 0.279561, acc 1\n",
            "2019-04-04T20:03:14.398502: step 10130, loss 0.292199, acc 1\n",
            "2019-04-04T20:03:14.581441: step 10140, loss 0.27859, acc 1\n",
            "2019-04-04T20:03:14.767941: step 10150, loss 0.27886, acc 1\n",
            "2019-04-04T20:03:14.956444: step 10160, loss 0.278873, acc 1\n",
            "2019-04-04T20:03:15.141629: step 10170, loss 0.278681, acc 1\n",
            "2019-04-04T20:03:15.324243: step 10180, loss 0.280041, acc 1\n",
            "2019-04-04T20:03:15.510499: step 10190, loss 0.278802, acc 1\n",
            "2019-04-04T20:03:15.694518: step 10200, loss 0.278977, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:15.726014: step 10200, loss 1.8402, acc 0.697417\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.619146\n",
            "\n",
            "2019-04-04T20:03:15.906155: step 10210, loss 0.27821, acc 1\n",
            "2019-04-04T20:03:16.095192: step 10220, loss 0.278693, acc 1\n",
            "2019-04-04T20:03:16.279222: step 10230, loss 0.278865, acc 1\n",
            "2019-04-04T20:03:16.468179: step 10240, loss 0.288222, acc 1\n",
            "2019-04-04T20:03:16.651544: step 10250, loss 0.278528, acc 1\n",
            "2019-04-04T20:03:16.842834: step 10260, loss 0.278143, acc 1\n",
            "2019-04-04T20:03:17.028054: step 10270, loss 0.277946, acc 1\n",
            "2019-04-04T20:03:17.215392: step 10280, loss 0.278352, acc 1\n",
            "2019-04-04T20:03:17.401323: step 10290, loss 0.27866, acc 1\n",
            "2019-04-04T20:03:17.589469: step 10300, loss 0.277999, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:17.621367: step 10300, loss 1.85117, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.601026\n",
            "\n",
            "2019-04-04T20:03:17.812538: step 10310, loss 0.278004, acc 1\n",
            "2019-04-04T20:03:17.999392: step 10320, loss 0.278007, acc 1\n",
            "2019-04-04T20:03:18.190238: step 10330, loss 0.27761, acc 1\n",
            "2019-04-04T20:03:18.369037: step 10340, loss 0.277471, acc 1\n",
            "2019-04-04T20:03:18.554539: step 10350, loss 0.278168, acc 1\n",
            "2019-04-04T20:03:18.738418: step 10360, loss 0.277878, acc 1\n",
            "2019-04-04T20:03:18.924141: step 10370, loss 0.277501, acc 1\n",
            "2019-04-04T20:03:19.108221: step 10380, loss 0.277983, acc 1\n",
            "2019-04-04T20:03:19.292125: step 10390, loss 0.27764, acc 1\n",
            "2019-04-04T20:03:19.473816: step 10400, loss 0.279001, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:19.505420: step 10400, loss 1.82786, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.59496\n",
            "\n",
            "2019-04-04T20:03:19.690632: step 10410, loss 0.277332, acc 1\n",
            "2019-04-04T20:03:19.883379: step 10420, loss 0.277468, acc 1\n",
            "2019-04-04T20:03:20.066666: step 10430, loss 0.277274, acc 1\n",
            "2019-04-04T20:03:20.258331: step 10440, loss 0.277158, acc 1\n",
            "2019-04-04T20:03:20.442787: step 10450, loss 0.277559, acc 1\n",
            "2019-04-04T20:03:20.626110: step 10460, loss 0.279357, acc 1\n",
            "2019-04-04T20:03:20.810220: step 10470, loss 0.277057, acc 1\n",
            "2019-04-04T20:03:21.000024: step 10480, loss 0.282577, acc 1\n",
            "2019-04-04T20:03:21.187155: step 10490, loss 0.276791, acc 1\n",
            "2019-04-04T20:03:21.372902: step 10500, loss 0.276845, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:21.404287: step 10500, loss 1.80557, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.580939\n",
            "\n",
            "2019-04-04T20:03:21.592472: step 10510, loss 0.277186, acc 1\n",
            "2019-04-04T20:03:21.778368: step 10520, loss 0.278394, acc 1\n",
            "2019-04-04T20:03:21.968040: step 10530, loss 0.277608, acc 1\n",
            "2019-04-04T20:03:22.156463: step 10540, loss 0.276985, acc 1\n",
            "2019-04-04T20:03:22.340824: step 10550, loss 0.277063, acc 1\n",
            "2019-04-04T20:03:22.523392: step 10560, loss 0.277, acc 1\n",
            "2019-04-04T20:03:22.711026: step 10570, loss 0.276618, acc 1\n",
            "2019-04-04T20:03:22.890487: step 10580, loss 0.277319, acc 1\n",
            "2019-04-04T20:03:23.077546: step 10590, loss 0.276815, acc 1\n",
            "2019-04-04T20:03:23.265187: step 10600, loss 0.27776, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:23.296554: step 10600, loss 1.80147, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.578432\n",
            "\n",
            "2019-04-04T20:03:23.483615: step 10610, loss 0.27686, acc 1\n",
            "2019-04-04T20:03:23.669293: step 10620, loss 0.276437, acc 1\n",
            "2019-04-04T20:03:23.853620: step 10630, loss 0.276005, acc 1\n",
            "2019-04-04T20:03:24.045278: step 10640, loss 0.281166, acc 1\n",
            "2019-04-04T20:03:24.233205: step 10650, loss 0.277452, acc 1\n",
            "2019-04-04T20:03:24.418195: step 10660, loss 0.276406, acc 1\n",
            "2019-04-04T20:03:24.603660: step 10670, loss 0.276378, acc 1\n",
            "2019-04-04T20:03:24.796366: step 10680, loss 0.275921, acc 1\n",
            "2019-04-04T20:03:24.979156: step 10690, loss 0.276767, acc 1\n",
            "2019-04-04T20:03:25.161411: step 10700, loss 0.275634, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:25.193499: step 10700, loss 1.81076, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.582835\n",
            "\n",
            "2019-04-04T20:03:25.380260: step 10710, loss 0.275544, acc 1\n",
            "2019-04-04T20:03:25.563468: step 10720, loss 0.275815, acc 1\n",
            "2019-04-04T20:03:25.749152: step 10730, loss 0.275627, acc 1\n",
            "2019-04-04T20:03:25.930015: step 10740, loss 0.279665, acc 1\n",
            "2019-04-04T20:03:26.113106: step 10750, loss 0.275666, acc 1\n",
            "2019-04-04T20:03:26.300236: step 10760, loss 0.275785, acc 1\n",
            "2019-04-04T20:03:26.483485: step 10770, loss 0.277486, acc 1\n",
            "2019-04-04T20:03:26.666365: step 10780, loss 0.275563, acc 1\n",
            "2019-04-04T20:03:26.852586: step 10790, loss 0.275889, acc 1\n",
            "2019-04-04T20:03:27.037784: step 10800, loss 0.275115, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:27.069520: step 10800, loss 1.83625, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.606274\n",
            "\n",
            "2019-04-04T20:03:27.251232: step 10810, loss 0.274998, acc 1\n",
            "2019-04-04T20:03:27.440523: step 10820, loss 0.275686, acc 1\n",
            "2019-04-04T20:03:27.616537: step 10830, loss 0.275001, acc 1\n",
            "2019-04-04T20:03:27.797427: step 10840, loss 0.276055, acc 1\n",
            "2019-04-04T20:03:27.977628: step 10850, loss 0.275122, acc 1\n",
            "2019-04-04T20:03:28.160801: step 10860, loss 0.275063, acc 1\n",
            "2019-04-04T20:03:28.344448: step 10870, loss 0.274894, acc 1\n",
            "2019-04-04T20:03:28.529192: step 10880, loss 0.275353, acc 1\n",
            "2019-04-04T20:03:28.709823: step 10890, loss 0.275206, acc 1\n",
            "2019-04-04T20:03:28.892161: step 10900, loss 0.274573, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:28.924458: step 10900, loss 1.84129, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.601426\n",
            "\n",
            "2019-04-04T20:03:29.113236: step 10910, loss 0.274571, acc 1\n",
            "2019-04-04T20:03:29.297315: step 10920, loss 0.274682, acc 1\n",
            "2019-04-04T20:03:29.485766: step 10930, loss 0.274786, acc 1\n",
            "2019-04-04T20:03:29.670113: step 10940, loss 0.274597, acc 1\n",
            "2019-04-04T20:03:29.851663: step 10950, loss 0.275296, acc 1\n",
            "2019-04-04T20:03:30.037092: step 10960, loss 0.27462, acc 1\n",
            "2019-04-04T20:03:30.230130: step 10970, loss 0.275847, acc 1\n",
            "2019-04-04T20:03:30.418062: step 10980, loss 0.274962, acc 1\n",
            "2019-04-04T20:03:30.598713: step 10990, loss 0.274888, acc 1\n",
            "2019-04-04T20:03:30.779014: step 11000, loss 0.274896, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:30.810809: step 11000, loss 1.84749, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.590866\n",
            "\n",
            "2019-04-04T20:03:30.992930: step 11010, loss 0.274815, acc 1\n",
            "2019-04-04T20:03:31.179707: step 11020, loss 0.275712, acc 1\n",
            "2019-04-04T20:03:31.360030: step 11030, loss 0.274552, acc 1\n",
            "2019-04-04T20:03:31.548403: step 11040, loss 0.274195, acc 1\n",
            "2019-04-04T20:03:31.729947: step 11050, loss 0.273976, acc 1\n",
            "2019-04-04T20:03:31.917599: step 11060, loss 0.274013, acc 1\n",
            "2019-04-04T20:03:32.100016: step 11070, loss 0.273724, acc 1\n",
            "2019-04-04T20:03:32.286873: step 11080, loss 0.273935, acc 1\n",
            "2019-04-04T20:03:32.477453: step 11090, loss 0.274764, acc 1\n",
            "2019-04-04T20:03:32.662023: step 11100, loss 0.274241, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:32.693491: step 11100, loss 1.83553, acc 0.693727\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.619266\n",
            "\n",
            "2019-04-04T20:03:32.876390: step 11110, loss 0.273735, acc 1\n",
            "2019-04-04T20:03:33.059159: step 11120, loss 0.273805, acc 1\n",
            "2019-04-04T20:03:33.241256: step 11130, loss 0.27422, acc 1\n",
            "2019-04-04T20:03:33.423542: step 11140, loss 0.273616, acc 1\n",
            "2019-04-04T20:03:33.617366: step 11150, loss 0.273211, acc 1\n",
            "2019-04-04T20:03:33.803724: step 11160, loss 0.273887, acc 1\n",
            "2019-04-04T20:03:33.993566: step 11170, loss 0.273291, acc 1\n",
            "2019-04-04T20:03:34.178519: step 11180, loss 0.273404, acc 1\n",
            "2019-04-04T20:03:34.367569: step 11190, loss 0.275048, acc 1\n",
            "2019-04-04T20:03:34.551070: step 11200, loss 0.273429, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:34.583304: step 11200, loss 1.82093, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.596875\n",
            "\n",
            "2019-04-04T20:03:34.770099: step 11210, loss 0.272956, acc 1\n",
            "2019-04-04T20:03:34.957561: step 11220, loss 0.273371, acc 1\n",
            "2019-04-04T20:03:35.143084: step 11230, loss 0.275357, acc 1\n",
            "2019-04-04T20:03:35.329367: step 11240, loss 0.27274, acc 1\n",
            "2019-04-04T20:03:35.518075: step 11250, loss 0.272693, acc 1\n",
            "2019-04-04T20:03:35.703590: step 11260, loss 0.273606, acc 1\n",
            "2019-04-04T20:03:35.887057: step 11270, loss 0.272733, acc 1\n",
            "2019-04-04T20:03:36.075353: step 11280, loss 0.272552, acc 1\n",
            "2019-04-04T20:03:36.259046: step 11290, loss 0.272689, acc 1\n",
            "2019-04-04T20:03:36.447918: step 11300, loss 0.273769, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:36.479492: step 11300, loss 1.80446, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.59681\n",
            "\n",
            "2019-04-04T20:03:36.667053: step 11310, loss 0.272663, acc 1\n",
            "2019-04-04T20:03:36.840339: step 11320, loss 0.272578, acc 1\n",
            "2019-04-04T20:03:37.021283: step 11330, loss 0.27373, acc 1\n",
            "2019-04-04T20:03:37.201434: step 11340, loss 0.272293, acc 1\n",
            "2019-04-04T20:03:37.385357: step 11350, loss 0.273223, acc 1\n",
            "2019-04-04T20:03:37.569040: step 11360, loss 0.272397, acc 1\n",
            "2019-04-04T20:03:37.753192: step 11370, loss 0.272483, acc 1\n",
            "2019-04-04T20:03:37.936085: step 11380, loss 0.272253, acc 1\n",
            "2019-04-04T20:03:38.121977: step 11390, loss 0.272297, acc 1\n",
            "2019-04-04T20:03:38.308280: step 11400, loss 0.272592, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:38.339791: step 11400, loss 1.83045, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.588975\n",
            "\n",
            "2019-04-04T20:03:38.520939: step 11410, loss 0.27314, acc 1\n",
            "2019-04-04T20:03:38.704096: step 11420, loss 0.271924, acc 1\n",
            "2019-04-04T20:03:38.883333: step 11430, loss 0.272089, acc 1\n",
            "2019-04-04T20:03:39.062309: step 11440, loss 0.273806, acc 1\n",
            "2019-04-04T20:03:39.243521: step 11450, loss 0.272029, acc 1\n",
            "2019-04-04T20:03:39.427538: step 11460, loss 0.27186, acc 1\n",
            "2019-04-04T20:03:39.616457: step 11470, loss 0.272096, acc 1\n",
            "2019-04-04T20:03:39.803606: step 11480, loss 0.271753, acc 1\n",
            "2019-04-04T20:03:39.989721: step 11490, loss 0.273399, acc 1\n",
            "2019-04-04T20:03:40.174318: step 11500, loss 0.271642, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:40.205828: step 11500, loss 1.86522, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.600291\n",
            "\n",
            "2019-04-04T20:03:40.394379: step 11510, loss 0.271854, acc 1\n",
            "2019-04-04T20:03:40.574029: step 11520, loss 0.271578, acc 1\n",
            "2019-04-04T20:03:40.759646: step 11530, loss 0.27174, acc 1\n",
            "2019-04-04T20:03:40.941411: step 11540, loss 0.271781, acc 1\n",
            "2019-04-04T20:03:41.123812: step 11550, loss 0.271132, acc 1\n",
            "2019-04-04T20:03:41.302901: step 11560, loss 0.271367, acc 1\n",
            "2019-04-04T20:03:41.482835: step 11570, loss 0.272416, acc 1\n",
            "2019-04-04T20:03:41.675507: step 11580, loss 0.270823, acc 1\n",
            "2019-04-04T20:03:41.858967: step 11590, loss 0.270926, acc 1\n",
            "2019-04-04T20:03:42.043723: step 11600, loss 0.271012, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:42.075252: step 11600, loss 1.8223, acc 0.675277\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.573741\n",
            "\n",
            "2019-04-04T20:03:42.258709: step 11610, loss 0.271142, acc 1\n",
            "2019-04-04T20:03:42.444354: step 11620, loss 0.270743, acc 1\n",
            "2019-04-04T20:03:42.625453: step 11630, loss 0.271034, acc 1\n",
            "2019-04-04T20:03:42.807481: step 11640, loss 0.270905, acc 1\n",
            "2019-04-04T20:03:42.989840: step 11650, loss 0.27055, acc 1\n",
            "2019-04-04T20:03:43.176588: step 11660, loss 0.270602, acc 1\n",
            "2019-04-04T20:03:43.360355: step 11670, loss 0.271568, acc 1\n",
            "2019-04-04T20:03:43.554603: step 11680, loss 0.270978, acc 1\n",
            "2019-04-04T20:03:43.732995: step 11690, loss 0.270747, acc 1\n",
            "2019-04-04T20:03:43.918959: step 11700, loss 0.275853, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:43.951246: step 11700, loss 1.81456, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.605328\n",
            "\n",
            "2019-04-04T20:03:44.132982: step 11710, loss 0.271109, acc 1\n",
            "2019-04-04T20:03:44.312456: step 11720, loss 0.270305, acc 1\n",
            "2019-04-04T20:03:44.494638: step 11730, loss 0.270461, acc 1\n",
            "2019-04-04T20:03:44.676190: step 11740, loss 0.270267, acc 1\n",
            "2019-04-04T20:03:44.861884: step 11750, loss 0.270795, acc 1\n",
            "2019-04-04T20:03:45.042988: step 11760, loss 0.270452, acc 1\n",
            "2019-04-04T20:03:45.228094: step 11770, loss 0.270079, acc 1\n",
            "2019-04-04T20:03:45.408163: step 11780, loss 0.270732, acc 1\n",
            "2019-04-04T20:03:45.590497: step 11790, loss 0.270152, acc 1\n",
            "2019-04-04T20:03:45.775009: step 11800, loss 0.269974, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:45.807600: step 11800, loss 1.85986, acc 0.686347\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.600085\n",
            "\n",
            "2019-04-04T20:03:45.989349: step 11810, loss 0.270374, acc 1\n",
            "2019-04-04T20:03:46.178649: step 11820, loss 0.270029, acc 1\n",
            "2019-04-04T20:03:46.363829: step 11830, loss 0.2697, acc 1\n",
            "2019-04-04T20:03:46.553456: step 11840, loss 0.26962, acc 1\n",
            "2019-04-04T20:03:46.737418: step 11850, loss 0.26966, acc 1\n",
            "2019-04-04T20:03:46.931280: step 11860, loss 0.269884, acc 1\n",
            "2019-04-04T20:03:47.114067: step 11870, loss 0.271232, acc 1\n",
            "2019-04-04T20:03:47.302425: step 11880, loss 0.269744, acc 1\n",
            "2019-04-04T20:03:47.487448: step 11890, loss 0.269977, acc 1\n",
            "2019-04-04T20:03:47.672499: step 11900, loss 0.269273, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:47.704650: step 11900, loss 1.8612, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.602963\n",
            "\n",
            "2019-04-04T20:03:47.898282: step 11910, loss 0.270275, acc 1\n",
            "2019-04-04T20:03:48.080192: step 11920, loss 0.269668, acc 1\n",
            "2019-04-04T20:03:48.266046: step 11930, loss 0.269799, acc 1\n",
            "2019-04-04T20:03:48.444211: step 11940, loss 0.270185, acc 1\n",
            "2019-04-04T20:03:48.631729: step 11950, loss 0.269466, acc 1\n",
            "2019-04-04T20:03:48.814383: step 11960, loss 0.269041, acc 1\n",
            "2019-04-04T20:03:49.000359: step 11970, loss 0.268953, acc 1\n",
            "2019-04-04T20:03:49.184063: step 11980, loss 0.270376, acc 1\n",
            "2019-04-04T20:03:49.371846: step 11990, loss 0.268745, acc 1\n",
            "2019-04-04T20:03:49.554961: step 12000, loss 0.269206, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:49.586654: step 12000, loss 1.8415, acc 0.682657\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.597659\n",
            "\n",
            "2019-04-04T20:03:49.772574: step 12010, loss 0.269501, acc 1\n",
            "2019-04-04T20:03:49.964860: step 12020, loss 0.269187, acc 1\n",
            "2019-04-04T20:03:50.147871: step 12030, loss 0.269517, acc 1\n",
            "2019-04-04T20:03:50.334246: step 12040, loss 0.269673, acc 1\n",
            "2019-04-04T20:03:50.517932: step 12050, loss 0.269209, acc 1\n",
            "2019-04-04T20:03:50.696697: step 12060, loss 0.269229, acc 1\n",
            "2019-04-04T20:03:50.880548: step 12070, loss 0.268924, acc 1\n",
            "2019-04-04T20:03:51.074788: step 12080, loss 0.268431, acc 1\n",
            "2019-04-04T20:03:51.258715: step 12090, loss 0.268831, acc 1\n",
            "2019-04-04T20:03:51.448245: step 12100, loss 0.268253, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:51.479501: step 12100, loss 1.82805, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.59423\n",
            "\n",
            "2019-04-04T20:03:51.659864: step 12110, loss 0.26848, acc 1\n",
            "2019-04-04T20:03:51.840773: step 12120, loss 0.269275, acc 1\n",
            "2019-04-04T20:03:52.025421: step 12130, loss 0.268778, acc 1\n",
            "2019-04-04T20:03:52.208462: step 12140, loss 0.269029, acc 1\n",
            "2019-04-04T20:03:52.398019: step 12150, loss 0.269027, acc 1\n",
            "2019-04-04T20:03:52.581009: step 12160, loss 0.268141, acc 1\n",
            "2019-04-04T20:03:52.769377: step 12170, loss 0.267935, acc 1\n",
            "2019-04-04T20:03:52.948460: step 12180, loss 0.268241, acc 1\n",
            "2019-04-04T20:03:53.142126: step 12190, loss 0.269313, acc 1\n",
            "2019-04-04T20:03:53.328792: step 12200, loss 0.26784, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:53.361078: step 12200, loss 1.85822, acc 0.690037\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.609236\n",
            "\n",
            "2019-04-04T20:03:53.541887: step 12210, loss 0.267827, acc 1\n",
            "2019-04-04T20:03:53.722865: step 12220, loss 0.267518, acc 1\n",
            "2019-04-04T20:03:53.902665: step 12230, loss 0.267712, acc 1\n",
            "2019-04-04T20:03:54.092251: step 12240, loss 0.268916, acc 1\n",
            "2019-04-04T20:03:54.273712: step 12250, loss 0.268778, acc 1\n",
            "2019-04-04T20:03:54.457437: step 12260, loss 0.267358, acc 1\n",
            "2019-04-04T20:03:54.639706: step 12270, loss 0.267782, acc 1\n",
            "2019-04-04T20:03:54.824049: step 12280, loss 0.267568, acc 1\n",
            "2019-04-04T20:03:55.004723: step 12290, loss 0.267496, acc 1\n",
            "2019-04-04T20:03:55.189002: step 12300, loss 0.267273, acc 1\n",
            "\n",
            "Evaluation:\n",
            "2019-04-04T20:03:55.220548: step 12300, loss 1.85138, acc 0.678967\n",
            "[UNOFFICIAL] (2*9+1)-Way Macro-Average F1 Score (excluding Other): 0.595723\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C_mXwSntDoml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Eval()**"
      ]
    },
    {
      "metadata": {
        "id": "mSkfb0IYDaTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Map data into vocabulary\n",
        "text_path = \"drive/My Drive/runs/1554407997/text_vocab\"\n",
        "text_vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(text_path)\n",
        "x = np.array(list(text_vocab_processor.transform(x_text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBrDb1eAGoQY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "position_path = \"drive/My Drive/runs/1554407997/pos_vocab\"\n",
        "position_vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(position_path)\n",
        "p1 = np.array(list(position_vocab_processor.transform(pos1)))\n",
        "p2 = np.array(list(position_vocab_processor.transform(pos2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9X119exGxUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_file = tf.train.latest_checkpoint(\"drive/My Drive/runs/1554407997/checkpoints\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Cq6SFoSG8RK",
        "colab_type": "code",
        "outputId": "e19fb00f-bc51-4a92-a7c8-e8686f0b2a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    session_conf = tf.ConfigProto(\n",
        "        allow_soft_placement=True,\n",
        "        log_device_placement=False)\n",
        "    session_conf.gpu_options.allow_growth = True\n",
        "    sess = tf.Session(config=session_conf)\n",
        "    with sess.as_default():\n",
        "        # Load the saved meta graph and restore variables\n",
        "        saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
        "        saver.restore(sess, checkpoint_file)\n",
        "\n",
        "        # Get the placeholders from the graph by name\n",
        "        input_text = graph.get_operation_by_name(\"input_text\").outputs[0]\n",
        "        input_p1 = graph.get_operation_by_name(\"input_p1\").outputs[0]\n",
        "        input_p2 = graph.get_operation_by_name(\"input_p2\").outputs[0]\n",
        "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
        "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
        "\n",
        "        # Tensors we want to evaluate\n",
        "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
        "\n",
        "        # Generate batches for one epoch\n",
        "        batches = batch_iter(list(zip(x, p1, p2)), 20, 1, shuffle=False)\n",
        "\n",
        "        # Collect the predictions here\n",
        "        preds = []\n",
        "        for batch in batches:\n",
        "            x_batch, p1_batch, p2_batch = zip(*batch)\n",
        "            pred = sess.run(predictions, {input_text: x_batch,\n",
        "                                          input_p1: p1_batch,\n",
        "                                          input_p2: p2_batch,\n",
        "                                          dropout_keep_prob: 1.0})\n",
        "            preds.append(pred)\n",
        "        preds = np.concatenate(preds)\n",
        "        truths = np.argmax(y, axis=1)\n",
        "\n",
        "        prediction_path = os.path.join(\"drive/My Drive/runs/1554407997\", \"predictions.txt\")\n",
        "        truth_path = os.path.join(\"drive/My Drive/runs/1554407997\", \"ground_truths.txt\")\n",
        "        prediction_file = open(prediction_path, 'w')\n",
        "        truth_file = open(truth_path, 'w')\n",
        "        for i in range(len(preds)):\n",
        "            prediction_file.write(\"{}\\t{}\\n\".format(i, label2class[preds[i]]))\n",
        "            truth_file.write(\"{}\\t{}\\n\".format(i, label2class[truths[i]]))\n",
        "        prediction_file.close()\n",
        "        truth_file.close()\n",
        "\n",
        "        perl_path = os.path.join(os.path.curdir,\n",
        "                                 \"SemEval2010_task8_all_data\",\n",
        "                                 \"SemEval2010_task8_scorer-v1.2\",\n",
        "                                 \"semeval2010_task8_scorer-v1.2.pl\")\n",
        "        process = subprocess.Popen([\"perl\", perl_path, prediction_path, truth_path], stdout=subprocess.PIPE)\n",
        "        for line in str(process.communicate()[0].decode(\"utf-8\")).split(\"\\\\n\"):\n",
        "            print(line)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/runs/1554407997/checkpoints/model-0.627-7000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k6T4yzyXJjc4",
        "colab_type": "code",
        "outputId": "1dcc5ecb-209a-4b65-9989-495c7eb4c487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"drive/My Drive/runs/1554407997/checkpoints\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t      model-0.61-3000.index\n",
            "model-0.591-2200.data-00000-of-00001  model-0.61-3000.meta\n",
            "model-0.591-2200.index\t\t      model-0.616-4900.data-00000-of-00001\n",
            "model-0.591-2200.meta\t\t      model-0.616-4900.index\n",
            "model-0.594-2400.data-00000-of-00001  model-0.616-4900.meta\n",
            "model-0.594-2400.index\t\t      model-0.627-7000.data-00000-of-00001\n",
            "model-0.594-2400.meta\t\t      model-0.627-7000.index\n",
            "model-0.61-3000.data-00000-of-00001   model-0.627-7000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}